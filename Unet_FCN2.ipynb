{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashpakshaikh26732/Unet-FCN/blob/main/Unet_FCN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XRgNljpyU9b"
      },
      "source": [
        "**all packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY-Fjqfj8lKQ",
        "outputId": "8f846b3c-ab7b-462c-abc7-2aeb5bb5ce49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml-dtypes-0.5.1 tensorboard-2.19.0 tensorflow-2.19.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mm_LuZ1iev66"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display,HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBI53Z14B58q",
        "outputId": "c16065c7-a0a1-4310-fab7-2426589ad42d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.18.0 in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (5.29.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.18.0) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow==2.18.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow==2.18.0) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.18.0) (0.1.2)\n",
            "Looking in links: https://storage.googleapis.com/libtpu-tf-releases/index.html\n",
            "Requirement already satisfied: tensorflow-tpu==2.18.0 in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (5.29.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (0.4.1)\n",
            "Requirement already satisfied: libtpu==2.18.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow-tpu==2.18.0) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow-tpu==2.18.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow-tpu==2.18.0) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow-tpu==2.18.0) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow-tpu==2.18.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow-tpu==2.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow-tpu==2.18.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow-tpu==2.18.0) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-tpu==2.18.0) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-tpu==2.18.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-tpu==2.18.0) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-tpu==2.18.0) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow-tpu==2.18.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow-tpu==2.18.0) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-tpu==2.18.0) (0.1.2)\n",
            "TPU is running: \n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.18.0\n",
        "!pip install tensorflow-tpu==2.18.0 --find-links=https://storage.googleapis.com/libtpu-tf-releases/index.html\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    print(\"TPU is running:\", tpu.master())\n",
        "except ValueError as e:\n",
        "    print(\"TPU is not avaible:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-_0SdKWb53X",
        "outputId": "d51a43a3-a760-4402-b949-552d01e9e319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of TPUs: 8\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of TPUs: {strategy.num_replicas_in_sync}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTuYhVhRffta",
        "outputId": "3ced8551-4c0f-41f2-a444-f8cef4a58c16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "TPU failed to initialize: Please provide a TPU Name to connect to.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "print(f'TensorFlow version: {tf.__version__}')\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  print(f'TPU cluster resolved: {tpu.cluster_spec()}')\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.TPUStrategy(tpu)\n",
        "  print(f'Number of TPUs: {strategy.num_replicas_in_sync}')\n",
        "except Exception as e:\n",
        "  print(f'TPU failed to initialize: {e}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzwsFyykuBp6"
      },
      "source": [
        "**mixed precision training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "I9g7HnQsuOMj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cdN0drMo70q4"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQK2Gy1ggZP-",
        "outputId": "bd51d001-1ef4-4815-f88f-922f0ee0779a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLI9cZz46258"
      },
      "source": [
        "**copy datasets from drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_cb4xI4h5b3z"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/Cityscapes/gtFine_trainvaltest.zip /content/\n",
        "!cp /content/drive/MyDrive/Cityscapes/leftImg8bit_trainvaltest.zip /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWcHvq9T67yT"
      },
      "source": [
        "**extract trainig the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIGN5YpV58XW",
        "outputId": "06a29e8d-05d8-4487-ac44-2b71f9cbe329"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "os.system(\"unzip -q /content/gtFine_trainvaltest.zip -d /content/ \")\n",
        "os.system(\"unzip -q /content/leftImg8bit_trainvaltest.zip -d /content/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MKUIQNX7naD",
        "outputId": "e8c986a2-bd40-473f-cabe-0ac427745248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images: 18\n",
            "Train Labels: 18\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Images:\", len(os.listdir(\"/content/leftImg8bit/train/\")))\n",
        "print(\"Train Labels:\", len(os.listdir(\"/content/gtFine/train/\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qafiZBb5yC0b",
        "outputId": "4fb651c2-3612-4c09-e54d-529475351cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test images :  6\n"
          ]
        }
      ],
      "source": [
        "print(\"test images : \", len(os.listdir('/content/leftImg8bit/test')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q1cFO0jJcA8"
      },
      "source": [
        "**Global Valrible**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3NSFJ69oJiMF"
      },
      "outputs": [],
      "source": [
        "img_height = 640\n",
        "img_width = 640\n",
        "batch_size = 1\n",
        "final_batch_size = batch_size * strategy.num_replicas_in_sync\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9Y6CZKmCbNd"
      },
      "source": [
        "**loading images and labels from directry for training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OzTJuxSUyT19"
      },
      "outputs": [],
      "source": [
        "def load_img():\n",
        "    train_dir = '/content/leftImg8bit/train'\n",
        "    train_image_cities = os.listdir(train_dir)\n",
        "    train_images = []\n",
        "\n",
        "    for city in sorted(train_image_cities):\n",
        "        train_city = os.path.join(train_dir, city)\n",
        "        images = sorted([os.path.join(train_city, img) for img in os.listdir(train_city) if img.endswith('.png')])\n",
        "        train_images.extend(images)\n",
        "\n",
        "    return train_images\n",
        "\n",
        "def load_labels():\n",
        "    train_dir = '/content/gtFine/train'\n",
        "    train_labels_cities = os.listdir(train_dir)\n",
        "    train_labels = []\n",
        "\n",
        "    for city in sorted(train_labels_cities):\n",
        "        train_city_label = os.path.join(train_dir, city)\n",
        "        labels = sorted([f for f in os.listdir(train_city_label) if f.endswith('_gtFine_labelIds.png')])\n",
        "        for label in labels:\n",
        "            label_path = os.path.join(train_city_label, label)\n",
        "            train_labels.append(label_path)\n",
        "\n",
        "    return train_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGkR1OkdChy9"
      },
      "source": [
        "**reading images from path**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tR2-lYACFmLh"
      },
      "outputs": [],
      "source": [
        "def read_img(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, (img_height, img_width))\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "def read_labels(label_path):\n",
        "    label = tf.io.read_file(label_path)\n",
        "    label = tf.io.decode_png(label, channels=1)\n",
        "    label = tf.image.resize(label, (img_height, img_width), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    return tf.cast(label, tf.uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMQ2HsmKQtqF"
      },
      "source": [
        "**augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ArL30hPWQzQc"
      },
      "outputs": [],
      "source": [
        "def process_data(image_path, label_path):\n",
        "    image = read_img(image_path)\n",
        "    label = read_labels(label_path)\n",
        "    return image, label\n",
        "\n",
        "def augment(image, label):\n",
        "    label = tf.cast(label, tf.float32)\n",
        "\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "        label = tf.image.flip_left_right(label)\n",
        "\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "\n",
        "    combined = tf.concat([image, label], axis=-1)\n",
        "    combined = tf.image.random_crop(combined, size=[640, 640, 4])\n",
        "    image, label = tf.split(combined, num_or_size_splits=[3, 1], axis=-1)\n",
        "\n",
        "    label = tf.cast(label, tf.uint8)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMrQX_bwIrwt"
      },
      "source": [
        "**creating dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiZ4wr51HQR_",
        "outputId": "1793c246-65e6-4f5b-dfbe-a8735fcbc04a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Train Images: 2975\n",
            "Total Train Labels: 2975\n"
          ]
        }
      ],
      "source": [
        "images = load_img()\n",
        "labels = load_labels()\n",
        "print(\"Total Train Images:\", len(images))\n",
        "print(\"Total Train Labels:\", len(labels))\n",
        "# Create TF Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "dataset = dataset.map(process_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset = dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset = dataset.shuffle(buffer_size=1000).cache().batch(final_batch_size)\n",
        "train_dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "train_dataset = strategy.experimental_distribute_dataset(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4asEByyJz3k",
        "outputId": "fe4d6d5b-8bc3-4a12-d862-d96f643cdec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape : (8, 640, 640, 3) , label shape (8, 640, 640, 1)\n",
            "image datatype : <dtype: 'float32'>, label dtype <dtype: 'uint8'>, TYPE : \n"
          ]
        }
      ],
      "source": [
        "for image , label in dataset.take(1):\n",
        "  print(f'image shape : {image.shape} , label shape {label.shape}')\n",
        "  print(f'image datatype : {image.dtype}, label dtype {label.dtype}, TYPE : ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtUwaeoBgZ1-"
      },
      "source": [
        "**loading images and labels from directry for validiation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Bt2sAOA9gZP4"
      },
      "outputs": [],
      "source": [
        "def load_img_val():\n",
        "    train_dir = '/content/leftImg8bit/val'\n",
        "    train_image_cities = os.listdir(train_dir)\n",
        "    train_images = []\n",
        "\n",
        "    for city in sorted(train_image_cities):\n",
        "        train_city = os.path.join(train_dir, city)\n",
        "        images = sorted([os.path.join(train_city, img) for img in os.listdir(train_city) if img.endswith('.png')])\n",
        "        train_images.extend(images)\n",
        "\n",
        "    return train_images\n",
        "\n",
        "def load_labels_val():\n",
        "    train_dir = '/content/gtFine/val'\n",
        "    train_labels_cities = os.listdir(train_dir)\n",
        "    train_labels = []\n",
        "\n",
        "    for city in sorted(train_labels_cities):\n",
        "        train_city_label = os.path.join(train_dir, city)\n",
        "        labels = sorted([f for f in os.listdir(train_city_label) if f.endswith('_gtFine_labelIds.png')])\n",
        "        for label in labels:\n",
        "            label_path = os.path.join(train_city_label, label)\n",
        "            train_labels.append(label_path)\n",
        "\n",
        "    return train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "akUFQg0SgqWq"
      },
      "outputs": [],
      "source": [
        "def read_img_val(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, (img_height, img_width))\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "def read_labels_val(label_path):\n",
        "    label = tf.io.read_file(label_path)\n",
        "    label = tf.io.decode_png(label, channels=1)\n",
        "    label = tf.image.resize(label, (img_height, img_width), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    return tf.cast(label, tf.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oLLrc6JQgv15"
      },
      "outputs": [],
      "source": [
        "def process_data_val(image_path, label_path):\n",
        "    image = read_img(image_path)\n",
        "    label = read_labels(label_path)\n",
        "    return image, label\n",
        "\n",
        "images = load_img_val()\n",
        "labels = load_labels_val()\n",
        "\n",
        "# Create TF Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "dataset = dataset.map(process_data_val, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size=1000).cache().batch(final_batch_size)\n",
        "val_dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_dataset = strategy.experimental_distribute_dataset(val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWuEcsIvhHAl"
      },
      "source": [
        "**loading images and labels from directry for testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZnpkmjsehZUW"
      },
      "outputs": [],
      "source": [
        "def load_img_test():\n",
        "    train_dir = '/content/leftImg8bit/test'\n",
        "    train_image_cities = os.listdir(train_dir)\n",
        "    train_images = []\n",
        "\n",
        "    for city in sorted(train_image_cities):\n",
        "        train_city = os.path.join(train_dir, city)\n",
        "        images = sorted([os.path.join(train_city, img) for img in os.listdir(train_city) if img.endswith('.png')])\n",
        "        train_images.extend(images)\n",
        "\n",
        "    return train_images\n",
        "\n",
        "def load_labels_test():\n",
        "    train_dir = '/content/gtFine/test'\n",
        "    train_labels_cities = os.listdir(train_dir)\n",
        "    train_labels = []\n",
        "\n",
        "    for city in sorted(train_labels_cities):\n",
        "        train_city_label = os.path.join(train_dir, city)\n",
        "        labels = sorted([f for f in os.listdir(train_city_label) if f.endswith('_gtFine_labelIds.png')])\n",
        "        for label in labels:\n",
        "            label_path = os.path.join(train_city_label, label)\n",
        "            train_labels.append(label_path)\n",
        "\n",
        "    return train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-w9CLcnqhqH9"
      },
      "outputs": [],
      "source": [
        "def read_img_test(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, (img_height, img_width))\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "def read_labels_test(label_path):\n",
        "    label = tf.io.read_file(label_path)\n",
        "    label = tf.io.decode_png(label, channels=1)\n",
        "    label = tf.image.resize(label, (img_height, img_width), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    return tf.cast(label, tf.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2TQo6yfIh2J0"
      },
      "outputs": [],
      "source": [
        "def process_data_test(image_path, label_path):\n",
        "    image = read_img(image_path)\n",
        "    label = read_labels(label_path)\n",
        "    return image, label\n",
        "\n",
        "images = load_img_test()\n",
        "labels = load_labels_test()\n",
        "\n",
        "# Create TF Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "dataset = dataset.map(process_data_test, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size=1000).cache().batch(final_batch_size)\n",
        "test_dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_dataset = strategy.experimental_distribute_dataset(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71fnRZr6XnEY"
      },
      "source": [
        "**FCN model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "lYYeYAZ7WKGM"
      },
      "outputs": [],
      "source": [
        "class Block(tf.keras.models.Model):\n",
        "    def __init__(self, n_conv, filters, kernel_size, activation, pool_size, pool_stride, block_name):\n",
        "        super().__init__()\n",
        "        self.conv_layers = [\n",
        "            tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding='same',\n",
        "                                   activation=activation, name=f\"{block_name}_conv{i+1}\")\n",
        "            for i in range(n_conv)\n",
        "        ]\n",
        "        self.pool = tf.keras.layers.MaxPool2D(pool_size=pool_size, strides=pool_stride, name=f\"{block_name}_pool\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for conv in self.conv_layers:\n",
        "            x = conv(x)\n",
        "        x = self.pool(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qTQFaELPY5CU"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.block1 = Block(n_conv=2 , filters=64 , kernel_size = (3,3) , activation ='relu' , pool_size=(2,2) , pool_stride = (2,2) , block_name = 'block1')\n",
        "    self.block2 = Block(n_conv=3 , filters = 128 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block2')\n",
        "    self.block3 = Block(n_conv=3 , filters = 256 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block3')\n",
        "    self.block4 = Block(n_conv=3 , filters = 512 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block4')\n",
        "    self.block5 = Block(n_conv=3 , filters = 512 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block5')\n",
        "  def call(self,inputs):\n",
        "    p1 = self.block1(inputs)\n",
        "    p2 = self.block2(p1)\n",
        "    p3 = self.block3(p2)\n",
        "    p4 = self.block4(p3)\n",
        "    p5 = self.block5(p4)\n",
        "    return p1 , p2 , p3 , p4 , p5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "C7urJTNYZAVO"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.models.Model):\n",
        "    def __init__(self, nclasses=19):\n",
        "        super().__init__()\n",
        "\n",
        "        self.upsample1 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.upsample2 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.upsample3 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "\n",
        "        self.skip1 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), activation='relu', padding='same')\n",
        "        self.skip2 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), activation='relu', padding='same')\n",
        "        self.skip3 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), activation='relu', padding='same')\n",
        "\n",
        "        self.add1 = tf.keras.layers.Add()\n",
        "        self.add2 = tf.keras.layers.Add()\n",
        "        self.add3 = tf.keras.layers.Add()\n",
        "\n",
        "        self.fcn4 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(4, 4), padding='same', name='fcn4')\n",
        "\n",
        "        self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        p1, p2, p3, p4, p5 = inputs\n",
        "\n",
        "        o = self.upsample1(p5)\n",
        "        o = self.add1([o, self.skip1(p4)])\n",
        "\n",
        "        o = self.upsample2(o)\n",
        "        o = self.add2([o, self.skip2(p3)])\n",
        "\n",
        "        o = self.upsample3(o)\n",
        "        o = self.add3([o, self.skip3(p2)])\n",
        "\n",
        "        fcn4 = self.fcn4(o)\n",
        "\n",
        "        return self.softmax(fcn4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4WXzcbDYZOJ5"
      },
      "outputs": [],
      "source": [
        "class FCN(tf.keras.models.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.Encoder = Encoder()\n",
        "        self.Decoder = Decoder()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.Encoder(inputs)\n",
        "        x = self.Decoder(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JxRi_CXd411R"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  fcn =FCN()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t99faxaF2nJN"
      },
      "source": [
        "**UNET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "q1GY9fuSZy2v"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters,block_name , kernel_size=3 , strides = (1,1) , activation='relu'):\n",
        "    super().__init__()\n",
        "    self.conv = [tf.keras.layers.Conv2D(filters=n_filters , strides=strides , kernel_size=(kernel_size, kernel_size) , activation='relu', name=f\"{block_name}_conv{i+1}\", padding='same') for i in range (2)]\n",
        "  def call(self, inputs):\n",
        "    x = inputs\n",
        "    for layer in self.conv:\n",
        "      x = layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XnXkjW1yBK2t"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters , pool_size , dropout,block_name):\n",
        "    super().__init__()\n",
        "    self.convBlock = ConvBlock(n_filters=n_filters , block_name=block_name, strides=(1,1))\n",
        "    self.pool = tf.keras.layers.MaxPooling2D(pool_size=pool_size)\n",
        "    self.dropout = tf.keras.layers.Dropout(rate = dropout)\n",
        "  def call (self, inputs) :\n",
        "    f = self.convBlock(inputs)\n",
        "    p = self.pool(f)\n",
        "    p = self.dropout(p)\n",
        "    return f , p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bGj_gAVYCtKV"
      },
      "outputs": [],
      "source": [
        "class Encoder (tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.encoder1 = EncoderBlock(64 , pool_size=(2,2),dropout=0.3 , block_name = 'block1')\n",
        "    self.encoder2 = EncoderBlock(128 , pool_size=(2,2),dropout=0.3 , block_name = 'block2')\n",
        "    self.encoder3 = EncoderBlock(256 , pool_size=(2,2),dropout=0.3 , block_name = 'block3')\n",
        "    self.encoder4 = EncoderBlock(512, pool_size=(2,2),dropout=0.3 , block_name = 'block4')\n",
        "  def call(self, inputs):\n",
        "    f1,p1=self.encoder1(inputs)\n",
        "    f2,p2 = self.encoder2(p1)\n",
        "    f3 , p3 = self.encoder3(p2)\n",
        "    f4,p4 = self.encoder4(p3)\n",
        "    return p4,(f1,f2,f3,f4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "JnixQBJQEYxk"
      },
      "outputs": [],
      "source": [
        "class BottleNeck(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.convBlock=ConvBlock(1024, block_name = 'bottleneck' )\n",
        "  def call(self, inputs):\n",
        "    x = self.convBlock(inputs)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "yRG3BTRoKBp_"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters ,dropout,block_name , kernel_size= (3,3),strides = (2,2)  ):\n",
        "    super().__init__()\n",
        "    self.convTranspose = tf.keras.layers.Conv2DTranspose(n_filters, kernel_size = kernel_size , strides=strides , padding = 'same')\n",
        "    self.concat = tf.keras.layers.Concatenate()\n",
        "    self.DropOut = tf.keras.layers.Dropout(dropout)\n",
        "    self.convBlock = ConvBlock(n_filters=n_filters , block_name =block_name  )\n",
        "  def call(self, inputs , convOutput):\n",
        "    u=self.convTranspose(inputs)\n",
        "    c = self.concat([u,convOutput])\n",
        "    c= self.DropOut(c)\n",
        "    c = self.convBlock(c)\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "38eh4paxNH6X"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Decoder (tf.keras.models.Model):\n",
        "  def __init__(self) :\n",
        "    super().__init__()\n",
        "    self.Decoder1 = DecoderBlock(n_filters=512 , dropout=0.3 , block_name='Decoder1')\n",
        "    self.Decoder2 = DecoderBlock(n_filters=256 , dropout=0.3 , block_name='Decoder2')\n",
        "    self.Decoder3 = DecoderBlock(n_filters=128 , dropout=0.3 , block_name='Decoder3')\n",
        "    self.Decoder4 = DecoderBlock(n_filters=64 , dropout=0.3 , block_name='Decoder4')\n",
        "    self.final_conv = tf.keras.layers.Conv2D(19, kernel_size=(1,1), activation='softmax')\n",
        "  def call(self , inputs , conv):\n",
        "    f1, f2 , f3, f4 = conv\n",
        "    c6 = self.Decoder1(inputs, f4 )\n",
        "    c7 = self.Decoder2(c6,f3)\n",
        "    c8 = self.Decoder3(c7,f2)\n",
        "    c9= self.Decoder4(c8, f1)\n",
        "    outputs = self.final_conv(c9)\n",
        "    return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "50M1jLpNPbHe"
      },
      "outputs": [],
      "source": [
        "class Unet (tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Encoder = Encoder()\n",
        "    self.BottleNeck = BottleNeck()\n",
        "    self.Decoder = Decoder()\n",
        "  def call(self , inputs):\n",
        "    encoder_output,convs = self.Encoder(inputs)\n",
        "    bottleNeck_output = self.BottleNeck(encoder_output)\n",
        "    output = self.Decoder(bottleNeck_output,convs)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "8ZQzYRpVi9dS"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  unet = Unet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcAZx14LYsBv"
      },
      "source": [
        "***UNET ++***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Ky0wpWCXYxRo"
      },
      "outputs": [],
      "source": [
        "class Unet_plus_plus_convolutional_block(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters , block_name , activation = 'relu',kernel_size=(3,3)  ):\n",
        "    super().__init__()\n",
        "    self.conv_layers = [tf.keras.layers.Conv2D(filters=n_filters , kernel_size= kernel_size , name=f\"{block_name}_conv{i+1}\",padding = 'same', activation='relu') for i in range (2)]\n",
        "  def call(self, inputs) :\n",
        "    x = inputs\n",
        "    for layer in self.conv_layers:\n",
        "      x=layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "DoVSW0wMbWTe"
      },
      "outputs": [],
      "source": [
        "class Encoder_Block_for_unt_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self,  n_filters , pool_size , dropout,block_name):\n",
        "    super().__init__()\n",
        "    self.conv = Unet_plus_plus_convolutional_block(n_filters=n_filters, block_name=block_name)\n",
        "    self.pool = tf.keras.layers.MaxPooling2D(pool_size=pool_size)\n",
        "    self.dropout = tf.keras.layers.Dropout(rate =dropout)\n",
        "  def call(self,inputs):\n",
        "    f=self.conv(inputs)\n",
        "    p = self.pool(f)\n",
        "    p = self.dropout(p)\n",
        "    return f ,  p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8cis-R7e4ozB"
      },
      "outputs": [],
      "source": [
        "class Encoder_for_unt_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.encoder1 = Encoder_Block_for_unt_plus_plus(n_filters=64, pool_size=(2,2) , dropout=0.3, block_name = 'encoder1')\n",
        "    self.encoder2 = Encoder_Block_for_unt_plus_plus(n_filters=128, pool_size=(2,2) , dropout=0.3, block_name = 'encoder2')\n",
        "    self.encoder3 = Encoder_Block_for_unt_plus_plus(n_filters=256, pool_size=(2,2) , dropout=0.3, block_name = 'encoder3')\n",
        "    self.encoder4 = Encoder_Block_for_unt_plus_plus(n_filters=512, pool_size=(2,2) , dropout=0.3, block_name = 'encoder4')\n",
        "  def call(self, inputs):\n",
        "    f1,p1 = self.encoder1(inputs)\n",
        "    f2,p2 = self.encoder2(p1)\n",
        "    f3,p3 = self.encoder3(p2)\n",
        "    f4,p4 = self.encoder4(p3)\n",
        "    return (f1,f2,f3,f4),(p1,p2,p3,p4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "r-p5Nw8n7TcD"
      },
      "outputs": [],
      "source": [
        "class BottleNeck_for_unet_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self ):\n",
        "    super().__init__()\n",
        "    self.bottle_neck = Unet_plus_plus_convolutional_block(n_filters=1024 , block_name = 'bottle_neck'  )\n",
        "  def call(self, inputs):\n",
        "    x = self.bottle_neck(inputs)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "HKqiRcGr83D5"
      },
      "outputs": [],
      "source": [
        "class Decoder_Block_for_unet_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self,n_filters  , dropout,block_name):\n",
        "    super().__init__()\n",
        "    self.conv = Unet_plus_plus_convolutional_block(n_filters=n_filters , block_name = block_name)\n",
        "    self.dropout = tf.keras.layers.Dropout(rate = dropout)\n",
        "    self.convTranspose = tf.keras.layers.Conv2DTranspose(n_filters, kernel_size = (3,3) , strides=(2,2) , padding = 'same')\n",
        "    self.concat = tf.keras.layers.Concatenate()\n",
        "\n",
        "  def call(self, conv_output_conc, inputs):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      if inputs.shape[1] <= 1 or inputs.shape[2] <= 1:\n",
        "\n",
        "          target_size = (max(conv_output_conc.shape[1], 1), max(conv_output_conc.shape[2], 1))\n",
        "          u = tf.image.resize(inputs, target_size)\n",
        "      else:\n",
        "          u = self.convTranspose(inputs)\n",
        "\n",
        "\n",
        "      if u.shape[1:3] != conv_output_conc.shape[1:3]:\n",
        "\n",
        "          if u.shape[1] * u.shape[2] < conv_output_conc.shape[1] * conv_output_conc.shape[2]:\n",
        "              u = tf.image.resize(u, (conv_output_conc.shape[1], conv_output_conc.shape[2]))\n",
        "          else:\n",
        "              conv_output_conc = tf.image.resize(conv_output_conc, (u.shape[1], u.shape[2]))\n",
        "\n",
        "      c = self.concat([u, conv_output_conc])\n",
        "      c = self.dropout(c)\n",
        "      c = self.conv(c)\n",
        "      return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "i9jopfkfASqD"
      },
      "outputs": [],
      "source": [
        "class Decoder_for_unet_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self,num_classes = 19):\n",
        "    super().__init__()\n",
        "    self.decoder11 = Decoder_Block_for_unet_plus_plus(n_filters=64  , dropout = 0.3, block_name = 'skip_conv_block_11')\n",
        "    self.decoder12 = Decoder_Block_for_unet_plus_plus(n_filters=64  , dropout = 0.3, block_name = 'skip_conv_block_12')\n",
        "    self.decoder13 = Decoder_Block_for_unet_plus_plus(n_filters=64  , dropout = 0.3, block_name = 'skip_conv_block_13')\n",
        "    self.decoder14 = Decoder_Block_for_unet_plus_plus(n_filters=64  , dropout = 0.3, block_name = 'skip_conv_block_14')\n",
        "    self.decoder21 = Decoder_Block_for_unet_plus_plus(n_filters=128  , dropout = 0.3, block_name = 'skip_conv_block_21')\n",
        "    self.decoder22 = Decoder_Block_for_unet_plus_plus(n_filters=128  , dropout = 0.3, block_name = 'skip_conv_block_22')\n",
        "    self.decoder23 = Decoder_Block_for_unet_plus_plus(n_filters=128  , dropout = 0.3, block_name = 'skip_conv_block_23')\n",
        "    self.decoder31 = Decoder_Block_for_unet_plus_plus(n_filters=256  , dropout = 0.3, block_name = 'skip_conv_block_31')\n",
        "    self.decoder32 = Decoder_Block_for_unet_plus_plus(n_filters=256  , dropout = 0.3, block_name = 'skip_conv_block_32')\n",
        "    self.decoder41 = Decoder_Block_for_unet_plus_plus(n_filters=512  , dropout = 0.3, block_name = 'skip_conv_block_41')\n",
        "\n",
        "    self.concat12=tf.keras.layers.Concatenate()\n",
        "    self.concat13=tf.keras.layers.Concatenate()\n",
        "    self.concat14=tf.keras.layers.Concatenate()\n",
        "\n",
        "    self.concat22=tf.keras.layers.Concatenate()\n",
        "    self.concat23=tf.keras.layers.Concatenate()\n",
        "\n",
        "    self.concat32=tf.keras.layers.Concatenate()\n",
        "    self.bottle_neck = BottleNeck_for_unet_plus_plus()\n",
        "    self.output_layer14 = tf.keras.layers.Conv2D(\n",
        "        filters=num_classes,\n",
        "        kernel_size=(1,1),\n",
        "        activation='sigmoid' if num_classes == 1 else 'softmax',\n",
        "        padding='same',\n",
        "        name='output_layer'\n",
        "        )\n",
        "    self.output_layer13 = tf.keras.layers.Conv2D(\n",
        "        filters=num_classes,\n",
        "        kernel_size=(1,1),\n",
        "        activation='sigmoid' if num_classes == 1 else 'softmax',\n",
        "        padding='same',\n",
        "        name='output_layer'\n",
        "        )\n",
        "    self.output_layer12 = tf.keras.layers.Conv2D(\n",
        "        filters=num_classes,\n",
        "        kernel_size=(1,1),\n",
        "        activation='sigmoid' if num_classes == 1 else 'softmax',\n",
        "        padding='same',\n",
        "        name='output_layer'\n",
        "        )\n",
        "    self.output_layer11 = tf.keras.layers.Conv2D(\n",
        "        filters=num_classes,\n",
        "        kernel_size=(1,1),\n",
        "        activation='sigmoid' if num_classes == 1 else 'softmax',\n",
        "        padding='same',\n",
        "        name='output_layer'\n",
        "        )\n",
        "\n",
        "  def call(self, convs_cont , pool_cont):\n",
        "    f1,f2,f3,f4 = convs_cont\n",
        "    p1,p2,p3,p4 = pool_cont\n",
        "    for i, feat in enumerate([f1, f2, f3, f4, p1, p2, p3, p4]):\n",
        "        if feat.shape[1] < 1 or feat.shape[2] < 1:\n",
        "            print(f\"Warning: Feature map {i} has invalid dimensions: {feat.shape}\")\n",
        "    p5 = self.bottle_neck(p4)\n",
        "    decoder41 = self.decoder41(f4,p5)\n",
        "    decoder31 = self.decoder31(f3,p4)\n",
        "    conc32 = self.concat32([f3 , decoder31])\n",
        "    decoder32 = self.decoder32(conc32 , decoder41)\n",
        "    decoder21 = self.decoder21(f2,p3)\n",
        "    conc22 = self.concat22([f2,decoder21])\n",
        "    decoder22 = self.decoder22(conc22 , decoder31)\n",
        "    conc23 = self.concat23([f2,decoder21, decoder22])\n",
        "    decoder23 = self.decoder23(conc23 , decoder32)\n",
        "    decoder11 = self.decoder11(f1,p2)\n",
        "    conc12 = self.concat12([f1,decoder11])\n",
        "    decoder12 = self.decoder12(conc12 , decoder21)\n",
        "    conc13 = self.concat13([f1,decoder11,decoder12])\n",
        "    decoder13 = self.decoder13(conc13 , decoder22)\n",
        "    conc14 = self.concat14([f1 , decoder11  , decoder12 , decoder13])\n",
        "    decoder14 = self.decoder14(conc14 , decoder23)\n",
        "    output14 = self.output_layer14(decoder14)\n",
        "    output13 = self.output_layer13(decoder13)\n",
        "    output12 = self.output_layer12(decoder12)\n",
        "    output11 = self.output_layer11(decoder11)\n",
        "    return output11,output12,output13,output14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_QbqnnYvIS-v"
      },
      "outputs": [],
      "source": [
        "class Unet_plus_plus(tf.keras.models.Model):\n",
        "    def __init__(self, min_input_size=16):\n",
        "        super().__init__()\n",
        "        self.min_input_size = min_input_size\n",
        "        self.encoder = Encoder_for_unt_plus_plus()\n",
        "        self.decoder = Decoder_for_unet_plus_plus()\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        input_shape = inputs.shape\n",
        "        if input_shape[1] < self.min_input_size or input_shape[2] < self.min_input_size:\n",
        "            raise ValueError(f\"Input image dimensions must be at least {self.min_input_size}x{self.min_input_size}\")\n",
        "\n",
        "        y, z = self.encoder(inputs)\n",
        "        output11, output12, output13, output14 = self.decoder(y, z)\n",
        "        return output11, output12, output13, output14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "QhvmJp5cJ86_"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  unet_plus_plus = Unet_plus_plus()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYo7fCzYMLoO"
      },
      "source": [
        "**testing code for model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG9N7x9NpFX8"
      },
      "source": [
        "**defining loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Zgqf26VNpmJO"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "\n",
        "  class DiceLoss(tf.keras.losses.Loss):\n",
        "      def __init__(self, smooth=1e-6):\n",
        "          super().__init__()\n",
        "          self.smooth = smooth\n",
        "\n",
        "      def call(self, y_true, y_pred):\n",
        "          y_true = tf.squeeze(y_true, axis=-1)\n",
        "          y_true_f = tf.keras.backend.flatten(tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[-1]))\n",
        "          y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "\n",
        "          intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "          denominator = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
        "\n",
        "          dice_loss = 1 - (2.0 * intersection + self.smooth) / (denominator + self.smooth)\n",
        "          return dice_loss\n",
        "\n",
        "  class SemanticSegmentationLoss(tf.keras.losses.Loss):\n",
        "      def __init__(self, alpha=1.0, beta=1.0):\n",
        "          super().__init__()\n",
        "          self.dice_loss = DiceLoss()\n",
        "          self.alpha = alpha\n",
        "          self.beta = beta\n",
        "\n",
        "      def call(self, y_true, y_pred):\n",
        "          ce = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
        "          dice_loss = self.dice_loss(y_true, y_pred)\n",
        "          return self.alpha * ce + self.beta * dice_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "VLllqFTgQm4p"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  class DeepSupervisionLoss(tf.keras.losses.Loss):\n",
        "      def __init__(self, weights=None, smooth=1e-6):\n",
        "          super().__init__()\n",
        "          self.smooth = smooth\n",
        "          self.weights = weights or [1.0]\n",
        "          self.ce_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "      def dice_loss(self, y_true, y_pred):\n",
        "          y_true = tf.squeeze(y_true, axis=-1)\n",
        "          num_classes = tf.shape(y_pred)[-1]\n",
        "          y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=num_classes)\n",
        "          intersection = tf.reduce_sum(y_true_one_hot * y_pred, axis=[1, 2])\n",
        "          denominator = tf.reduce_sum(y_true_one_hot, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
        "          return 1 - (2.0 * intersection + self.smooth) / (denominator + self.smooth)\n",
        "\n",
        "      def call(self, y_true, y_pred):\n",
        "          total_loss = 0.0\n",
        "          num_outputs = len(y_pred)\n",
        "          self.weights = self.weights[:num_outputs] + [1.0] * (num_outputs - len(self.weights))\n",
        "          for i in range(num_outputs):\n",
        "              ce = self.ce_loss(y_true, y_pred[i])\n",
        "              dice = self.dice_loss(y_true, y_pred[i])\n",
        "              total_loss += self.weights[i] * (ce + dice)\n",
        "          return total_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "SGS2N0sJsZWd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqLy6d_fQqWr"
      },
      "source": [
        "**IOU metric**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "fyxUTVNmwvIY"
      },
      "outputs": [],
      "source": [
        "class IOUMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, n_classes=19, smooth=1e-6, name=\"iou\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.n_classes = n_classes\n",
        "        self.smooth = smooth\n",
        "        self.iou_sum = self.add_weight(name=\"iou_sum\", initializer=\"zeros\")\n",
        "        self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n",
        "    @tf.function\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_true = tf.squeeze(y_true, axis=-1)\n",
        "        y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=self.n_classes)\n",
        "        # y_pred = tf.nn.softmax(y_pred, axis=-1)\n",
        "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "\n",
        "        intersection = tf.reduce_sum(y_true * y_pred, axis=[0, 1, 2])\n",
        "        union = tf.reduce_sum(y_true, axis=[0, 1, 2]) + tf.reduce_sum(y_pred, axis=[0, 1, 2]) - intersection\n",
        "\n",
        "\n",
        "        iou_per_class = (intersection + self.smooth) / (union + self.smooth)\n",
        "\n",
        "\n",
        "        valid_classes = tf.cast(union > 0, tf.float32)\n",
        "        num_valid_classes = tf.reduce_sum(valid_classes)\n",
        "\n",
        "\n",
        "        mean_iou = tf.reduce_sum(iou_per_class * valid_classes) / tf.maximum(num_valid_classes, 1.0)\n",
        "\n",
        "\n",
        "        self.iou_sum.assign_add(mean_iou)\n",
        "        self.count.assign_add(1)\n",
        "\n",
        "    def result(self):\n",
        "        return self.iou_sum / tf.maximum(self.count, 1.0)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.iou_sum.assign(0)\n",
        "        self.count.assign(0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"n_classes\": self.n_classes, \"smooth\": self.smooth})\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb5ZLJrUQxgx"
      },
      "source": [
        "**per class IOU metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "XVQfJePV-tjG"
      },
      "outputs": [],
      "source": [
        "class PerClassIOUMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, n_classes=19, smooth=1e-6, name=\"iou_per_class\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.n_classes = n_classes\n",
        "        self.smooth = smooth\n",
        "        self.sum_union = self.add_weight(name=\"sum_union\", shape=(n_classes,), initializer=\"zeros\")\n",
        "        self.sum_intersection = self.add_weight(name=\"sum_intersection\", shape=(n_classes,), initializer=\"zeros\")\n",
        "    @tf.function\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_true = tf.squeeze(y_true, axis=-1)\n",
        "        y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.n_classes)\n",
        "        y_pred = tf.cast(y_pred , dtype = tf.float32 )\n",
        "\n",
        "        intersection = tf.reduce_sum(y_true * y_pred, axis=[0, 1, 2])\n",
        "        union = tf.reduce_sum(y_true, axis=[0, 1, 2]) + tf.reduce_sum(y_pred, axis=[0, 1, 2]) - intersection\n",
        "\n",
        "\n",
        "        self.sum_union.assign_add(union)\n",
        "        self.sum_intersection.assign_add(intersection)\n",
        "    @tf.function\n",
        "    def result(self):\n",
        "        return (self.sum_intersection + self.smooth) / (self.sum_union + self.smooth)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.sum_intersection.assign(tf.zeros_like(self.sum_intersection))\n",
        "        self.sum_union.assign(tf.zeros_like(self.sum_union))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI8rv85Uic1C"
      },
      "source": [
        "**Dice Coeficient Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "UVd2Y6GxVtPl"
      },
      "outputs": [],
      "source": [
        "class Dice_Coefficent_matrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, n_classes=19, smooth=1e-6, name='dice_coefficient', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.n_classes = n_classes\n",
        "        self.smooth = smooth\n",
        "\n",
        "        self.sum_dice_coefficent = self.add_weight(name=\"sum_dice_coefficent\", initializer=\"zeros\", dtype=tf.float32)\n",
        "        self.count = self.add_weight(name=\"count\", initializer=\"zeros\", dtype=tf.float32)\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "\n",
        "        y_true = tf.squeeze(y_true, axis=-1)\n",
        "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "        y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=self.n_classes)\n",
        "\n",
        "\n",
        "        intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
        "        total_area = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
        "\n",
        "\n",
        "        dice_score = 2 * (intersection + self.smooth) / (total_area + self.smooth)\n",
        "\n",
        "\n",
        "        dice_score = tf.reduce_mean(dice_score, axis=-1)\n",
        "\n",
        "\n",
        "        mean_dice = tf.reduce_mean(dice_score)\n",
        "\n",
        "\n",
        "        self.sum_dice_coefficent.assign_add(mean_dice)\n",
        "        self.count.assign_add(1.0)\n",
        "\n",
        "\n",
        "    def result(self):\n",
        "        return self.sum_dice_coefficent / tf.maximum(self.count, 1.0)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.sum_dice_coefficent.assign(0.0)\n",
        "        self.count.assign(0.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLNA7ijum2vZ"
      },
      "source": [
        "**per class_dice_coefficent metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "qd-b0q9nmYZd"
      },
      "outputs": [],
      "source": [
        "class PerClassDiceCoefficientMatrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, n_classes=19, smooth=1e-6, name=\"dice_per_class\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.n_classes = n_classes\n",
        "        self.smooth = smooth\n",
        "        self.sum_intersection = self.add_weight(name=\"sum_intersection\", shape=(n_classes,), initializer=\"zeros\")\n",
        "        self.sum_union = self.add_weight(name=\"sum_union\", shape=(n_classes,), initializer=\"zeros\")\n",
        "    @tf.function\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_true = tf.squeeze(y_true, axis=-1)\n",
        "        y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.n_classes)\n",
        "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "        intersection = tf.reduce_sum(y_true * y_pred, axis=[0, 1, 2])\n",
        "        sum_areas = tf.reduce_sum(y_true, axis=[0, 1, 2]) + tf.reduce_sum(y_pred, axis=[0, 1, 2])\n",
        "\n",
        "        self.sum_intersection.assign_add(intersection)\n",
        "        self.sum_union.assign_add(sum_areas)\n",
        "\n",
        "    def result(self):\n",
        "        return (2.0 * self.sum_intersection + self.smooth) / (self.sum_union + self.smooth)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.sum_intersection.assign(tf.zeros_like(self.sum_intersection))\n",
        "        self.sum_union.assign(tf.zeros_like(self.sum_union))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkxRcmDDnKth"
      },
      "source": [
        "**Pixel Accurcy Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "boqIP7CWm8Gy"
      },
      "outputs": [],
      "source": [
        "class Pixel_accurcy_metrics(tf.keras.metrics.Metric):\n",
        "  def __init__(self, n_classes=19, name=\"pixel_accuracy\", **kwargs):\n",
        "    super().__init__(name=name, **kwargs)\n",
        "    self.n_classes = n_classes\n",
        "    self.sum_pixel_wise_accurcy = self.add_weight(name=\"sum_correct_pixels\", initializer=\"zeros\", dtype=tf.float32)\n",
        "    self.count = self.add_weight(name=\"total_pixels\", initializer=\"zeros\", dtype=tf.float32)\n",
        "\n",
        "  @tf.function\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    y_true = tf.squeeze(y_true, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "    y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=self.n_classes)\n",
        "    y_pred = tf.one_hot(tf.argmax(y_pred, axis=-1), depth=self.n_classes)\n",
        "\n",
        "    correct_pixel = tf.reduce_sum(y_true * y_pred)\n",
        "    total_pixel = tf.reduce_prod(tf.shape(y_true)[:-1])\n",
        "\n",
        "\n",
        "    pixel_accuracy = correct_pixel / tf.maximum(tf.cast(total_pixel, tf.float32), 1.0)\n",
        "    self.sum_pixel_wise_accurcy.assign_add(pixel_accuracy)\n",
        "    self.count.assign_add(1)\n",
        "\n",
        "\n",
        "  def result(self):\n",
        "    return self.sum_pixel_wise_accurcy / tf.maximum(self.count, 1.0)\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.sum_pixel_wise_accurcy.assign(0)\n",
        "    self.count.assign(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbxDqaLiU2LZ"
      },
      "source": [
        "**optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "EkI53Row67bK"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    optimizer_fcn = mixed_precision.LossScaleOptimizer(\n",
        "        tf.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-5),\n",
        "        dynamic=True\n",
        "    )\n",
        "    optimizer_unet = mixed_precision.LossScaleOptimizer(\n",
        "        tf.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-5),\n",
        "        dynamic=True\n",
        "    )\n",
        "    optimizer_unet_plus_plus = mixed_precision.LossScaleOptimizer(\n",
        "        tf.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-5),\n",
        "        dynamic=True\n",
        "    )\n",
        "\n",
        "    # Explicitly build optimizer states\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j72q95Pjob9m"
      },
      "source": [
        "**checkPoint dirs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Jolqu8_FoelE"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir_fcn = '/content/drive/MyDrive/CityScapes_model_checkpoints/fcn'\n",
        "checkpoint_dir_unet = '/content/drive/MyDrive/CityScapes_model_checkpoints/unet'\n",
        "checkpoint_dir_unet_plus_plus = '/content/drive/MyDrive/CityScapes_model_checkpoints/unet_plus_plus'\n",
        "log_dir = '/content/drive/MyDrive/CityScapes_model_checkpoints/log_dir'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr83oImgE-T7"
      },
      "source": [
        "**custom callbacks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "az4V0gCqFDCt"
      },
      "outputs": [],
      "source": [
        "class Custom_checkpoint_Callabck(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, checkpoint_dir_fcn , checkpoint_dir_unet , checkpoint_dir_unet_plus_plus , fcn , unet , unet_plus_plus , optimizer_fcn ,optimizer_unet ,optimizer_unet_plus_plus  ) :\n",
        "    super().__init__()\n",
        "    self.checkpoint_dir_fcn = checkpoint_dir_fcn\n",
        "    self.checkpoint_dir_unet = checkpoint_dir_unet\n",
        "    self.checkpoint_dir_unet_plus_plus = checkpoint_dir_unet_plus_plus\n",
        "    self.checkpoint_fcn = tf.train.Checkpoint(\n",
        "        model = fcn ,\n",
        "        optimizer = optimizer_fcn,\n",
        "        epoch = tf.Variable(0 , dtype = tf.int64)\n",
        "    )\n",
        "    self.checkpoint_manager_for_fcn = tf.train.CheckpointManager(\n",
        "        self.checkpoint_fcn ,\n",
        "        self.checkpoint_dir_fcn ,\n",
        "        max_to_keep=3\n",
        "    )\n",
        "    self.checkpoint_unet = tf.train.Checkpoint(\n",
        "        model = unet ,\n",
        "        optimizer = optimizer_unet,\n",
        "        epoch = tf.Variable(0 , dtype = tf.int64)\n",
        "    )\n",
        "    self.checkpoint_manager_for_unet = tf.train.CheckpointManager(\n",
        "        self.checkpoint_unet ,\n",
        "        self.checkpoint_dir_unet ,\n",
        "        max_to_keep=3\n",
        "    )\n",
        "    self.checkpoint_unet_plus_plus = tf.train.Checkpoint(\n",
        "        model = unet_plus_plus ,\n",
        "        optimizer = optimizer_unet_plus_plus,\n",
        "        epoch = tf.Variable(0 , dtype = tf.int64)\n",
        "    )\n",
        "    self.checkpoint_manager_for_unet_plus_plus = tf.train.CheckpointManager(\n",
        "        self.checkpoint_unet_plus_plus ,\n",
        "        self.checkpoint_dir_unet_plus_plus ,\n",
        "        max_to_keep=3\n",
        "    )\n",
        "  def on_epoch_end(self , epoch, logs = None):\n",
        "    self.checkpoint_fcn.epoch.assign(epoch+1)\n",
        "    self.checkpoint_manager_for_fcn.save()\n",
        "    print(f\"\\nCheckpoint saved for epoch {epoch } at {self.checkpoint_manager_for_fcn.latest_checkpoint} for fcn model\")\n",
        "    self.checkpoint_unet.epoch.assign(epoch+1)\n",
        "    self.checkpoint_manager_for_unet.save()\n",
        "    print(f\"\\nCheckpoint saved for epoch {epoch } at {self.checkpoint_manager_for_unet.latest_checkpoint} for unet model\")\n",
        "    self.checkpoint_unet_plus_plus.epoch.assign(epoch+1)\n",
        "    self.checkpoint_manager_for_unet_plus_plus.save()\n",
        "    print(f\"\\nCheckpoint saved for epoch {epoch } at {self.checkpoint_manager_for_unet_plus_plus.latest_checkpoint} for unet_plus_plus model\")\n",
        "  def load_latest_model(self):\n",
        "    if self.checkpoint_manager_for_fcn.latest_checkpoint and self.checkpoint_manager_for_unet.latest_checkpoint and self.checkpoint_manager_for_unet_plus_plus.latest_checkpoint :\n",
        "\n",
        "      self.checkpoint_fcn.restore(self.checkpoint_manager_for_fcn.latest_checkpoint)\n",
        "      self.checkpoint_unet.restore(self.checkpoint_manager_for_unet.latest_checkpoint)\n",
        "      self.checkpoint_unet_plus_plus.restore(self.checkpoint_manager_for_unet_plus_plus.latest_checkpoint)\n",
        "      start_epoch =self.checkpoint_fcn.epoch.numpy()\n",
        "      print(f\"Restored from checkpoint: {self.checkpoint_manager_for_fcn.latest_checkpoint}, \"\n",
        "                  f\"resuming from epoch {start_epoch}\")\n",
        "      print(f\"Restored from checkpoint: {self.checkpoint_manager_for_unet.latest_checkpoint}, \"\n",
        "                  f\"resuming from epoch {start_epoch}\")\n",
        "      print(f\"Restored from checkpoint: {self.checkpoint_manager_for_unet_plus_plus.latest_checkpoint}, \"\n",
        "                  f\"resuming from epoch {start_epoch}\")\n",
        "      return start_epoch\n",
        "    else :\n",
        "      print('no checkpoint found starting from epoch 1')\n",
        "      return 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "_m7da_J8G566"
      },
      "outputs": [],
      "source": [
        "class Custom_early_stopping_callback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, paticance = 15  , min_delta = 1e-4):\n",
        "    self.patiance = paticance\n",
        "    self.min_delta = min_delta\n",
        "    self.best_loss = {\n",
        "        'fcn' : float('inf') ,\n",
        "        'unet' : float('inf') ,\n",
        "        'unet_plus_plus' : float('inf')\n",
        "    }\n",
        "    self.stoped_epoch = 0\n",
        "    self.wait = {\n",
        "        'fcn' : 0 ,\n",
        "        'unet': 0 ,\n",
        "        'unet_plus_plus' : 0\n",
        "    }\n",
        "  def early_stoping(self, epoch , val_loss):\n",
        "    if (val_loss['fcn']< self.best_loss['fcn']-self.min_delta):\n",
        "      self.best_loss['fcn'] = val_loss['fcn']\n",
        "      self.wait['fcn'] = 0\n",
        "    else :\n",
        "      self.wait['fcn'] +=1\n",
        "    if (val_loss['unet']< self.best_loss['unet']-self.min_delta):\n",
        "      self.best_loss['unet'] = val_loss['unet']\n",
        "      self.wait['unet'] = 0\n",
        "    else  :\n",
        "      self.wait['unet']+=1\n",
        "    if (val_loss['unet_plus_plus']< self.best_loss['unet_plus_plus']-self.min_delta):\n",
        "      self.best_loss['unet_plus_plus'] = val_loss['unet_plus_plus']\n",
        "      self.wait['unet_plus_plus'] = 0\n",
        "    else :\n",
        "      self.wait['unet_plus_plus']+=1\n",
        "    if self.wait['fcn'] > self.patiance and self.wait['unet']>self.patiance and self.wait['unet_plus_plus']>self.patiance:\n",
        "      self.stoped_epoch  =epoch\n",
        "      print (f'early stoping trainig at {self.stoped_epoch}')\n",
        "      return True\n",
        "    return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "NGFZO7E5UMgH"
      },
      "outputs": [],
      "source": [
        "class Custom_learning_rate_schedule(tf.keras.callbacks.Callback):\n",
        "  def __init__(self , optimizer_fcn , optimizer_unet , optimizer_unet_plus_plus , factor = 0.5 , patiance = 5 , min_delta = 1e-4 , min_lr = 1e-8 ):\n",
        "    super().__init__()\n",
        "    self.factor = factor\n",
        "    self.patiance = patiance\n",
        "    self.min_delta = min_delta\n",
        "    self.min_lr = min_lr\n",
        "    self.best_val_loss = {\n",
        "        'fcn' : float('inf') ,\n",
        "        'unet': float('inf') ,\n",
        "        'unet_plus_plus' : float('inf')\n",
        "    }\n",
        "    self.optimzer  = {\n",
        "        'fcn' : optimizer_fcn ,\n",
        "        'unet' : optimizer_fcn ,\n",
        "        'unet_plus_plus': optimizer_unet_plus_plus\n",
        "    }\n",
        "    self.wait = {\n",
        "        'fcn' : 0 ,\n",
        "        'unet': 0 ,\n",
        "        'unet_plus_plus' : 0\n",
        "    }\n",
        "  def change_learning_rate(self, epoch , val_loss):\n",
        "    for model_name , val_loss in val_loss.items():\n",
        "      if val_loss < self.best_val_loss[model_name]-self.min_delta:\n",
        "        self.best_val_loss[model_name] = val_loss\n",
        "        self.wait[model_name] = 0\n",
        "      else :\n",
        "        self.wait[model_name] +=1\n",
        "      if self.wait[model_name] >= self.patiance :\n",
        "        old_lr = self.optimzer[model_name].lr.numpy()\n",
        "        new_lr = tf.maximum(old_lr*self.factor , self.min_lr)\n",
        "        self.optimzer[model_name].lr.assign(new_lr)\n",
        "        print (f'learning rate for model : {model_name} has been change from : {old_lr} to the new lr : {new_lr} at epoch : {epoch}')\n",
        "        self.wait= 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "wOdDahlsAFkl"
      },
      "outputs": [],
      "source": [
        "class Custom_Training_logger_callback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, batches_per_epoch):\n",
        "    super().__init__()\n",
        "    self.model_name = ['fcn' , 'unet' , 'unet_plus_plus']\n",
        "    self.batch_per_epoch = batches_per_epoch\n",
        "    self.batch_table_display = None\n",
        "    self.graph_display = None\n",
        "  def On_epoch_begin(self, epoch ):\n",
        "    print(f'Epoch begins : {epoch}')\n",
        "    self.progress_bar = tqdm(total=self.batch_per_epoch,desc=f'epoch {epoch}')\n",
        "    self.batch_table_data = []\n",
        "    self.batch_loss = {\n",
        "        'fcn':[] ,\n",
        "        'unet': [] ,\n",
        "        'unet_plus_plus' :[]\n",
        "    }\n",
        "\n",
        "    self.epoch_table_data = []\n",
        "    display(HTML('<h3>📊 Batch-wise Loss Table</h3>'))\n",
        "\n",
        "\n",
        "  def on_batch_end(self, batch , epoch,data = None):\n",
        "    self.progress_bar.set_postfix({\n",
        "        f'epoch :{epoch} , batch ': batch / self.batch_per_epoch\n",
        "        })\n",
        "    self.progress_bar.update(1)\n",
        "    if data == None :\n",
        "      return\n",
        "    self.batch_table_data.append({\n",
        "        'batch': batch ,\n",
        "        'fcn_loss' : data['fcn']['loss'] ,\n",
        "\n",
        "        'unet_loss' :data['unet']['loss'],\n",
        "\n",
        "        'unet_plus_plus_loss' : data['unet_plus_plus']['loss']  ,\n",
        "\n",
        "        'fcn_IOUMetric' : data['fcn']['metrics']['IOUMetric'] ,\n",
        "        'fcn_PerClassIOUMetric' : data['fcn']['metrics']['PerClassIOUMetric'],\n",
        "        'fcn_Dice_Coefficent_matrics' :  data['fcn']['metrics']['Dice_Coefficent_matrics'],\n",
        "        'fcn_PerClassDiceCoefficientMatrics' : data['fcn']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "        'fcn_Pixel_accurcy_metrics' : data['fcn']['metrics']['Pixel_accurcy_metrics'],\n",
        "        'unet_IOUMetric' : data['unet']['metrics']['IOUMetric'] ,\n",
        "        'unet_PerClassIOUMetric' : data['unet']['metrics']['PerClassIOUMetric'],\n",
        "        'unet_Dice_Coefficent_matrics' :  data['unet']['metrics']['Dice_Coefficent_matrics'],\n",
        "        'unet_PerClassDiceCoefficientMatrics' : data['unet']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "        'unet_Pixel_accurcy_metrics' : data['unet']['metrics']['Pixel_accurcy_metrics'],\n",
        "        'unet_plus_plus_IOUMetric' : data['unet_plus_plus']['metrics']['IOUMetric'] ,\n",
        "        'unet_plus_plus_PerClassIOUMetric' : data['unet_plus_plus']['metrics']['PerClassIOUMetric'],\n",
        "        'unet_plus_plus_Dice_Coefficent_matrics' :  data['unet_plus_plus']['metrics']['Dice_Coefficent_matrics'],\n",
        "        'unet_plus_plus_PerClassDiceCoefficientMatrics' : data['unet_plus_plus']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "        'unet_plus_plus_Pixel_accurcy_metrics' : data['unet_plus_plus']['metrics']['Pixel_accurcy_metrics'],\n",
        "\n",
        "      })\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(self.batch_table_data)\n",
        "\n",
        "    if self.batch_table_display is None:\n",
        "      self.batch_table_display = display( df, display_id=True)\n",
        "    else :\n",
        "      self.batch_table_display.update(df)\n",
        "    self.batch_loss['fcn'].append(data['fcn']['loss'])\n",
        "    self.batch_loss['unet'].append(data['unet']['loss'])\n",
        "    self.batch_loss['unet_plus_plus'].append(data['unet_plus_plus']['loss'])\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    axes[0].plot(self.batch_loss['fcn'], label='FCN Loss', marker='o')\n",
        "    axes[0].plot(self.batch_loss['unet'], label='U-Net Loss', marker='o')\n",
        "    axes[0].plot(self.batch_loss['unet_plus_plus'], label='U-Net++ Loss', marker='o')\n",
        "    axes[0].set_title('Training Loss')\n",
        "    axes[0].set_xlabel('Batch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if self.graph_display is None:\n",
        "      display(HTML('<h3>📉 Loss Graphs (Batch-wise Trend)</h3>'))\n",
        "      self.graph_display = display(fig, display_id=True)\n",
        "    else:\n",
        "      self.graph_display.update(fig)\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "  def on_epoch_end(self , epoch ,data):\n",
        "    self.progress_bar.close()\n",
        "    if data == None :\n",
        "      return\n",
        "    display(HTML('<h3>📊 Epoch Summary Table</h3>'))\n",
        "    self.epoch_table_data.append({\n",
        "        'epoch': epoch ,\n",
        "        'fcn_loss' : data['fcn']['loss'] ,\n",
        "        'fcn_val_loss':data['fcn']['val_loss'] ,\n",
        "        'unet_loss' :data['unet']['loss'],\n",
        "        'unet_val_loss' : data['unet']['val_loss'] ,\n",
        "        'unet_plus_plus_loss' : data['unet_plus_plus']['loss']  ,\n",
        "        'unet_plus_plus_val_loss' : data['unet_plus_plus']['val_loss'],\n",
        "        'fcn_IOUMetric' : data['fcn']['metrics']['IOUMetric'] ,\n",
        "        'fcn_PerClassIOUMetric' : data['fcn']['metrics']['PerClassIOUMetric'],\n",
        "        'fcn_Dice_Coefficent_matrics' :  data['fcn']['metrics']['Dice_Coefficent_matrics'],\n",
        "        'fcn_PerClassDiceCoefficientMatrics' : data['fcn']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "        'fcn_Pixel_accurcy_metrics' : data['fcn']['metrics']['Pixel_accurcy_metrics'],\n",
        "        'unet_IOUMetric' : data['unet']['metrics']['IOUMetric'] ,\n",
        "        'unet_PerClassIOUMetric' : data['unet']['metrics']['PerClassIOUMetric'],\n",
        "        'unet_Dice_Coefficent_matrics' :  data['unet']['metrics']['Dice_Coefficent_matrics'],\n",
        "        'unet_PerClassDiceCoefficientMatrics' : data['unet']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "        'unet_Pixel_accurcy_metrics' : data['unet']['metrics']['Pixel_accurcy_metrics'],\n",
        "        'unet_plus_plus_IOUMetric' : data['unet_plus_plus']['metrics']['IOUMetric'] ,\n",
        "        'unet_plus_plus_PerClassIOUMetric' : data['unet_plus_plus']['metrics']['PerClassIOUMetric'],\n",
        "        'unet_plus_plus_Dice_Coefficent_matrics' :  data['unet_plus_plus']['metrics']['Dice_Coefficent_matrics'],\n",
        "        'unet_plus_plus_PerClassDiceCoefficientMatrics' : data['unet_plus_plus']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "        'unet_plus_plus_Pixel_accurcy_metrics' : data['unet_plus_plus']['metrics']['Pixel_accurcy_metrics'],\n",
        "\n",
        "        'fcn_IOUMetric_val' : data['fcn']['metrics']['IOUMetric_val'] ,\n",
        "        'fcn_PerClassIOUMetric_val' : data['fcn']['metrics']['PerClassIOUMetric_val'],\n",
        "        'fcn_Dice_Coefficent_matrics_val' :  data['fcn']['metrics']['Dice_Coefficent_matrics_val'],\n",
        "        'fcn_PerClassDiceCoefficientMatrics_val' : data['fcn']['metrics']['PerClassDiceCoefficientMatrics_val'],\n",
        "        'fcn_Pixel_accurcy_metrics_val' : data['fcn']['metrics']['Pixel_accurcy_metrics_val'],\n",
        "        'unet_IOUMetric_val' : data['unet']['metrics']['IOUMetric_val'] ,\n",
        "        'unet_PerClassIOUMetric_val' : data['unet']['metrics']['PerClassIOUMetric_val'],\n",
        "        'unet_Dice_Coefficent_matrics_val' :  data['unet']['metrics']['Dice_Coefficent_matrics_val'],\n",
        "        'unet_PerClassDiceCoefficientMatrics_val' : data['unet']['metrics']['PerClassDiceCoefficientMatrics_val'],\n",
        "        'unet_Pixel_accurcy_metrics_val' : data['unet']['metrics']['Pixel_accurcy_metrics_val'],\n",
        "        'unet_plus_plus_IOUMetric_val' : data['unet_plus_plus']['metrics']['IOUMetric_val'] ,\n",
        "        'unet_plus_plus_PerClassIOUMetric_val' : data['unet_plus_plus']['metrics']['PerClassIOUMetric_val'],\n",
        "        'unet_plus_plus_Dice_Coefficent_matrics_val' :  data['unet_plus_plus']['metrics']['Dice_Coefficent_matrics_val'],\n",
        "        'unet_plus_plus_PerClassDiceCoefficientMatrics_val' : data['unet_plus_plus']['metrics']['PerClassDiceCoefficientMatrics_val'],\n",
        "        'unet_plus_plus_Pixel_accurcy_metrics_val' : data['unet_plus_plus']['metrics']['Pixel_accurcy_metrics_val'],\n",
        "      })\n",
        "    df=pd.DataFrame(self.epoch_table_data)\n",
        "    display(df)\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    axes[0].plot(self.batch_loss['fcn'], label='FCN Loss', marker='o')\n",
        "    axes[0].plot(self.batch_loss['unet'], label='U-Net Loss', marker='o')\n",
        "    axes[0].plot(self.batch_loss['unet_plus_plus'], label='U-Net++ Loss', marker='o')\n",
        "    axes[0].set_title('Training Loss')\n",
        "    axes[0].set_xlabel('Batch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    display(HTML(f'<h3>📉 Final Loss Graphs - Epoch {epoch + 1}</h3>'))\n",
        "    self.final_graph_display = display(fig, display_id=f'final_graph_epoch_{epoch + 1}')\n",
        "    plt.close(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "lZb3PnfxLOWu"
      },
      "outputs": [],
      "source": [
        "class Master_callback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, log_dir , checkpoint_dir_fcn , checkpoint_dir_unet ,                 checkpoint_dir_unet_plus_plus , fcn , unet , unet_plus_plus , optimizer_fcn ,optimizer_unet ,   optimizer_unet_plus_plus , batches_per_epoch  ):\n",
        "    self.writer=tf.summary.create_file_writer(logdir=log_dir)\n",
        "    # initilizing custom checkpoint callback\n",
        "    self.ccc = Custom_checkpoint_Callabck(checkpoint_dir_fcn=checkpoint_dir_fcn,checkpoint_dir_unet=checkpoint_dir_unet , checkpoint_dir_unet_plus_plus=checkpoint_dir_unet_plus_plus , fcn = fcn , unet = unet , unet_plus_plus=unet_plus_plus , optimizer_fcn=optimizer_fcn , optimizer_unet=optimizer_unet , optimizer_unet_plus_plus=optimizer_unet_plus_plus )\n",
        "    # initilizing custom ealry stoping callback\n",
        "    self.cesc = Custom_early_stopping_callback()\n",
        "    # initilizing custom learning rate scheduler\n",
        "    self.clrs = Custom_learning_rate_schedule(optimizer_fcn=optimizer_fcn , optimizer_unet=optimizer_unet , optimizer_unet_plus_plus=optimizer_unet_plus_plus)\n",
        "    # initilizing custom training logger\n",
        "    self.ctlc = Custom_Training_logger_callback(batches_per_epoch=batches_per_epoch)\n",
        "    self.stop = False\n",
        "\n",
        "  def on_train_begin(self):\n",
        "    return self.ccc.load_latest_model()\n",
        "  def on_epoch_begin(self, epoch ):\n",
        "    self.ctlc.On_epoch_begin(epoch)\n",
        "  def on_batch_end(self,batch , epoch , data):\n",
        "    self.ctlc.on_batch_end(batch , epoch , data)\n",
        "  def on_epoch_end(self, epoch , data):\n",
        "    self.ctlc.on_epoch_end(epoch , data)\n",
        "    # summary -->\n",
        "    with self.writer.as_default():\n",
        "      tf.summary.scalar('fcn_loss' , data['fcn']['loss'],step=epoch)\n",
        "      tf.summary.scalar('fcn_val_loss' , data['fcn']['val_loss'],step=epoch)\n",
        "      tf.summary.scalar('unet_loss' , data['unet']['loss'],step=epoch)\n",
        "      tf.summary.scalar('uent_val_loss' , data['unet']['val_loss'],step=epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_loss' , data['unet_plus_plus']['loss'],step=epoch)\n",
        "      tf.summary.scalar('uent_plus_plus_val_loss' , data['unet_plus_plus']['val_loss'],step=epoch)\n",
        "      tf.summary.scalar('fcn_IOUMetric',data['fcn']['metrics']['IOUMetric'] , step = epoch)\n",
        "      tf.summary.scalar('fcn_PerClassIOUMetric' , data['fcn']['metrics']['PerClassIOUMetric'] , step = epoch)\n",
        "      tf.summary.scalar('fcn_Dice_Coefficent_matrics' ,  data['fcn']['metrics']['Dice_Coefficent_matrics'] , step = epoch)\n",
        "      tf.summary.scalar('fcn_PerClassDiceCoefficientMatrics' , data['fcn']['metrics']['PerClassDiceCoefficientMatrics'] , step = epoch)\n",
        "      tf.summary.scalar('fcn_Pixel_accurcy_metrics' , data['fcn']['metrics']['Pixel_accurcy_metrics'], step = epoch)\n",
        "\n",
        "      tf.summary.scalar('unet_IOUMetric',data['unet']['metrics']['IOUMetric'] , step = epoch)\n",
        "      tf.summary.scalar('unet_PerClassIOUMetric' , data['unet']['metrics']['PerClassIOUMetric'] , step = epoch)\n",
        "      tf.summary.scalar('unet_Dice_Coefficent_matrics' ,  data['unet']['metrics']['Dice_Coefficent_matrics'] , step = epoch)\n",
        "      tf.summary.scalar('unet_PerClassDiceCoefficientMatrics' , data['unet']['metrics']['PerClassDiceCoefficientMatrics'] , step = epoch)\n",
        "      tf.summary.scalar('unet_Pixel_accurcy_metrics' , data['unet']['metrics']['Pixel_accurcy_metrics'], step = epoch)\n",
        "\n",
        "      tf.summary.scalar('unet_plus_plus_IOUMetric',data['unet_plus_plus']['metrics']['IOUMetric'] , step = epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_PerClassIOUMetric' , data['unet_plus_plus']['metrics']['PerClassIOUMetric'] , step = epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_Dice_Coefficent_matrics' ,  data['unet_plus_plus']['metrics']['Dice_Coefficent_matrics'] , step = epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_PerClassDiceCoefficientMatrics' , data['unet_plus_plus']['metrics']['PerClassDiceCoefficientMatrics'] , step = epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_Pixel_accurcy_metrics' , data['unet_plus_plus']['metrics']['Pixel_accurcy_metrics'], step = epoch)\n",
        "\n",
        "      tf.summary.scalar('fcn_IOUMetric_val',data['fcn']['metrics']['IOUMetric_val'] , step = epoch)\n",
        "      tf.summary.scalar('fcn_PerClassIOUMetric_val' , data['fcn']['metrics']['PerClassIOUMetric_val'] , step = epoch)\n",
        "      tf.summary.scalar('fcn_Dice_Coefficent_matrics_val' ,  data['fcn']['metrics']['Dice_Coefficent_matrics_val'] , step = epoch)\n",
        "      tf.summary.scalar('fcn_PerClassDiceCoefficientMatrics_val' , data['fcn']['metrics']['PerClassDiceCoefficientMatrics_val'] , step = epoch)\n",
        "      tf.summary.scalar('fcn_Pixel_accurcy_metrics_val' , data['fcn']['metrics']['Pixel_accurcy_metrics_val'], step = epoch)\n",
        "\n",
        "      tf.summary.scalar('unet_IOUMetric_val',data['unet']['metrics']['IOUMetric_val'] , step = epoch)\n",
        "      tf.summary.scalar('unet_PerClassIOUMetric_val' , data['unet']['metrics']['PerClassIOUMetric_val'] , step = epoch)\n",
        "      tf.summary.scalar('unet_Dice_Coefficent_matrics_val' ,  data['unet']['metrics']['Dice_Coefficent_matrics_val'] , step = epoch)\n",
        "      tf.summary.scalar('unet_PerClassDiceCoefficientMatrics_val' , data['unet']['metrics']['PerClassDiceCoefficientMatrics_val'] , step = epoch)\n",
        "      tf.summary.scalar('unet_Pixel_accurcy_metrics_val' , data['unet']['metrics']['Pixel_accurcy_metrics__val'], step = epoch)\n",
        "\n",
        "      tf.summary.scalar('unet_plus_plus_IOUMetric_val',data['unet_plus_plus']['metrics']['IOUMetric_val'] , step = epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_PerClassIOUMetric_val' , data['unet_plus_plus']['metrics']['PerClassIOUMetric_val'] , step = epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_Dice_Coefficent_matrics_val' ,  data['unet_plus_plus']['metrics']['Dice_Coefficent_matrics_val'] , step = epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_PerClassDiceCoefficientMatrics_val' , data['unet_plus_plus']['metrics']['PerClassDiceCoefficientMatrics_val'] , step = epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_Pixel_accurcy_metrics_val' , data['unet_plus_plus']['metrics']['Pixel_accurcy_metrics_val'], step = epoch)\n",
        "    self.writer.flush()\n",
        "    self.ccc.on_epoch_end(epoch)\n",
        "    self.clrs.change_learning_rate(epoch ,{\n",
        "        'fcn' : data['fcn']['val_loss'] ,\n",
        "        'unet' :  data['unet']['val_loss'] ,\n",
        "        'unet_plus_plus' :  data['unet_plus_plus']['val_loss']\n",
        "    })\n",
        "    return self.cesc.early_stoping(epoch , {\n",
        "        'fcn' : data['fcn']['val_loss'] ,\n",
        "        'unet' :  data['unet']['val_loss'] ,\n",
        "        'unet_plus_plus' :  data['unet_plus_plus']['val_loss']\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugK4Tt5h7myZ"
      },
      "source": [
        "**initilizing instances**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  fcn_SemanticSegmentationLoss=SemanticSegmentationLoss()\n",
        "  unet_SemanticSegmentationLoss=SemanticSegmentationLoss()\n",
        "  deepSupervisionLoss=DeepSupervisionLoss(weights = [0.5, 0.3, 0.15, 0.05])"
      ],
      "metadata": {
        "id": "QZhkibVdihjv"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "QrB19aAPvme4"
      },
      "outputs": [],
      "source": [
        "batches_per_epoch = 372\n",
        "master_callback =Master_callback(log_dir=log_dir , checkpoint_dir_fcn=checkpoint_dir_fcn , checkpoint_dir_unet=checkpoint_dir_unet , checkpoint_dir_unet_plus_plus=checkpoint_dir_unet_plus_plus , fcn=fcn , unet = unet , unet_plus_plus=unet_plus_plus ,batches_per_epoch=batches_per_epoch ,optimizer_fcn=optimizer_fcn , optimizer_unet=optimizer_unet , optimizer_unet_plus_plus=optimizer_unet_plus_plus )\n",
        "\n",
        "\n",
        "\n",
        "# fcn matrics\n",
        "with strategy.scope() :\n",
        "  fcn_IOUMetric = IOUMetric()\n",
        "  fcn_PerClassIOUMetric = PerClassIOUMetric()\n",
        "  fcn_Dice_Coefficent_matrics = Dice_Coefficent_matrics()\n",
        "  fcn_PerClassDiceCoefficientMatrics = PerClassDiceCoefficientMatrics()\n",
        "  fcn_Pixel_accurcy_metrics  = Pixel_accurcy_metrics()\n",
        "\n",
        "  fcn_IOUMetric_val = IOUMetric()\n",
        "  fcn_PerClassIOUMetric_val = PerClassIOUMetric()\n",
        "  fcn_Dice_Coefficent_matrics_val = Dice_Coefficent_matrics()\n",
        "  fcn_PerClassDiceCoefficientMatrics_val = PerClassDiceCoefficientMatrics()\n",
        "  fcn_Pixel_accurcy_metrics_val  = Pixel_accurcy_metrics()\n",
        "\n",
        "  # unet matrics\n",
        "  unet_IOUMetric = IOUMetric()\n",
        "  unet_PerClassIOUMetric = PerClassIOUMetric()\n",
        "  unet_Dice_Coefficent_matrics = Dice_Coefficent_matrics()\n",
        "  unet_PerClassDiceCoefficientMatrics = PerClassDiceCoefficientMatrics()\n",
        "  unet_Pixel_accurcy_metrics  = Pixel_accurcy_metrics()\n",
        "\n",
        "  unet_IOUMetric_val = IOUMetric()\n",
        "  unet_PerClassIOUMetric_val = PerClassIOUMetric()\n",
        "  unet_Dice_Coefficent_matrics_val = Dice_Coefficent_matrics()\n",
        "  unet_PerClassDiceCoefficientMatrics_val = PerClassDiceCoefficientMatrics()\n",
        "  unet_Pixel_accurcy_metrics_val  = Pixel_accurcy_metrics()\n",
        "\n",
        "  # unet_plus_plus matrics\n",
        "  unet_plus_plus_IOUMetric = IOUMetric()\n",
        "  unet_plus_plus_PerClassIOUMetric = PerClassIOUMetric()\n",
        "  unet_plus_plus_Dice_Coefficent_matrics = Dice_Coefficent_matrics()\n",
        "  unet_plus_plus_PerClassDiceCoefficientMatrics = PerClassDiceCoefficientMatrics()\n",
        "  unet_plus_plus_Pixel_accurcy_metrics  = Pixel_accurcy_metrics()\n",
        "\n",
        "  unet_plus_plus_IOUMetric_val = IOUMetric()\n",
        "  unet_plus_plus_PerClassIOUMetric_val = PerClassIOUMetric()\n",
        "  unet_plus_plus_Dice_Coefficent_matrics_val = Dice_Coefficent_matrics()\n",
        "  unet_plus_plus_PerClassDiceCoefficientMatrics_val = PerClassDiceCoefficientMatrics()\n",
        "  unet_plus_plus_Pixel_accurcy_metrics_val  = Pixel_accurcy_metrics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBt10VB8kHRA"
      },
      "source": [
        "**custom training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "wDw20qT5HhDJ"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  @tf.function\n",
        "  def train_step(x_train_batch, y_train_batch):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      # tf.print(\"Input shapes - x:\", x_train_batch.shape, \"y:\", y_train_batch.shape)\n",
        "      fcn_logits = fcn(x_train_batch)\n",
        "      # tf.print(\"fcn_logits shape:\", fcn_logits.shape)\n",
        "      fcn_loss = fcn_SemanticSegmentationLoss(y_true=y_train_batch, y_pred=fcn_logits)\n",
        "      # tf.print(\"fcn_loss computed:\", fcn_loss)\n",
        "      unet_logits = unet(x_train_batch)\n",
        "      # tf.print(\"unet_logits shape:\", unet_logits.shape)\n",
        "      unet_loss = unet_SemanticSegmentationLoss(y_true=y_train_batch, y_pred=unet_logits)\n",
        "      # tf.print(\"unet_loss computed:\", unet_loss)\n",
        "      unet_plus_plus_outputs = unet_plus_plus(x_train_batch)\n",
        "      unet_plus_plus_loss = deepSupervisionLoss(y_true=y_train_batch, y_pred=unet_plus_plus_outputs)\n",
        "      unet_plus_plus_logits = unet_plus_plus_outputs[-1]\n",
        "      # tf.print(\"unet_plus_plus_logits shape:\", unet_plus_plus_logits.shape)\n",
        "\n",
        "    fcn_gradients = tape.gradient(fcn_loss, fcn.trainable_variables)\n",
        "    # tf.print(\"fcn_gradients computed, length:\", len(fcn_gradients))\n",
        "    unet_gradients = tape.gradient(unet_loss, unet.trainable_variables)\n",
        "    # tf.print(\"unet_gradients computed, length:\", len(unet_gradients))\n",
        "    unet_plus_plus_gradients = tape.gradient(unet_plus_plus_loss, unet_plus_plus.trainable_variables)\n",
        "    # tf.print(\"unet_plus_plus_gradients computed, length:\", len(unet_plus_plus_gradients))\n",
        "\n",
        "\n",
        "\n",
        "    optimizer_fcn.apply_gradients(zip(fcn_gradients,fcn.trainable_variables))\n",
        "    optimizer_unet.apply_gradients(zip(unet_gradients,unet.trainable_variables))\n",
        "    optimizer_unet_plus_plus.apply_gradients(zip(unet_plus_plus_gradients , unet_plus_plus.trainable_variables))\n",
        "\n",
        "    fcn_IOUMetric.update_state(y_true=y_train_batch, y_pred=fcn_logits)\n",
        "    fcn_PerClassIOUMetric.update_state(y_true=y_train_batch, y_pred=fcn_logits)\n",
        "    fcn_Dice_Coefficent_matrics.update_state(y_train_batch, fcn_logits)\n",
        "    fcn_PerClassDiceCoefficientMatrics.update_state(y_train_batch, fcn_logits)\n",
        "    fcn_Pixel_accurcy_metrics.update_state(y_train_batch, fcn_logits)\n",
        "\n",
        "    unet_IOUMetric.update_state(y_true=y_train_batch, y_pred=unet_logits)\n",
        "    unet_PerClassIOUMetric.update_state(y_true=y_train_batch, y_pred=unet_logits)\n",
        "    unet_Dice_Coefficent_matrics.update_state(y_train_batch, unet_logits)\n",
        "    unet_PerClassDiceCoefficientMatrics.update_state(y_train_batch, unet_logits)\n",
        "    unet_Pixel_accurcy_metrics.update_state(y_train_batch, unet_logits)\n",
        "\n",
        "    unet_plus_plus_IOUMetric.update_state(y_true=y_train_batch, y_pred=unet_plus_plus_logits)\n",
        "    unet_plus_plus_PerClassIOUMetric.update_state(y_true=y_train_batch, y_pred=unet_plus_plus_logits)\n",
        "    unet_plus_plus_Dice_Coefficent_matrics.update_state(y_train_batch, unet_plus_plus_logits)\n",
        "    unet_plus_plus_PerClassDiceCoefficientMatrics.update_state(y_train_batch, unet_plus_plus_logits)\n",
        "    unet_plus_plus_Pixel_accurcy_metrics.update_state(y_train_batch, unet_plus_plus_logits)\n",
        "\n",
        "    del tape\n",
        "    return {\n",
        "      'fcn_loss': fcn_loss,\n",
        "      'unet_loss': unet_loss,\n",
        "      'unet_plus_plus_loss' : unet_plus_plus_loss\n",
        "\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "sCgVkQwLZeyT"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  @tf.function\n",
        "  def val_step(x_val_batch,y_val_batch):\n",
        "    fcn_logits = fcn(x_val_batch)\n",
        "    fcn_val_loss = fcn_SemanticSegmentationLoss(y_true=y_val_batch,y_pred=fcn_logits)\n",
        "    unet_logits  = unet(x_val_batch)\n",
        "    unet_val_loss = unet_SemanticSegmentationLoss(y_true = y_val_batch,y_pred = unet_logits)\n",
        "    unet_plus_plus_logits = unet_plus_plus(x_val_batch)\n",
        "    unet_plus_plus_val_loss = deepSupervisionLoss(y_true = y_val_batch, y_pred = unet_plus_plus_logits)\n",
        "\n",
        "    fcn_IOUMetric_val.update_state(y_true=y_val_batch, y_pred=fcn_logits)\n",
        "    fcn_PerClassIOUMetric_val.update_state(y_true=y_val_batch, y_pred=fcn_logits)\n",
        "    fcn_Dice_Coefficent_matrics_val.update_state(y_val_batch, fcn_logits)\n",
        "    fcn_PerClassDiceCoefficientMatrics_val.update_state(y_val_batch, fcn_logits)\n",
        "    fcn_Pixel_accurcy_metrics_val.update_state(y_val_batch, fcn_logits)\n",
        "\n",
        "    unet_IOUMetric_val.update_state(y_true=y_val_batch, y_pred=unet_logits)\n",
        "    unet_PerClassIOUMetric_val.update_state(y_true=y_val_batch, y_pred=unet_logits)\n",
        "    unet_Dice_Coefficent_matrics_val.update_state(y_val_batch, unet_logits)\n",
        "    unet_PerClassDiceCoefficientMatrics_val.update_state(y_val_batch, unet_logits)\n",
        "    unet_Pixel_accurcy_metrics_val.update_state(y_val_batch, unet_logits)\n",
        "\n",
        "    unet_plus_plus_IOUMetric_val.update_state(y_true=y_val_batch, y_pred=unet_plus_plus_logits)\n",
        "    unet_plus_plus_PerClassIOUMetric_val.update_state(y_true=y_val_batch, y_pred=unet_plus_plus_logits)\n",
        "    unet_plus_plus_Dice_Coefficent_matrics_val.update_state(y_val_batch, unet_plus_plus_logits)\n",
        "    unet_plus_plus_PerClassDiceCoefficientMatrics_val.update_state(y_val_batch, unet_plus_plus_logits)\n",
        "    unet_plus_plus_Pixel_accurcy_metrics_val.update_state(y_val_batch, unet_plus_plus_logits)\n",
        "    return {\n",
        "        'fcn_val_loss' : fcn_val_loss ,\n",
        "        'unet_val_loss' : unet_val_loss ,\n",
        "        'unet_plus_plus_val_loss' : unet_plus_plus_val_loss\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "u90A1zGJ3rhE"
      },
      "outputs": [],
      "source": [
        "with strategy.scope() :\n",
        "  @tf.function\n",
        "  def distributed_train_step(x_train_batch , y_train_batch):\n",
        "    per_replica_results = strategy.run(train_step, args=(x_train_batch, y_train_batch))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    fcn_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN,per_replica_results['fcn_loss'],axis=None)\n",
        "    unet_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN,per_replica_results['unet_loss'],axis=None)\n",
        "    unet_plus_plus_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN,per_replica_results['unet_plus_plus_loss'],axis = None)\n",
        "\n",
        "    return {\n",
        "        'fcn' : fcn_loss ,\n",
        "        'unet' : unet_loss ,\n",
        "        'unet_plus_plus' : unet_plus_plus_loss\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "WJIzbVN0Wcnc"
      },
      "outputs": [],
      "source": [
        "with strategy.scope() :\n",
        "  @tf.function\n",
        "  def distributed_val_step(x_val_batch,y_val_batch):\n",
        "    per_replica_results = strategy.run(val_step , args = (x_val_batch,y_val_batch))\n",
        "    fcn_val_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN,per_replica_results['fcn_val_loss'] , axis = None)\n",
        "    unet_val_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN,per_replica_results['unet_val_loss'] , axis = None)\n",
        "    unet_plus_plus_val_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN,per_replica_results['unet_plus_plus_val_loss'] , axis = None)\n",
        "    return {\n",
        "        'fcn' : fcn_val_loss ,\n",
        "        'unet' : unet_val_loss ,\n",
        "        'unet_plus_plus' : unet_plus_plus_val_loss\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "_8Iz61nAft5x"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "\n",
        "  def train_model_for_one_epoch(epoch):\n",
        "    fcn_loss = []\n",
        "    unet_loss = []\n",
        "    unet_plus_plus_loss = []\n",
        "    for step  , (x_train_batch , y_train_batch) in enumerate (train_dataset):\n",
        "      losses=distributed_train_step(x_train_batch , y_train_batch)\n",
        "      fcn_loss.append(losses['fcn'])\n",
        "      unet_loss.append(losses['unet'])\n",
        "      unet_plus_plus_loss.append(losses['unet_plus_plus'])\n",
        "      data = {\n",
        "          'fcn': {\n",
        "              'loss' : losses['fcn'] ,\n",
        "              'metrics': {\n",
        "                  'IOUMetric' : fcn_IOUMetric.result(),\n",
        "                  'PerClassIOUMetric' : fcn_PerClassIOUMetric.result(),\n",
        "                  'Dice_Coefficent_matrics' : fcn_Dice_Coefficent_matrics.result(),\n",
        "                  'PerClassDiceCoefficientMatrics' : fcn_PerClassDiceCoefficientMatrics.result() ,\n",
        "                  'Pixel_accurcy_metrics' : fcn_Pixel_accurcy_metrics.result()\n",
        "              }\n",
        "          },\n",
        "          'unet' : {\n",
        "              'loss' : losses['unet'] ,\n",
        "              'metrics': {\n",
        "                  'IOUMetric' : unet_IOUMetric.result(),\n",
        "                  'PerClassIOUMetric' : unet_PerClassIOUMetric.result(),\n",
        "                  'Dice_Coefficent_matrics' : unet_Dice_Coefficent_matrics.result(),\n",
        "                  'PerClassDiceCoefficientMatrics' : unet_PerClassDiceCoefficientMatrics.result() ,\n",
        "                  'Pixel_accurcy_metrics' : unet_Pixel_accurcy_metrics.result()\n",
        "              }\n",
        "          },\n",
        "          'unet_plus_plus' : {\n",
        "              'loss' : losses['unet_plus_plus'] ,\n",
        "              'metrics': {\n",
        "                  'IOUMetric' : unet_plus_plus_IOUMetric.result(),\n",
        "                  'PerClassIOUMetric' : unet_plus_plus_PerClassIOUMetric.result(),\n",
        "                  'Dice_Coefficent_matrics' : unet_plus_plus_Dice_Coefficent_matrics.result(),\n",
        "                  'PerClassDiceCoefficientMatrics' : unet_plus_plus_PerClassDiceCoefficientMatrics.result() ,\n",
        "                  'Pixel_accurcy_metrics' : unet_plus_plus_Pixel_accurcy_metrics.result()\n",
        "              }\n",
        "          }\n",
        "      }\n",
        "      master_callback.on_batch_end(batch = step+1 , epoch = epoch,data = data)\n",
        "    return {\n",
        "        'fcn' : fcn_loss ,\n",
        "        'unet' : unet_loss  ,\n",
        "        'unet_plus_plus' : unet_plus_plus_loss\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "UTN0SW90VJ3m"
      },
      "outputs": [],
      "source": [
        "with strategy.scope() :\n",
        "  @tf.function\n",
        "  def val_model_for_one_epoch():\n",
        "    fcn_val_loss = []\n",
        "    unet_val_loss = []\n",
        "    unet_plus_plus_val_loss = []\n",
        "    for step , (x_val_batch,y_val_batch) in enumerate(val_dataset):\n",
        "      losses = distributed_val_step(x_val_batch , y_val_batch)\n",
        "      fcn_val_loss.append(losses['fcn'])\n",
        "      unet_val_loss.append(losses['unet'])\n",
        "      unet_plus_plus_val_loss.append(losses['unet_plus_plus'])\n",
        "    return {\n",
        "        'fcn' : fcn_val_loss ,\n",
        "        'unet' : unet_val_loss ,\n",
        "        'unet_plus_plus' : unet_plus_plus_val_loss\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "fcq-4mHrBoZB",
        "outputId": "e071a3d1-a117-40d7-d0b7-0a699711d329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no checkpoint found starting from epoch 1\n",
            "Epoch begins : 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\repoch 1:   0%|          | 0/372 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h3>📊 Batch-wise Loss Table</h3>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "  stop_training =False\n",
        "  start=master_callback.on_train_begin()\n",
        "  for epoch in range(start , 250 ):\n",
        "    master_callback.on_epoch_begin(epoch)\n",
        "    losses = train_model_for_one_epoch(epoch)\n",
        "    val_losses = val_model_for_one_epoch()\n",
        "    data = {\n",
        "            'fcn': {\n",
        "                'loss' : losses['fcn'] ,\n",
        "                'val_loss' : val_losses['fcn'] ,\n",
        "                'metrics': {\n",
        "                    'IOUMetric' : fcn_IOUMetric.result(),\n",
        "                    'PerClassIOUMetric' : fcn_PerClassIOUMetric.result(),\n",
        "                    'Dice_Coefficent_matrics' : fcn_Dice_Coefficent_matrics.result(),\n",
        "                    'PerClassDiceCoefficientMatrics' : fcn_PerClassDiceCoefficientMatrics.result() ,\n",
        "                    'Pixel_accurcy_metrics' : fcn_Pixel_accurcy_metrics.result(),\n",
        "\n",
        "                    'IOUMetric_val' : fcn_IOUMetric_val.result(),\n",
        "                    'PerClassIOUMetric_val' : fcn_PerClassIOUMetric_val.result(),\n",
        "                    'Dice_Coefficent_matrics_val' : fcn_Dice_Coefficent_matrics_val.result(),\n",
        "                    'PerClassDiceCoefficientMatrics_val' : fcn_PerClassDiceCoefficientMatrics_val.result() ,\n",
        "                    'Pixel_accurcy_metrics_val' : fcn_Pixel_accurcy_metrics_val.result()\n",
        "                }\n",
        "            },\n",
        "            'unet' : {\n",
        "                'loss' : losses['unet'] ,\n",
        "                'val_loss' : val_losses['unet'],\n",
        "                'metrics': {\n",
        "                    'IOUMetric' : unet_IOUMetric.result(),\n",
        "                    'PerClassIOUMetric' : unet_PerClassIOUMetric.result(),\n",
        "                    'Dice_Coefficent_matrics' : unet_Dice_Coefficent_matrics.result(),\n",
        "                    'PerClassDiceCoefficientMatrics' : unet_PerClassDiceCoefficientMatrics.result() ,\n",
        "                    'Pixel_accurcy_metrics' : unet_Pixel_accurcy_metrics.result(),\n",
        "\n",
        "                    'IOUMetric_val' : unet_IOUMetric_val.result(),\n",
        "                    'PerClassIOUMetric_val' : unet_PerClassIOUMetric_val.result(),\n",
        "                    'Dice_Coefficent_matrics_val' : unet_Dice_Coefficent_matrics_val.result(),\n",
        "                    'PerClassDiceCoefficientMatrics_val' : unet_PerClassDiceCoefficientMatrics_val.result() ,\n",
        "                    'Pixel_accurcy_metrics_val' : unet_Pixel_accurcy_metrics_val.result()\n",
        "                }\n",
        "            },\n",
        "            'unet_plus_plus' : {\n",
        "                'loss' : losses['unet_plus_plus'] ,\n",
        "                'val_loss' : val_losses['unet_plus_plus'] ,\n",
        "                'metrics': {\n",
        "                    'IOUMetric' : unet_plus_plus_IOUMetric.result(),\n",
        "                    'PerClassIOUMetric' : unet_plus_plus_PerClassIOUMetric.result(),\n",
        "                    'Dice_Coefficent_matrics' : unet_plus_plus_Dice_Coefficent_matrics.result(),\n",
        "                    'PerClassDiceCoefficientMatrics' : unet_plus_plus_PerClassDiceCoefficientMatrics.result() ,\n",
        "                    'Pixel_accurcy_metrics' : unet_plus_plus_Pixel_accurcy_metrics.result(),\n",
        "\n",
        "                    'IOUMetric_val' : unet_plus_plus_IOUMetric_val.result(),\n",
        "                    'PerClassIOUMetric_val' : unet_plus_plus_PerClassIOUMetric_val.result(),\n",
        "                    'Dice_Coefficent_matrics_val' : unet_plus_plus_Dice_Coefficent_matrics_val.result(),\n",
        "                    'PerClassDiceCoefficientMatrics_val' : unet_plus_plus_PerClassDiceCoefficientMatrics_val.result() ,\n",
        "                    'Pixel_accurcy_metrics_val' : unet_plus_plus_Pixel_accurcy_metrics_val.result()\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    fcn_IOUMetric.reset_state()\n",
        "    fcn_IOUMetric_val.reset_state()\n",
        "    fcn_PerClassIOUMetric.reset_state()\n",
        "    fcn_PerClassIOUMetric_val.reset_state()\n",
        "    fcn_Dice_Coefficent_matrics.reset_state()\n",
        "    fcn_Dice_Coefficent_matrics_val.reset_state()\n",
        "    fcn_PerClassDiceCoefficientMatrics.reset_state()\n",
        "    fcn_PerClassDiceCoefficientMatrics_val.reset_state()\n",
        "    fcn_Pixel_accurcy_metrics.reset_state()\n",
        "    fcn_Pixel_accurcy_metrics_val.reset_state()\n",
        "\n",
        "    unet_IOUMetric.reset_state()\n",
        "    unet_IOUMetric_val.reset_state()\n",
        "    unet_PerClassIOUMetric.reset_state()\n",
        "    unet_PerClassIOUMetric_val.reset_state()\n",
        "    unet_Dice_Coefficent_matrics.reset_state()\n",
        "    unet_Dice_Coefficent_matrics_val.reset_state()\n",
        "    unet_PerClassDiceCoefficientMatrics.reset_state()\n",
        "    unet_PerClassDiceCoefficientMatrics_val.reset_state()\n",
        "    unet_Pixel_accurcy_metrics.reset_state()\n",
        "    unet_Pixel_accurcy_metrics_val.reset_state()\n",
        "\n",
        "    unet_plus_plus_IOUMetric.reset_state()\n",
        "    unet_plus_plus_IOUMetric_val.reset_state()\n",
        "    unet_plus_plus_PerClassIOUMetric.reset_state()\n",
        "    unet_plus_plus_PerClassIOUMetric_val.reset_state()\n",
        "    unet_plus_plus_Dice_Coefficent_matrics.reset_state()\n",
        "    unet_plus_plus_Dice_Coefficent_matrics_val.reset_state()\n",
        "    unet_plus_plus_PerClassDiceCoefficientMatrics.reset_state()\n",
        "    unet_plus_plus_PerClassDiceCoefficientMatrics_val.reset_state()\n",
        "    unet_plus_plus_Pixel_accurcy_metrics.reset_state()\n",
        "    unet_plus_plus_Pixel_accurcy_metrics_val.reset_state()\n",
        "\n",
        "    stop_training=master_callback.on_epoch_end(epoch=epoch , data= data)\n",
        "    if stop_training :\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkMcZwBqAajg"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hocvJL_Do4Gk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e16e80f-5eeb-43e9-fb2a-267740caa5bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "started training {epoch}\n",
            "starting of step : 0\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 0\n",
            "starting of step : 1\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 1\n",
            "starting of step : 2\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 2\n",
            "starting of step : 3\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 3\n",
            "starting of step : 4\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 4\n",
            "starting of step : 5\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 5\n",
            "starting of step : 6\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 6\n",
            "starting of step : 7\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 7\n",
            "starting of step : 8\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 8\n",
            "starting of step : 9\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 9\n",
            "starting of step : 10\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 10\n",
            "starting of step : 11\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 11\n",
            "starting of step : 12\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 12\n",
            "starting of step : 13\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 13\n",
            "starting of step : 14\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 14\n",
            "starting of step : 15\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 15\n",
            "starting of step : 16\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 16\n",
            "starting of step : 17\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 17\n",
            "starting of step : 18\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 18\n",
            "starting of step : 19\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 19\n",
            "starting of step : 20\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 20\n",
            "starting of step : 21\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 21\n",
            "starting of step : 22\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 22\n",
            "starting of step : 23\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 23\n",
            "starting of step : 24\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 24\n",
            "starting of step : 25\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 25\n",
            "starting of step : 26\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 26\n",
            "starting of step : 27\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 27\n",
            "starting of step : 28\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 28\n",
            "starting of step : 29\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 29\n",
            "starting of step : 30\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 30\n",
            "starting of step : 31\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 31\n",
            "starting of step : 32\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 32\n",
            "starting of step : 33\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 33\n",
            "starting of step : 34\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 34\n",
            "starting of step : 35\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 35\n",
            "starting of step : 36\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 36\n",
            "starting of step : 37\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 37\n",
            "starting of step : 38\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 38\n",
            "starting of step : 39\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 39\n",
            "starting of step : 40\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 40\n",
            "starting of step : 41\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 41\n",
            "starting of step : 42\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 42\n",
            "starting of step : 43\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 43\n",
            "starting of step : 44\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 44\n",
            "starting of step : 45\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 45\n",
            "starting of step : 46\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 46\n",
            "starting of step : 47\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 47\n",
            "starting of step : 48\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 48\n",
            "starting of step : 49\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 49\n",
            "starting of step : 50\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 50\n",
            "starting of step : 51\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 51\n",
            "starting of step : 52\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 52\n",
            "starting of step : 53\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 53\n",
            "starting of step : 54\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 54\n",
            "starting of step : 55\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 55\n",
            "starting of step : 56\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 56\n",
            "starting of step : 57\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 57\n",
            "starting of step : 58\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 58\n",
            "starting of step : 59\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 59\n",
            "starting of step : 60\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 60\n",
            "starting of step : 61\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 61\n",
            "starting of step : 62\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 62\n",
            "starting of step : 63\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 63\n",
            "starting of step : 64\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 64\n",
            "starting of step : 65\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 65\n",
            "starting of step : 66\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 66\n",
            "starting of step : 67\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 67\n",
            "starting of step : 68\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 68\n",
            "starting of step : 69\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 69\n",
            "starting of step : 70\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 70\n",
            "starting of step : 71\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 71\n",
            "starting of step : 72\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 72\n",
            "starting of step : 73\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 73\n",
            "starting of step : 74\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 74\n",
            "starting of step : 75\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 75\n",
            "starting of step : 76\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 76\n",
            "starting of step : 77\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 77\n",
            "starting of step : 78\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 78\n",
            "starting of step : 79\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 79\n",
            "starting of step : 80\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 80\n",
            "starting of step : 81\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 81\n",
            "starting of step : 82\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 82\n",
            "starting of step : 83\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 83\n",
            "starting of step : 84\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 84\n",
            "starting of step : 85\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 85\n",
            "starting of step : 86\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 86\n",
            "starting of step : 87\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 87\n",
            "starting of step : 88\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 88\n",
            "starting of step : 89\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 89\n",
            "starting of step : 90\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 90\n",
            "starting of step : 91\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 91\n",
            "starting of step : 92\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 92\n",
            "starting of step : 93\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 93\n",
            "starting of step : 94\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 94\n",
            "starting of step : 95\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 95\n",
            "starting of step : 96\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 96\n",
            "starting of step : 97\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 97\n",
            "starting of step : 98\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 98\n",
            "starting of step : 99\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 99\n",
            "starting of step : 100\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 100\n",
            "starting of step : 101\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 101\n",
            "starting of step : 102\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 102\n",
            "starting of step : 103\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 103\n",
            "starting of step : 104\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 104\n",
            "starting of step : 105\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 105\n",
            "starting of step : 106\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 106\n",
            "starting of step : 107\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 107\n",
            "starting of step : 108\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 108\n",
            "starting of step : 109\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 109\n",
            "starting of step : 110\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 110\n",
            "starting of step : 111\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 111\n",
            "starting of step : 112\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 112\n",
            "starting of step : 113\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 113\n",
            "starting of step : 114\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 114\n",
            "starting of step : 115\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 115\n",
            "starting of step : 116\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 116\n",
            "starting of step : 117\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 117\n",
            "starting of step : 118\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 118\n",
            "starting of step : 119\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 119\n",
            "starting of step : 120\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 120\n",
            "starting of step : 121\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 121\n",
            "starting of step : 122\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 122\n",
            "starting of step : 123\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 123\n",
            "starting of step : 124\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 124\n",
            "starting of step : 125\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 125\n",
            "starting of step : 126\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 126\n",
            "starting of step : 127\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 127\n",
            "starting of step : 128\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 128\n",
            "starting of step : 129\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 129\n",
            "starting of step : 130\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 130\n",
            "starting of step : 131\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 131\n",
            "starting of step : 132\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 132\n",
            "starting of step : 133\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 133\n",
            "starting of step : 134\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 134\n",
            "starting of step : 135\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 135\n",
            "starting of step : 136\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 136\n",
            "starting of step : 137\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 137\n",
            "starting of step : 138\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 138\n",
            "starting of step : 139\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 139\n",
            "starting of step : 140\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 140\n",
            "starting of step : 141\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 141\n",
            "starting of step : 142\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 142\n",
            "starting of step : 143\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 143\n",
            "starting of step : 144\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 144\n",
            "starting of step : 145\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 145\n",
            "starting of step : 146\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 146\n",
            "starting of step : 147\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 147\n",
            "starting of step : 148\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 148\n",
            "starting of step : 149\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 149\n",
            "starting of step : 150\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 150\n",
            "starting of step : 151\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 151\n",
            "starting of step : 152\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 152\n",
            "starting of step : 153\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 153\n",
            "starting of step : 154\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 154\n",
            "starting of step : 155\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 155\n",
            "starting of step : 156\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 156\n",
            "starting of step : 157\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 157\n",
            "starting of step : 158\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 158\n",
            "starting of step : 159\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 159\n",
            "starting of step : 160\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 160\n",
            "starting of step : 161\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 161\n",
            "starting of step : 162\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 162\n",
            "starting of step : 163\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 163\n",
            "starting of step : 164\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 164\n",
            "starting of step : 165\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 165\n",
            "starting of step : 166\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 166\n",
            "starting of step : 167\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 167\n",
            "starting of step : 168\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 168\n",
            "starting of step : 169\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 169\n",
            "starting of step : 170\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 170\n",
            "starting of step : 171\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 171\n",
            "starting of step : 172\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 172\n",
            "starting of step : 173\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 173\n",
            "starting of step : 174\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 174\n",
            "starting of step : 175\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 175\n",
            "starting of step : 176\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 176\n",
            "starting of step : 177\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 177\n",
            "starting of step : 178\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 178\n",
            "starting of step : 179\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 179\n",
            "starting of step : 180\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 180\n",
            "starting of step : 181\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 181\n",
            "starting of step : 182\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 182\n",
            "starting of step : 183\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 183\n",
            "starting of step : 184\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 184\n",
            "starting of step : 185\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 185\n",
            "starting of step : 186\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 186\n",
            "starting of step : 187\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 187\n",
            "starting of step : 188\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 188\n",
            "starting of step : 189\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 189\n",
            "starting of step : 190\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 190\n",
            "starting of step : 191\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 191\n",
            "starting of step : 192\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 192\n",
            "starting of step : 193\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 193\n",
            "starting of step : 194\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 194\n",
            "starting of step : 195\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 195\n",
            "starting of step : 196\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 196\n",
            "starting of step : 197\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 197\n",
            "starting of step : 198\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 198\n",
            "starting of step : 199\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 199\n",
            "starting of step : 200\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 200\n",
            "starting of step : 201\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 201\n",
            "starting of step : 202\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 202\n",
            "starting of step : 203\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 203\n",
            "starting of step : 204\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 204\n",
            "starting of step : 205\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 205\n",
            "starting of step : 206\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 206\n",
            "starting of step : 207\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 207\n",
            "starting of step : 208\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 208\n",
            "starting of step : 209\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 209\n",
            "starting of step : 210\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 210\n",
            "starting of step : 211\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 211\n",
            "starting of step : 212\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 212\n",
            "starting of step : 213\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 213\n",
            "starting of step : 214\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 214\n",
            "starting of step : 215\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 215\n",
            "starting of step : 216\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 216\n",
            "starting of step : 217\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 217\n",
            "starting of step : 218\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 218\n",
            "starting of step : 219\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 219\n",
            "starting of step : 220\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 220\n",
            "starting of step : 221\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 221\n",
            "starting of step : 222\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 222\n",
            "starting of step : 223\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 223\n",
            "starting of step : 224\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 224\n",
            "starting of step : 225\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 225\n",
            "starting of step : 226\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 226\n",
            "starting of step : 227\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 227\n",
            "starting of step : 228\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 228\n",
            "starting of step : 229\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 229\n",
            "starting of step : 230\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 230\n",
            "starting of step : 231\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 231\n",
            "starting of step : 232\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 232\n",
            "starting of step : 233\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 233\n",
            "starting of step : 234\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 234\n",
            "starting of step : 235\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 235\n",
            "starting of step : 236\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 236\n",
            "starting of step : 237\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 237\n",
            "starting of step : 238\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 238\n",
            "starting of step : 239\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 239\n",
            "starting of step : 240\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 240\n",
            "starting of step : 241\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 241\n",
            "starting of step : 242\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 242\n",
            "starting of step : 243\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 243\n",
            "starting of step : 244\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 244\n",
            "starting of step : 245\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 245\n",
            "starting of step : 246\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 246\n",
            "starting of step : 247\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 247\n",
            "starting of step : 248\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 248\n",
            "starting of step : 249\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 249\n",
            "starting of step : 250\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 250\n",
            "starting of step : 251\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 251\n",
            "starting of step : 252\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 252\n",
            "starting of step : 253\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 253\n",
            "starting of step : 254\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 254\n",
            "starting of step : 255\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 255\n",
            "starting of step : 256\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 256\n",
            "starting of step : 257\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 257\n",
            "starting of step : 258\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 258\n",
            "starting of step : 259\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 259\n",
            "starting of step : 260\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 260\n",
            "starting of step : 261\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 261\n",
            "starting of step : 262\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 262\n",
            "starting of step : 263\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 263\n",
            "starting of step : 264\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 264\n",
            "starting of step : 265\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 265\n",
            "starting of step : 266\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 266\n",
            "starting of step : 267\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 267\n",
            "starting of step : 268\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 268\n",
            "starting of step : 269\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 269\n",
            "starting of step : 270\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 270\n",
            "starting of step : 271\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 271\n",
            "starting of step : 272\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 272\n",
            "starting of step : 273\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 273\n",
            "starting of step : 274\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 274\n",
            "starting of step : 275\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 275\n",
            "starting of step : 276\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 276\n",
            "starting of step : 277\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 277\n",
            "starting of step : 278\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 278\n",
            "starting of step : 279\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 279\n",
            "starting of step : 280\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 280\n",
            "starting of step : 281\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 281\n",
            "starting of step : 282\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 282\n",
            "starting of step : 283\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 283\n",
            "starting of step : 284\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 284\n",
            "starting of step : 285\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 285\n",
            "starting of step : 286\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 286\n",
            "starting of step : 287\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 287\n",
            "starting of step : 288\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 288\n",
            "starting of step : 289\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 289\n",
            "starting of step : 290\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 290\n",
            "starting of step : 291\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 291\n",
            "starting of step : 292\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 292\n",
            "starting of step : 293\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 293\n",
            "starting of step : 294\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 294\n",
            "starting of step : 295\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 295\n",
            "starting of step : 296\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 296\n",
            "starting of step : 297\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 297\n",
            "starting of step : 298\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 298\n",
            "starting of step : 299\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 299\n",
            "starting of step : 300\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 300\n",
            "starting of step : 301\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 301\n",
            "starting of step : 302\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 302\n",
            "starting of step : 303\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 303\n",
            "starting of step : 304\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 304\n",
            "starting of step : 305\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 305\n",
            "starting of step : 306\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 306\n",
            "starting of step : 307\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 307\n",
            "starting of step : 308\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 308\n",
            "starting of step : 309\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 309\n",
            "starting of step : 310\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 310\n",
            "starting of step : 311\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 311\n",
            "starting of step : 312\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 312\n",
            "starting of step : 313\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 313\n",
            "starting of step : 314\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 314\n",
            "starting of step : 315\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 315\n",
            "starting of step : 316\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 316\n",
            "starting of step : 317\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 317\n",
            "starting of step : 318\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 318\n",
            "starting of step : 319\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 319\n",
            "starting of step : 320\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 320\n",
            "starting of step : 321\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 321\n",
            "starting of step : 322\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 322\n",
            "starting of step : 323\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 323\n",
            "starting of step : 324\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 324\n",
            "starting of step : 325\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 325\n",
            "starting of step : 326\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 326\n",
            "starting of step : 327\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 327\n",
            "starting of step : 328\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 328\n",
            "starting of step : 329\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 329\n",
            "starting of step : 330\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 330\n",
            "starting of step : 331\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 331\n",
            "starting of step : 332\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 332\n",
            "starting of step : 333\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 333\n",
            "starting of step : 334\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 334\n",
            "starting of step : 335\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 335\n",
            "starting of step : 336\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 336\n",
            "starting of step : 337\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 337\n",
            "starting of step : 338\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 338\n",
            "starting of step : 339\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 339\n",
            "starting of step : 340\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 340\n",
            "starting of step : 341\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 341\n",
            "starting of step : 342\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 342\n",
            "starting of step : 343\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 343\n",
            "starting of step : 344\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 344\n",
            "starting of step : 345\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 345\n",
            "starting of step : 346\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 346\n",
            "starting of step : 347\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 347\n",
            "starting of step : 348\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 348\n",
            "starting of step : 349\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 349\n",
            "starting of step : 350\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 350\n",
            "starting of step : 351\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 351\n",
            "starting of step : 352\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 352\n",
            "starting of step : 353\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 353\n",
            "starting of step : 354\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 354\n",
            "starting of step : 355\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 355\n",
            "starting of step : 356\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 356\n",
            "starting of step : 357\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 357\n",
            "starting of step : 358\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 358\n",
            "starting of step : 359\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 359\n",
            "starting of step : 360\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 360\n",
            "starting of step : 361\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 361\n",
            "starting of step : 362\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 362\n",
            "starting of step : 363\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 363\n",
            "starting of step : 364\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 364\n",
            "starting of step : 365\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 365\n",
            "starting of step : 366\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 366\n",
            "starting of step : 367\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 367\n",
            "starting of step : 368\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 368\n",
            "starting of step : 369\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 369\n",
            "starting of step : 370\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "end of step : 370\n",
            "starting of step : 371\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "  @tf.function\n",
        "  def train_step(x_batch_train,y_batch_train):\n",
        "    with tf.GradientTape()  as tape :\n",
        "      logits=fcn(x_batch_train)\n",
        "      loss = fcn_SemanticSegmentationLoss(y_batch_train,logits)\n",
        "    gradients = tape.gradient(loss , fcn.trainable_variables)\n",
        "    optimizer_fcn.apply_gradients(zip(gradients, fcn.trainable_variables))\n",
        "    return loss\n",
        "  @tf.function\n",
        "  def distributed_train_step(x_train_batch,y_train_batch):\n",
        "    per_replica_loss =strategy.run(train_step , args = (x_train_batch , y_train_batch))\n",
        "    return  strategy.reduce(tf.distribute.ReduceOp.MEAN,per_replica_loss,axis=None)\n",
        "  for epoch in range (2):\n",
        "    print('started training {epoch}')\n",
        "    for step , (x_batch_train,y_batch_train ) in enumerate(train_dataset) :\n",
        "      print(f'starting of step : {step}')\n",
        "      error=distributed_train_step(x_batch_train,y_batch_train)\n",
        "      print(error)\n",
        "      print(f'end of step : {step}')\n",
        "    print(f'end of epoch {epoch}')\n",
        "  print('finish training ')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gAz3gOSrjuZ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}