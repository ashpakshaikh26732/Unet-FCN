{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1B12W-D6S226pHFryN9Y2XzlBbHV5Pvsg",
      "authorship_tag": "ABX9TyMQsEC4mKvAxq6zmNQujOLf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashpakshaikh26732/Unet-FCN/blob/main/Unet_FCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**all packages**"
      ],
      "metadata": {
        "id": "5XRgNljpyU9b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "mm_LuZ1iev66"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "  print(f'no of tpus : {strategy.num_replicas_in_sync}')\n",
        "except ValueError :\n",
        "  print('tpu failed to initilized')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTuYhVhRffta",
        "outputId": "cee8cc90-78e2-4a04-83d5-503491e55147"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tpu failed to initilized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**mixed precision training**"
      ],
      "metadata": {
        "id": "tzwsFyykuBp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "I9g7HnQsuOMj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cdN0drMo70q4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vQK2Gy1ggZP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1952aadc-5a09-4c32-d01e-bf2ee063213c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**copy datasets from drive**"
      ],
      "metadata": {
        "id": "XLI9cZz46258"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Cityscapes/gtFine_trainvaltest.zip /content/\n",
        "!cp /content/drive/MyDrive/Cityscapes/leftImg8bit_trainvaltest.zip /content"
      ],
      "metadata": {
        "id": "_cb4xI4h5b3z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**extract trainig the data**"
      ],
      "metadata": {
        "id": "gWcHvq9T67yT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.system(\"unzip -q /content/gtFine_trainvaltest.zip -d /content/ \")\n",
        "os.system(\"unzip -q /content/leftImg8bit_trainvaltest.zip -d /content/\")"
      ],
      "metadata": {
        "id": "gIGN5YpV58XW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb158779-c095-42ff-915a-56a588bac6da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Images:\", len(os.listdir(\"/content/leftImg8bit/train/aachen\")))  # Adjust path as needed\n",
        "print(\"Train Labels:\", len(os.listdir(\"/content/gtFine/train/aachen\")))"
      ],
      "metadata": {
        "id": "-MKUIQNX7naD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e15a53a-c00c-464c-8366-8950a4269fd1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images: 174\n",
            "Train Labels: 696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"test images : \", len(os.listdir('/content/leftImg8bit/test')))"
      ],
      "metadata": {
        "id": "qafiZBb5yC0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104e34a3-d773-4f13-d566-cbe7bb782e70"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test images :  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Global Valrible**"
      ],
      "metadata": {
        "id": "9Q1cFO0jJcA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 224\n",
        "img_width = 224\n",
        "batch_size = 16\n",
        "# final_batch_size = batch_size * strategy.num_replicas_in_sync"
      ],
      "metadata": {
        "id": "3NSFJ69oJiMF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**loading images and labels from directry**"
      ],
      "metadata": {
        "id": "J9Y6CZKmCbNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img():\n",
        "    train_dir = '/content/leftImg8bit/train'\n",
        "    train_image_cities = os.listdir(train_dir)\n",
        "    train_images = []\n",
        "\n",
        "    for city in train_image_cities:\n",
        "        train_city = os.path.join(train_dir, city)\n",
        "        images = [os.path.join(train_city, img) for img in os.listdir(train_city) if img.endswith('.png')]\n",
        "        train_images.extend(images)\n",
        "\n",
        "    return train_images\n",
        "\n",
        "def load_labels():\n",
        "    train_dir = '/content/gtFine/train'\n",
        "    train_labels_cities = os.listdir(train_dir)\n",
        "    train_labels = []\n",
        "    for city in train_labels_cities:\n",
        "        train_city_label = os.path.join(train_dir, city)\n",
        "        labels = [f for f in os.listdir(train_city_label) if f.endswith('_gtFine_labelIds.png')]\n",
        "        for label in labels:\n",
        "            label_path = os.path.join(train_city_label, label)\n",
        "            train_labels.append(label_path)\n",
        "    return train_labels"
      ],
      "metadata": {
        "id": "OzTJuxSUyT19"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**reading images from path**"
      ],
      "metadata": {
        "id": "cGkR1OkdChy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_img(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, (img_height, img_width))\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "def read_labels(label_path):\n",
        "    label = tf.io.read_file(label_path)\n",
        "    label = tf.io.decode_png(label, channels=1)\n",
        "    label = tf.image.resize(label, (img_height, img_width), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    return tf.cast(label, tf.uint8)\n"
      ],
      "metadata": {
        "id": "tR2-lYACFmLh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**augmentation**"
      ],
      "metadata": {
        "id": "PMQ2HsmKQtqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment(image, label):\n",
        "\n",
        "    label = tf.cast(label, tf.float32)\n",
        "\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "        label = tf.image.flip_left_right(label)\n",
        "\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "\n",
        "    combined = tf.concat([image, label], axis=-1)\n",
        "    combined = tf.image.random_crop(combined, size=[224, 224, 6])\n",
        "\n",
        "    image, label = tf.split(combined, num_or_size_splits=2, axis=-1)\n",
        "\n",
        "\n",
        "    label = tf.cast(label, tf.uint8)\n",
        "\n",
        "    return image, label\n"
      ],
      "metadata": {
        "id": "ArL30hPWQzQc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**creating dataset**"
      ],
      "metadata": {
        "id": "AMrQX_bwIrwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = load_img()\n",
        "labels = load_labels()\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "dataset = dataset.map(lambda image_path , label_path :( read_img(image_path) , label_path)).map(lambda image , label_path : (image,read_labels(label_path=label_path)))\n",
        "dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset = dataset.shuffle(buffer_size=1000).cache().batch(batch_size)\n",
        "dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "oiZ4wr51HQR_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for image , label in dataset.take(1):\n",
        "#   print(f'image shape : {image.shape} , label shape {label.shape}')\n",
        "#   print(f'image datatype : {image.dtype}, label dtype {label.dtype}')"
      ],
      "metadata": {
        "id": "l4asEByyJz3k"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FCN model**"
      ],
      "metadata": {
        "id": "71fnRZr6XnEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(tf.keras.models.Model):\n",
        "    def __init__(self, n_conv, filters, kernel_size, activation, pool_size, pool_stride, block_name):\n",
        "        super().__init__()\n",
        "        self.conv_layers = [\n",
        "            tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding='same',\n",
        "                                   activation=activation, name=f\"{block_name}_conv{i+1}\")\n",
        "            for i in range(n_conv)\n",
        "        ]\n",
        "        self.pool = tf.keras.layers.MaxPool2D(pool_size=pool_size, strides=pool_stride, name=f\"{block_name}_pool\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for conv in self.conv_layers:\n",
        "            x = conv(x)\n",
        "        x = self.pool(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lYYeYAZ7WKGM"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.block1 = Block(n_conv=2 , filters=64 , kernel_size = (3,3) , activation ='relu' , pool_size=(2,2) , pool_stride = (2,2) , block_name = 'block1')\n",
        "    self.block2 = Block(n_conv=3 , filters = 128 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block2')\n",
        "    self.block3 = Block(n_conv=3 , filters = 256 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block3')\n",
        "    self.block4 = Block(n_conv=3 , filters = 512 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block4')\n",
        "    self.block5 = Block(n_conv=3 , filters = 512 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block5')\n",
        "  def call(self,inputs):\n",
        "    p1 = self.block1(inputs)\n",
        "    p2 = self.block2(p1)\n",
        "    p3 = self.block3(p2)\n",
        "    p4 = self.block4(p3)\n",
        "    p5 = self.block5(p4)\n",
        "    return p1 , p2 , p3 , p4 , p5"
      ],
      "metadata": {
        "id": "qTQFaELPY5CU"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.models.Model):\n",
        "    def __init__(self, nclasses=19):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.upsample1 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.upsample2 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.upsample3 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "\n",
        "\n",
        "        self.skip1 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), activation='relu', padding='same')\n",
        "        self.skip2 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), activation='relu', padding='same')\n",
        "        self.skip3 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), activation='relu', padding='same')\n",
        "\n",
        "\n",
        "        self.add1 = tf.keras.layers.Add()\n",
        "        self.add2 = tf.keras.layers.Add()\n",
        "        self.add3 = tf.keras.layers.Add()\n",
        "\n",
        "\n",
        "        self.fcn32 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(32, 32), strides=(32, 32), padding='same', name='fcn32')\n",
        "        self.fcn16 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(16, 16), strides=(16, 16), padding='same', name='fcn16')\n",
        "        self.fcn8 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(8, 8), strides=(8, 8), padding='same', name='fcn8')\n",
        "        self.fcn4 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(4, 4), padding='same', name='fcn4')\n",
        "\n",
        "\n",
        "        self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        p1, p2, p3, p4, p5 = inputs\n",
        "\n",
        "        fcn32 = self.fcn32(p5)\n",
        "\n",
        "\n",
        "        o = self.upsample1(p5)\n",
        "        o = self.add1([o, self.skip1(p4)])\n",
        "        fcn16 = self.fcn16(o)\n",
        "\n",
        "\n",
        "        o = self.upsample2(o)\n",
        "        o = self.add2([o, self.skip2(p3)])\n",
        "        fcn8 = self.fcn8(o)\n",
        "\n",
        "\n",
        "        o = self.upsample3(o)\n",
        "        o = self.add3([o, self.skip3(p2)])\n",
        "        fcn4 = self.fcn4(o)\n",
        "\n",
        "\n",
        "        return self.softmax(fcn32), self.softmax(fcn16), self.softmax(fcn8), self.softmax(fcn4)"
      ],
      "metadata": {
        "id": "C7urJTNYZAVO"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FCN(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Encoder = Encoder()\n",
        "    self.Decoder = Decoder()\n",
        "  def call(self, inputs):\n",
        "    x=self.Encoder(inputs)\n",
        "    x = self.Decoder(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "4WXzcbDYZOJ5"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JxRi_CXd411R"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**UNET**"
      ],
      "metadata": {
        "id": "t99faxaF2nJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters,block_name , kernel_size=3 , strides = (1,1) , activation='relu'):\n",
        "    super().__init__()\n",
        "    self.conv = [tf.keras.layers.Conv2D(filters=n_filters , strides=strides , kernel_size=(kernel_size, kernel_size) , activation='relu', name=f\"{block_name}_conv{i+1}\", padding='same') for i in range (2)]\n",
        "  def call(self, inputs):\n",
        "    x = inputs\n",
        "    for layer in self.conv:\n",
        "      x = layer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "q1GY9fuSZy2v"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters , pool_size , dropout,block_name):\n",
        "    super().__init__()\n",
        "    self.convBlock = ConvBlock(n_filters=n_filters , block_name=block_name, strides=(1,1))\n",
        "    self.pool = tf.keras.layers.MaxPooling2D(pool_size=pool_size)\n",
        "    self.dropout = tf.keras.layers.Dropout(rate = dropout)\n",
        "  def call (self, inputs) :\n",
        "    f = self.convBlock(inputs)\n",
        "    p = self.pool(f)\n",
        "    p = self.dropout(p)\n",
        "    return f , p"
      ],
      "metadata": {
        "id": "XnXkjW1yBK2t"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder (tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.encoder1 = EncoderBlock(64 , pool_size=(2,2),dropout=0.3 , block_name = 'block1')\n",
        "    self.encoder2 = EncoderBlock(128 , pool_size=(2,2),dropout=0.3 , block_name = 'block2')\n",
        "    self.encoder3 = EncoderBlock(256 , pool_size=(2,2),dropout=0.3 , block_name = 'block3')\n",
        "    self.encoder4 = EncoderBlock(512, pool_size=(2,2),dropout=0.3 , block_name = 'block4')\n",
        "  def call(self, inputs):\n",
        "    f1,p1=self.encoder1(inputs)\n",
        "    f2,p2 = self.encoder2(p1)\n",
        "    f3 , p3 = self.encoder3(p2)\n",
        "    f4,p4 = self.encoder4(p3)\n",
        "    return p4,(f1,f2,f3,f4)"
      ],
      "metadata": {
        "id": "bGj_gAVYCtKV"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleNeck(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.convBlock=ConvBlock(1024, block_name = 'bottleneck' )\n",
        "  def call(self, inputs):\n",
        "    x = self.convBlock(inputs)\n",
        "    return x"
      ],
      "metadata": {
        "id": "JnixQBJQEYxk"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters ,dropout,block_name , kernel_size= (3,3),strides = (2,2)  ):\n",
        "    super().__init__()\n",
        "    self.convTranspose = tf.keras.layers.Conv2DTranspose(n_filters, kernel_size = kernel_size , strides=strides , padding = 'same')\n",
        "    self.concat = tf.keras.layers.Concatenate()\n",
        "    self.DropOut = tf.keras.layers.Dropout(dropout)\n",
        "    self.convBlock = ConvBlock(n_filters=n_filters , block_name =block_name  )\n",
        "  def call(self, inputs , convOutput):\n",
        "    u=self.convTranspose(inputs)\n",
        "    c = self.concat([u,convOutput])\n",
        "    c= self.DropOut(c)\n",
        "    c = self.convBlock(c)\n",
        "    return c"
      ],
      "metadata": {
        "id": "yRG3BTRoKBp_"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder (tf.keras.models.Model):\n",
        "  def __init__(self) :\n",
        "    super().__init__()\n",
        "    self.Decoder1 = DecoderBlock(n_filters=512 , dropout=0.3 , block_name='Decoder1')\n",
        "    self.Decoder2 = DecoderBlock(n_filters=256 , dropout=0.3 , block_name='Decoder2')\n",
        "    self.Decoder3 = DecoderBlock(n_filters=128 , dropout=0.3 , block_name='Decoder3')\n",
        "    self.Decoder4 = DecoderBlock(n_filters=64 , dropout=0.3 , block_name='Decoder4')\n",
        "    self.final_conv = tf.keras.layers.Conv2D(19, kernel_size=(1,1), activation='softmax')\n",
        "  def call(self , inputs , conv):\n",
        "    f1, f2 , f3, f4 = conv\n",
        "    c6 = self.Decoder1(inputs, f4 )\n",
        "    c7 = self.Decoder2(c6,f3)\n",
        "    c8 = self.Decoder3(c7,f2)\n",
        "    c9= self.Decoder4(c8, f1)\n",
        "    outputs = self.final_conv(c9)\n",
        "    return outputs\n"
      ],
      "metadata": {
        "id": "38eh4paxNH6X"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class  Unet (tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Encoder = Encoder()\n",
        "    self.BottleNeck = BottleNeck()\n",
        "    self.Decoder = Decoder()\n",
        "  def call(self , inputs):\n",
        "    encoder_output,convs = self.Encoder(inputs)\n",
        "    bottleNeck_output = self.BottleNeck(encoder_output)\n",
        "    output = self.Decoder(bottleNeck_output,convs)\n",
        "    return output"
      ],
      "metadata": {
        "id": "50M1jLpNPbHe"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***UNET ++***"
      ],
      "metadata": {
        "id": "jcAZx14LYsBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Unet_plus_plus_convolutional_block(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters , block_name , activation = 'relu',kernel_size=(3,3)  ):\n",
        "    super().__init__()\n",
        "    self.conv_layers = [tf.keras.layers.Conv2D(filters=n_filters , kernel_size= kernel_size , name=f\"{block_name}_conv{i+1}\",padding = 'same', activation='relu') for i in range (2)]\n",
        "  def call(self, inputs) :\n",
        "    x = inputs\n",
        "    for layer in self.conv_layers:\n",
        "      x=layer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Ky0wpWCXYxRo"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_Block_for_unt_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self,  n_filters , pool_size , dropout,block_name):\n",
        "    super().__init__()\n",
        "    self.conv = Unet_plus_plus_convolutional_block(n_filters=n_filters, block_name=block_name)\n",
        "    self.pool = tf.keras.layers.MaxPooling2D(pool_size=pool_size)\n",
        "    self.dropout = tf.keras.layers.Dropout(rate =dropout)\n",
        "  def call(self,inputs):\n",
        "    f=self.conv(inputs)\n",
        "    p = self.pool(f)\n",
        "    p = self.dropout(p)\n",
        "    return f ,  p"
      ],
      "metadata": {
        "id": "DoVSW0wMbWTe"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_for_unt_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.encoder1 = Encoder_Block_for_unt_plus_plus(n_filters=64, pool_size=(2,2) , dropout=0.3, block_name = 'encoder1')\n",
        "    self.encoder2 = Encoder_Block_for_unt_plus_plus(n_filters=128, pool_size=(2,2) , dropout=0.3, block_name = 'encoder2')\n",
        "    self.encoder3 = Encoder_Block_for_unt_plus_plus(n_filters=256, pool_size=(2,2) , dropout=0.3, block_name = 'encoder3')\n",
        "    self.encoder4 = Encoder_Block_for_unt_plus_plus(n_filters=512, pool_size=(2,2) , dropout=0.3, block_name = 'encoder4')\n",
        "  def call(self, inputs):\n",
        "    f1,p1 = self.encoder1(inputs)\n",
        "    f2,p2 = self.encoder2(p1)\n",
        "    f3,p3 = self.encoder3(p2)\n",
        "    f4,p4 = self.encoder4(p3)\n",
        "    return (f1,f2,f3,f4),(p1,p2,p3,p4)"
      ],
      "metadata": {
        "id": "8cis-R7e4ozB"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleNeck_for_unet_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self ):\n",
        "    super().__init__()\n",
        "    self.bottle_neck = Unet_plus_plus_convolutional_block(n_filters=1024 , block_name = 'bottle_neck'  )\n",
        "  def call(self, inputs):\n",
        "    x = self.bottle_neck(inputs)\n",
        "    return x"
      ],
      "metadata": {
        "id": "r-p5Nw8n7TcD"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder_Block_for_unet_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self,n_filters  , dropout,block_name):\n",
        "    super().__init__()\n",
        "    self.conv = Unet_plus_plus_convolutional_block(n_filters=n_filters , block_name = block_name)\n",
        "    self.dropout = tf.keras.layers.Dropout(rate = dropout)\n",
        "    self.convTranspose = tf.keras.layers.Conv2DTranspose(n_filters, kernel_size = (3,3) , strides=(2,2) , padding = 'same')\n",
        "    self.concat = tf.keras.layers.Concatenate()\n",
        "\n",
        "  def call(self, conv_output_conc, inputs):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      if inputs.shape[1] <= 1 or inputs.shape[2] <= 1:\n",
        "\n",
        "          target_size = (max(conv_output_conc.shape[1], 1), max(conv_output_conc.shape[2], 1))\n",
        "          u = tf.image.resize(inputs, target_size)\n",
        "      else:\n",
        "          u = self.convTranspose(inputs)\n",
        "\n",
        "\n",
        "      if u.shape[1:3] != conv_output_conc.shape[1:3]:\n",
        "\n",
        "          if u.shape[1] * u.shape[2] < conv_output_conc.shape[1] * conv_output_conc.shape[2]:\n",
        "              u = tf.image.resize(u, (conv_output_conc.shape[1], conv_output_conc.shape[2]))\n",
        "          else:\n",
        "              conv_output_conc = tf.image.resize(conv_output_conc, (u.shape[1], u.shape[2]))\n",
        "\n",
        "      c = self.concat([u, conv_output_conc])\n",
        "      c = self.dropout(c)\n",
        "      c = self.conv(c)\n",
        "      return c"
      ],
      "metadata": {
        "id": "HKqiRcGr83D5"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder_for_unet_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self,num_classes = 19):\n",
        "    super().__init__()\n",
        "    self.decoder11 = Decoder_Block_for_unet_plus_plus(n_filters=64  , dropout = 0.3, block_name = 'skip_conv_block_11')\n",
        "    self.decoder12 = Decoder_Block_for_unet_plus_plus(n_filters=64  , dropout = 0.3, block_name = 'skip_conv_block_12')\n",
        "    self.decoder13 = Decoder_Block_for_unet_plus_plus(n_filters=64  , dropout = 0.3, block_name = 'skip_conv_block_13')\n",
        "    self.decoder14 = Decoder_Block_for_unet_plus_plus(n_filters=64  , dropout = 0.3, block_name = 'skip_conv_block_14')\n",
        "    self.decoder21 = Decoder_Block_for_unet_plus_plus(n_filters=128  , dropout = 0.3, block_name = 'skip_conv_block_21')\n",
        "    self.decoder22 = Decoder_Block_for_unet_plus_plus(n_filters=128  , dropout = 0.3, block_name = 'skip_conv_block_22')\n",
        "    self.decoder23 = Decoder_Block_for_unet_plus_plus(n_filters=128  , dropout = 0.3, block_name = 'skip_conv_block_23')\n",
        "    self.decoder31 = Decoder_Block_for_unet_plus_plus(n_filters=256  , dropout = 0.3, block_name = 'skip_conv_block_31')\n",
        "    self.decoder32 = Decoder_Block_for_unet_plus_plus(n_filters=256  , dropout = 0.3, block_name = 'skip_conv_block_32')\n",
        "    self.decoder41 = Decoder_Block_for_unet_plus_plus(n_filters=512  , dropout = 0.3, block_name = 'skip_conv_block_41')\n",
        "\n",
        "    self.concat12=tf.keras.layers.Concatenate()\n",
        "    self.concat13=tf.keras.layers.Concatenate()\n",
        "    self.concat14=tf.keras.layers.Concatenate()\n",
        "\n",
        "    self.concat22=tf.keras.layers.Concatenate()\n",
        "    self.concat23=tf.keras.layers.Concatenate()\n",
        "\n",
        "    self.concat32=tf.keras.layers.Concatenate()\n",
        "    self.bottle_neck = BottleNeck_for_unet_plus_plus()\n",
        "    self.output_layer14 = tf.keras.layers.Conv2D(\n",
        "        filters=num_classes,\n",
        "        kernel_size=(1,1),\n",
        "        activation='sigmoid' if num_classes == 1 else 'softmax',\n",
        "        padding='same',\n",
        "        name='output_layer'\n",
        "        )\n",
        "    self.output_layer13 = tf.keras.layers.Conv2D(\n",
        "        filters=num_classes,\n",
        "        kernel_size=(1,1),\n",
        "        activation='sigmoid' if num_classes == 1 else 'softmax',\n",
        "        padding='same',\n",
        "        name='output_layer'\n",
        "        )\n",
        "    self.output_layer12 = tf.keras.layers.Conv2D(\n",
        "        filters=num_classes,\n",
        "        kernel_size=(1,1),\n",
        "        activation='sigmoid' if num_classes == 1 else 'softmax',\n",
        "        padding='same',\n",
        "        name='output_layer'\n",
        "        )\n",
        "    self.output_layer11 = tf.keras.layers.Conv2D(\n",
        "        filters=num_classes,\n",
        "        kernel_size=(1,1),\n",
        "        activation='sigmoid' if num_classes == 1 else 'softmax',\n",
        "        padding='same',\n",
        "        name='output_layer'\n",
        "        )\n",
        "\n",
        "  def call(self, convs_cont , pool_cont):\n",
        "    f1,f2,f3,f4 = convs_cont\n",
        "    p1,p2,p3,p4 = pool_cont\n",
        "    for i, feat in enumerate([f1, f2, f3, f4, p1, p2, p3, p4]):\n",
        "        if feat.shape[1] < 1 or feat.shape[2] < 1:\n",
        "            print(f\"Warning: Feature map {i} has invalid dimensions: {feat.shape}\")\n",
        "    p5 = self.bottle_neck(p4)\n",
        "    decoder41 = self.decoder41(f4,p5)\n",
        "    decoder31 = self.decoder31(f3,p4)\n",
        "    conc32 = self.concat32([f3 , decoder31])\n",
        "    decoder32 = self.decoder32(conc32 , decoder41)\n",
        "    decoder21 = self.decoder21(f2,p3)\n",
        "    conc22 = self.concat22([f2,decoder21])\n",
        "    decoder22 = self.decoder22(conc22 , decoder31)\n",
        "    conc23 = self.concat23([f2,decoder21, decoder22])\n",
        "    decoder23 = self.decoder23(conc23 , decoder32)\n",
        "    decoder11 = self.decoder11(f1,p2)\n",
        "    conc12 = self.concat12([f1,decoder11])\n",
        "    decoder12 = self.decoder12(conc12 , decoder21)\n",
        "    conc13 = self.concat13([f1,decoder11,decoder12])\n",
        "    decoder13 = self.decoder13(conc13 , decoder22)\n",
        "    conc14 = self.concat14([f1 , decoder11  , decoder12 , decoder13])\n",
        "    decoder14 = self.decoder14(conc14 , decoder23)\n",
        "    output14 = self.output_layer14(decoder14)\n",
        "    output13 = self.output_layer13(decoder13)\n",
        "    output12 = self.output_layer12(decoder12)\n",
        "    output11 = self.output_layer11(decoder11)\n",
        "    return output11,output12,output13,output14"
      ],
      "metadata": {
        "id": "i9jopfkfASqD"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Unet_plus_plus(tf.keras.models.Model):\n",
        "    def __init__(self, min_input_size=16):\n",
        "        super().__init__()\n",
        "        self.min_input_size = min_input_size\n",
        "        self.encoder = Encoder_for_unt_plus_plus()\n",
        "        self.decoder = Decoder_for_unet_plus_plus()\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        input_shape = inputs.shape\n",
        "        if input_shape[1] < self.min_input_size or input_shape[2] < self.min_input_size:\n",
        "            raise ValueError(f\"Input image dimensions must be at least {self.min_input_size}x{self.min_input_size}\")\n",
        "\n",
        "        y, z = self.encoder(inputs)\n",
        "        output11, output12, output13, output14 = self.decoder(y, z)\n",
        "        return output11, output12, output13, output14"
      ],
      "metadata": {
        "id": "_QbqnnYvIS-v"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model122 = Unet_plus_plus()"
      ],
      "metadata": {
        "id": "QhvmJp5cJ86_"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model122.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "vytgogDGKqcW",
        "outputId": "25a03a28-3999-4cd3-d5a9-87f3ec64b911"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"unet_plus_plus\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"unet_plus_plus\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_for_unt_plus_plus            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mEncoder_for_unt_plus_plus\u001b[0m)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder_for_unet_plus_plus           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mDecoder_for_unet_plus_plus\u001b[0m)         │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_for_unt_plus_plus            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder_for_unt_plus_plus</span>)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder_for_unet_plus_plus           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder_for_unet_plus_plus</span>)         │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**testing code for model**"
      ],
      "metadata": {
        "id": "bYo7fCzYMLoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "input_shape = (1, 256,256, 3)\n",
        "random_input = tf.random.normal(input_shape)\n",
        "\n",
        "# Initialize model\n",
        "\n",
        "\n",
        "# Run forward pass\n",
        "outputs = model122(random_input)\n",
        "\n",
        "# Print output shapes\n",
        "output_names = [\"fcn32\", \"fcn16\", \"fcn8\", \"fcn4\", \"fcn2\"]\n",
        "for name, out in zip(output_names, outputs):\n",
        "    print(f\"{name} output shape: {out.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO-8NqIPMOyR",
        "outputId": "38b428ee-63ab-4d41-f729-edbea30baa04"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fcn32 output shape: (1, 256, 256, 19)\n",
            "fcn16 output shape: (1, 256, 256, 19)\n",
            "fcn8 output shape: (1, 256, 256, 19)\n",
            "fcn4 output shape: (1, 256, 256, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model122.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "F_v-YwqH5Izm",
        "outputId": "32ba2ebf-2a8c-4ede-d233-c49b0e6473d5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"unet_plus_plus\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"unet_plus_plus\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_for_unt_plus_plus            │ ?                           │       \u001b[38;5;34m4,685,376\u001b[0m │\n",
              "│ (\u001b[38;5;33mEncoder_for_unt_plus_plus\u001b[0m)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder_for_unet_plus_plus           │ ?                           │      \u001b[38;5;34m36,064,972\u001b[0m │\n",
              "│ (\u001b[38;5;33mDecoder_for_unet_plus_plus\u001b[0m)         │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_for_unt_plus_plus            │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,685,376</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder_for_unt_plus_plus</span>)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder_for_unet_plus_plus           │ ?                           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">36,064,972</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder_for_unet_plus_plus</span>)         │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,750,348\u001b[0m (155.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,750,348</span> (155.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,750,348\u001b[0m (155.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,750,348</span> (155.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model122.save('model.keras')"
      ],
      "metadata": {
        "id": "Y2mqdoHT5-U1"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files"
      ],
      "metadata": {
        "id": "K-t_7gG7z_TV"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# files.download('model.h5')"
      ],
      "metadata": {
        "id": "ERGbIpq80CJq"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# files.download('model.keras')"
      ],
      "metadata": {
        "id": "Py27qFeK0F75"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initilizating instaces of the models**"
      ],
      "metadata": {
        "id": "fIfwcCtrYxqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Fcn =FCN()\n",
        "Unet = Unet()\n",
        "Unet_plus_plus = Unet_plus_plus()"
      ],
      "metadata": {
        "id": "Q-hssWV3olla"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**defining loss**"
      ],
      "metadata": {
        "id": "pG9N7x9NpFX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "with strategy.scope():\n",
        "    class DiceLoss(tf.keras.losses.Loss):\n",
        "        def __init__(self, smooth=1e-6):\n",
        "            super().__init__()\n",
        "            self.smooth = smooth\n",
        "\n",
        "        def call(self, y_true, y_pred):\n",
        "\n",
        "            y_true_f = tf.keras.backend.flatten(tf.one_hot(tf.cast(y_true , tf.int32), depth=tf.shape(y_pred)[-1]))\n",
        "            y_pred_f = tf.keras.backend.flatten((y_pred))\n",
        "\n",
        "            intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "            denominator = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
        "\n",
        "            dice_loss = 1 - (2.0 * intersection + self.smooth) / (denominator + self.smooth)\n",
        "            return dice_loss\n",
        "\n",
        "with strategy.scope():\n",
        "    class SemanticSegmentationLoss(tf.keras.losses.Loss):\n",
        "        def __init__(self , alpha = 1.0 , beta = 1.0):\n",
        "            super().__init__()\n",
        "            self.dice_loss = DiceLoss()\n",
        "            self.alpha = alpha\n",
        "            self.beta = beta\n",
        "\n",
        "        def call(self, y_true, y_pred):\n",
        "\n",
        "            ce = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
        "            dice_loss = self.dice_loss(y_true, y_pred)\n",
        "            return self.alpha * ce +self.beta * dice_loss\n"
      ],
      "metadata": {
        "id": "Zgqf26VNpmJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  class DeepSupervisionLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, weights=None, smooth=1e-6):\n",
        "      super().__init__()\n",
        "      self.smooth = smooth\n",
        "      self.weights = weights if weights else [1.0]\n",
        "      self.ce_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    def dice_loss(self, y_true, y_pred):\n",
        "      y_true_f = tf.keras.backend.flatten(tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[-1]))\n",
        "      y_pred_f = tf.keras.backend.flatten((y_pred))\n",
        "      intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "      denominator = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
        "      return 1 - (2.0 * intersection + self.smooth) / (denominator + self.smooth)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "      total_loss = 0.0\n",
        "      num_outputs = len(y_pred)\n",
        "      for i in range(num_outputs):\n",
        "        ce = self.ce_loss(y_true, y_pred[i])\n",
        "        dice = self.dice_loss(y_true, y_pred[i])\n",
        "        total_loss += self.weights[i] * (ce + dice)\n",
        "      return total_loss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "VLllqFTgQm4p",
        "outputId": "a67ff78c-5c8b-4378-aa7c-453eeec9045c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'strategy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-374a16bfa081>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0mDeepSupervisionLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'strategy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    optimizer = mixed_precision.LossScaleOptimizer(tf.keras.optimizers.Adam(learning_rate=1e-5), dynamic=True)"
      ],
      "metadata": {
        "id": "p00KctQJsIL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IOU metric**"
      ],
      "metadata": {
        "id": "HqLy6d_fQqWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IOUMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, n_classes=19, smooth=1e-6, name=\"iou\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.n_classes = n_classes\n",
        "        self.smooth = smooth\n",
        "        self.iou_sum = self.add_weight(name=\"iou_sum\", initializer=\"zeros\")\n",
        "        self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n",
        "    @tf.function\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "\n",
        "        y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=self.n_classes)\n",
        "        # y_pred = tf.nn.softmax(y_pred, axis=-1)\n",
        "\n",
        "\n",
        "        intersection = tf.reduce_sum(y_true * y_pred, axis=[0, 1, 2])\n",
        "        union = tf.reduce_sum(y_true, axis=[0, 1, 2]) + tf.reduce_sum(y_pred, axis=[0, 1, 2]) - intersection\n",
        "\n",
        "\n",
        "        iou_per_class = (intersection + self.smooth) / (union + self.smooth)\n",
        "\n",
        "\n",
        "        valid_classes = tf.cast(union > 0, tf.float32)\n",
        "        num_valid_classes = tf.reduce_sum(valid_classes)\n",
        "\n",
        "\n",
        "        mean_iou = tf.reduce_sum(iou_per_class * valid_classes) / tf.maximum(num_valid_classes, 1.0)\n",
        "\n",
        "\n",
        "        self.iou_sum.assign_add(mean_iou)\n",
        "        self.count.assign_add(1)\n",
        "    @tf.function\n",
        "    def result(self):\n",
        "        return self.iou_sum / tf.maximum(self.count, 1.0)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.iou_sum.assign(0)\n",
        "        self.count.assign(0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"n_classes\": self.n_classes, \"smooth\": self.smooth})\n",
        "        return config\n"
      ],
      "metadata": {
        "id": "fyxUTVNmwvIY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**per class IOU metrics**"
      ],
      "metadata": {
        "id": "Jb5ZLJrUQxgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PerClassIOUMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, n_classes=19, smooth=1e-6, name=\"iou_per_class\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.n_classes = n_classes\n",
        "        self.smooth = smooth\n",
        "        self.sum_union = self.add_weight(name=\"sum_union\", shape=(n_classes,), initializer=\"zeros\")\n",
        "        self.sum_intersection = self.add_weight(name=\"sum_intersection\", shape=(n_classes,), initializer=\"zeros\")\n",
        "    @tf.function\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "\n",
        "        y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.n_classes)\n",
        "\n",
        "\n",
        "        intersection = tf.reduce_sum(y_true * y_pred, axis=[0, 1, 2])\n",
        "        union = tf.reduce_sum(y_true, axis=[0, 1, 2]) + tf.reduce_sum(y_pred, axis=[0, 1, 2]) - intersection\n",
        "\n",
        "\n",
        "        self.sum_union.assign_add(union)\n",
        "        self.sum_intersection.assign_add(intersection)\n",
        "    @tf.function\n",
        "    def result(self):\n",
        "        return (self.sum_intersection + self.smooth) / (self.sum_union + self.smooth)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.sum_intersection.assign(tf.zeros_like(self.sum_intersection))\n",
        "        self.sum_union.assign(tf.zeros_like(self.sum_union))\n"
      ],
      "metadata": {
        "id": "XVQfJePV-tjG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dice Coeficient Metrics**"
      ],
      "metadata": {
        "id": "UI8rv85Uic1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dice_Coefficent_matrics(tf.keras.metrics.Metric):\n",
        "  def __init__(self, n_classes = 19 , smooth = 1e-6 , name = 'dice coefficent' , **kwargs):\n",
        "    super().__init__(name = name , **kwargs)\n",
        "    self.n_classes = n_classes\n",
        "    self.smooth = smooth\n",
        "    self.sum_dice_coefficent =self.add_weight(name=\"sum_dice_coeffient\", initializer=\"zeros\")\n",
        "    self.count =self.add_weight(name=\"count\", initializer=\"zeros\")\n",
        "  @tf.function\n",
        "  def update_state(self, y_true , y_pred , sample_weight = None):\n",
        "    y_true = tf.one_hot(tf.cast(y_true , dtype= tf.int32) , depth=self.n_classes)\n",
        "\n",
        "    intersection = tf.reduce_sum (y_true * y_pred , axis = [0,1,2])\n",
        "    total_area = tf.reduce_sum(y_pred, axis=[0,1,2])  + tf.reduce_sum(y_true , axis=[0,1,2])\n",
        "\n",
        "    dice_score = 2 * (intersection+ self.smooth)/(total_area +self.smooth)\n",
        "    valid_classes = tf.cast(total_area > 0, tf.float32)\n",
        "    num_valid_classes = tf.reduce_sum(valid_classes)\n",
        "\n",
        "    mean_dice = tf.reduce_sum(dice_score * valid_classes) / tf.maximum(num_valid_classes, 1.0)\n",
        "\n",
        "    self.sum_dice_coefficent.assign_add(dice_score)\n",
        "    self.count.assign_add(1)\n",
        "  @tf.function\n",
        "  def result(self ):\n",
        "    return self.sum_dice_coefficent/tf.maximum(self.count, 1.0)\n",
        "  def reset_state(self):\n",
        "    self.sum_dice_coefficent.assign(0)\n",
        "    self.count.assign(0)"
      ],
      "metadata": {
        "id": "UVd2Y6GxVtPl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**per class_dice_coefficent metrics**"
      ],
      "metadata": {
        "id": "YLNA7ijum2vZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PerClassDiceCoefficient(tf.keras.metrics.Metric):\n",
        "    def __init__(self, n_classes=19, smooth=1e-6, name=\"dice_per_class\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.n_classes = n_classes\n",
        "        self.smooth = smooth\n",
        "        self.sum_intersection = self.add_weight(name=\"sum_intersection\", shape=(n_classes,), initializer=\"zeros\")\n",
        "        self.sum_union = self.add_weight(name=\"sum_union\", shape=(n_classes,), initializer=\"zeros\")\n",
        "    @tf.function\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "\n",
        "        y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.n_classes)\n",
        "\n",
        "        intersection = tf.reduce_sum(y_true * y_pred, axis=[0, 1, 2])\n",
        "        sum_areas = tf.reduce_sum(y_true, axis=[0, 1, 2]) + tf.reduce_sum(y_pred, axis=[0, 1, 2])\n",
        "\n",
        "        self.sum_intersection.assign_add(intersection)\n",
        "        self.sum_union.assign_add(sum_areas)\n",
        "    @tf.function\n",
        "    def result(self):\n",
        "        return (2.0 * self.sum_intersection + self.smooth) / (self.sum_union + self.smooth)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.sum_intersection.assign(tf.zeros_like(self.sum_intersection))\n",
        "        self.sum_union.assign(tf.zeros_like(self.sum_union))\n"
      ],
      "metadata": {
        "id": "qd-b0q9nmYZd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pixel Accurcy Metrics**"
      ],
      "metadata": {
        "id": "JkxRcmDDnKth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Pixel_accurcy_metrics(tf.keras.metrics.Metric):\n",
        "  def __init__(self, n_classes = 19  , name = 'pixel_accurcy_metrics' , **kwargs):\n",
        "    super().__init__(name = name , **kwargs)\n",
        "    self.n_classes = n_classes\n",
        "    self.sum_pixel_wise_accurcy = self.add_weight(name=\"sum_pixel_wise_accurcy\", initializer=\"zeros\")\n",
        "    self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n",
        "  @tf.function\n",
        "  def update_state(self, y_true , y_pred  , sample_weight  = None) :\n",
        "    y_true = tf.one_hot(tf.cast(y_true , dtype=tf.int32) , depth = self.n_classes)\n",
        "    y_pred = tf.one_hot(tf.argmax(y_pred , axis=-1) , depth = self.n_classes)\n",
        "    correct_pixel = tf.reduce_sum(y_true * y_pred)\n",
        "    total_pixel = tf.reduce_prod(tf.shape(y_true)[:-1])\n",
        "    pixel_accuracy = (correct_pixel)/tf.maximum(total_pixel,1.0)\n",
        "    self.sum_pixel_wise_accurcy.assign_add(pixel_accuracy)\n",
        "    self.count.assign_add(1)\n",
        "  @tf.function\n",
        "  def result(self):\n",
        "    return self.sum_pixel_wise_accurcy/tf.maximum(self.count, 1.0)\n",
        "  def reset_state(self):\n",
        "    self.sum_pixel_wise_accurcy.assign(0)\n",
        "    self.count.assign(0)"
      ],
      "metadata": {
        "id": "boqIP7CWm8Gy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**optimizer**"
      ],
      "metadata": {
        "id": "hbxDqaLiU2LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  optimizer_fcn = tf.optimizers.AdamW(learning_rate=1e-4 , weight_decay=1e-5)\n",
        "  optimizer_unet = tf.optimizers.AdamW(learning_rate=1e-4 , weight_decay=1e-5)\n",
        "  optimizer_unet_plus_plus = tf.optimizers.AdamW(learning_rate=1e-4 , weight_decay=1e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "3rhyJcz4U4dz",
        "outputId": "a0f0d013-d57b-4f16-d667-328ca31c54a6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'strategy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-0e476b9f6ee6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'strategy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_fcn = tf.optimizers.AdamW(learning_rate=1e-4 , weight_decay=1e-5)\n",
        "optimizer_unet = tf.optimizers.AdamW(learning_rate=1e-4 , weight_decay=1e-5)\n",
        "optimizer_unet_plus_plus = tf.optimizers.AdamW(learning_rate=1e-4 , weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "EkI53Row67bK"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**checkPoint dirs**"
      ],
      "metadata": {
        "id": "j72q95Pjob9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir_fcn = '/content/drive/MyDrive/CityScapes_model_checkpoints/fcn'\n",
        "checkpoint_dir_unet = '/content/drive/MyDrive/CityScapes_model_checkpoints/unet'\n",
        "checkpoint_dir_unet_plus_plus = '/content/drive/MyDrive/CityScapes_model_checkpoints/unet_plus_plus'"
      ],
      "metadata": {
        "id": "Jolqu8_FoelE"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**custom callbacks**"
      ],
      "metadata": {
        "id": "Wr83oImgE-T7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Custom_checkpoint_Callabck(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, checkpoint_dir_fcn , checkpoint_dir_unet , checkpoint_dir_unet_plus_plus , fcn , unet , unet_plus_plus , optimizer_fcn ,optimizer_unet ,optimizer_unet_plus_plus  ) :\n",
        "    super().__init__()\n",
        "    self.checkpoint_dir_fcn = checkpoint_dir_fcn\n",
        "    self.checkpoint_dir_unet = checkpoint_dir_unet\n",
        "    self.checkpoint_dir_unet_plus_plus = checkpoint_dir_unet_plus_plus\n",
        "    self.checkpoint_fcn = tf.train.Checkpoint(\n",
        "        model = fcn ,\n",
        "        optimizer = optimizer_fcn,\n",
        "        epoch = tf.Variable(0 , dtype = tf.int64)\n",
        "    )\n",
        "    self.checkpoint_manager_for_fcn = tf.train.CheckpointManager(\n",
        "        self.checkpoint_fcn ,\n",
        "        self.checkpoint_dir_fcn ,\n",
        "        max_to_keep=3\n",
        "    )\n",
        "    self.checkpoint_unet = tf.train.Checkpoint(\n",
        "        model = unet ,\n",
        "        optimizer = optimizer_unet,\n",
        "        epoch = tf.Variable(0 , dtype = tf.int64)\n",
        "    )\n",
        "    self.checkpoint_manager_for_unet = tf.train.CheckpointManager(\n",
        "        self.checkpoint_unet ,\n",
        "        self.checkpoint_dir_unet ,\n",
        "        max_to_keep=3\n",
        "    )\n",
        "    self.checkpoint_unet_plus_plus = tf.train.Checkpoint(\n",
        "        model = unet_plus_plus ,\n",
        "        optimizer = optimizer_unet_plus_plus,\n",
        "        epoch = tf.Variable(0 , dtype = tf.int64)\n",
        "    )\n",
        "    self.checkpoint_manager_for_unet_plus_plus = tf.train.CheckpointManager(\n",
        "        self.checkpoint_unet_plus_plus ,\n",
        "        self.checkpoint_dir_unet_plus_plus ,\n",
        "        max_to_keep=3\n",
        "    )\n",
        "  def on_epoch_end(self , epoch, logs = None):\n",
        "    self.checkpoint_fcn.epoch.assign(epoch+1)\n",
        "    self.checkpoint_manager_for_fcn.save()\n",
        "    print(f\"\\nCheckpoint saved for epoch {epoch + 1} at {self.checkpoint_manager_for_fcn.latest_checkpoint} for fcn model\")\n",
        "    self.checkpoint_unet.epoch.assign(epoch+1)\n",
        "    self.checkpoint_manager_for_unet.save()\n",
        "    print(f\"\\nCheckpoint saved for epoch {epoch + 1} at {self.checkpoint_manager_for_unet.latest_checkpoint} for unet model\")\n",
        "    self.checkpoint_unet_plus_plus.epoch.assign(epoch+1)\n",
        "    self.checkpoint_manager_for_unet_plus_plus.save()\n",
        "    print(f\"\\nCheckpoint saved for epoch {epoch + 1} at {self.checkpoint_manager_for_unet_plus_plus.latest_checkpoint} for unet_plus_plus model\")\n",
        "  def load_latest_model(self):\n",
        "    if self.checkpoint_manager_for_fcn.latest_checkpoint and self.checkpoint_manager_for_unet.latest_checkpoint and self.checkpoint_manager_for_unet_plus_plus.latest_checkpoint :\n",
        "\n",
        "      self.checkpoint_fcn.restore(self.checkpoint_manager_for_fcn.latest_checkpoint)\n",
        "      self.checkpoint_unet.restore(self.checkpoint_manager_for_unet.latest_checkpoint)\n",
        "      self.checkpoint_unet_plus_plus.restore(self.checkpoint_manager_for_unet_plus_plus.latest_checkpoint)\n",
        "      start_epoch =self.checkpoint_fcn.epoch.numpy()\n",
        "      print(f\"Restored from checkpoint: {self.checkpoint_manager_for_fcn.latest_checkpoint}, \"\n",
        "                  f\"resuming from epoch {start_epoch}\")\n",
        "      print(f\"Restored from checkpoint: {self.checkpoint_manager_for_unet.latest_checkpoint}, \"\n",
        "                  f\"resuming from epoch {start_epoch}\")\n",
        "      print(f\"Restored from checkpoint: {self.checkpoint_manager_for_unet_plus_plus.latest_checkpoint}, \"\n",
        "                  f\"resuming from epoch {start_epoch}\")\n",
        "      return start_epoch\n",
        "    else :\n",
        "      print('no checkpoint found starting from epoch 0')\n",
        "      return 0\n",
        ""
      ],
      "metadata": {
        "id": "az4V0gCqFDCt"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Custom_checkpoint_Callabck = Custom_checkpoint_Callabck(checkpoint_dir_fcn=checkpoint_dir_fcn , checkpoint_dir_unet=checkpoint_dir_unet , checkpoint_dir_unet_plus_plus=checkpoint_dir_unet_plus_plus , fcn=Fcn , unet=Unet , unet_plus_plus=Unet_plus_plus ,optimizer_fcn=optimizer_fcn,optimizer_unet=optimizer_unet,optimizer_unet_plus_plus=optimizer_unet_plus_plus)"
      ],
      "metadata": {
        "id": "tzRqX1rFdqTZ"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class custom_early_stoping_callback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, patiance = 15 , min_delta=1e-6):\n",
        "    self.patiance = patiance\n",
        "    self.min_delta =min_delta\n",
        "    self.best_loss = float('inf')\n",
        "    self.wait = 0\n",
        "    self.stoped_epoch = 0\n",
        "  def early_stoping(self, epoch , val_loss):\n",
        "    if val_loss < self.best_loss - self.min_delta :\n",
        "      self.best_loss = val_loss\n",
        "      self.wait = 0\n",
        "    else :\n",
        "      self.wait +=1\n",
        "      if (self.wait >= self.patiance):\n",
        "        self.stoped_epoch = epoch\n",
        "        print(f'early stoped at epoch = {self.stoped_epoch}')\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "DVXgPJuj7mdm"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class custom_learning_rate_sceduler(tf.keras.callbacks.Callback):\n",
        ""
      ],
      "metadata": {
        "id": "_m7da_J8G566"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}