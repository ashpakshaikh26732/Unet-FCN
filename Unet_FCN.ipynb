{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1B12W-D6S226pHFryN9Y2XzlBbHV5Pvsg",
      "authorship_tag": "ABX9TyPU0CIKiaxwwg/xA7TKTbLK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashpakshaikh26732/Unet-FCN/blob/main/Unet_FCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**all packages**"
      ],
      "metadata": {
        "id": "5XRgNljpyU9b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mm_LuZ1iev66"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "  print(f'no of tpus : {strategy.num_replicas_in_sync}')\n",
        "except ValueError :\n",
        "  print('tpu failed to initilized')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTuYhVhRffta",
        "outputId": "139f0800-e1c6-4ff7-d6ef-2d44caf2b52d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use the non-experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no of tpus : 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**mixed precision training**"
      ],
      "metadata": {
        "id": "tzwsFyykuBp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "I9g7HnQsuOMj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vQK2Gy1ggZP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb5baac7-0aeb-43b3-a730-8e14cebd5353"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**copy datasets from drive**"
      ],
      "metadata": {
        "id": "XLI9cZz46258"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Cityscapes/gtFine_trainvaltest.zip /content/\n",
        "!cp /content/drive/MyDrive/Cityscapes/leftImg8bit_trainvaltest.zip /content"
      ],
      "metadata": {
        "id": "_cb4xI4h5b3z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**extract trainig the data**"
      ],
      "metadata": {
        "id": "gWcHvq9T67yT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.system(\"unzip -q /content/gtFine_trainvaltest.zip -d /content/ \")\n",
        "os.system(\"unzip -q /content/leftImg8bit_trainvaltest.zip -d /content/\")"
      ],
      "metadata": {
        "id": "gIGN5YpV58XW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73dd156-bfa6-4531-bbb9-4e0f3944461a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Images:\", len(os.listdir(\"/content/leftImg8bit/train/aachen\")))  # Adjust path as needed\n",
        "print(\"Train Labels:\", len(os.listdir(\"/content/gtFine/train/aachen\")))"
      ],
      "metadata": {
        "id": "-MKUIQNX7naD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39689e4f-2381-44dc-f983-1d5db1c2f73e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images: 174\n",
            "Train Labels: 696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"test images : \", len(os.listdir('/content/leftImg8bit/test')))"
      ],
      "metadata": {
        "id": "qafiZBb5yC0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8e4dfdb-2b3f-4384-9f1c-a76fcc33b07a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test images :  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Global Valrible**"
      ],
      "metadata": {
        "id": "9Q1cFO0jJcA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 224\n",
        "img_width = 224\n",
        "batch_size = 16\n",
        "# final_batch_size = batch_size * strategy.num_replicas_in_sync"
      ],
      "metadata": {
        "id": "3NSFJ69oJiMF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**loading images and labels from directry**"
      ],
      "metadata": {
        "id": "J9Y6CZKmCbNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img():\n",
        "    train_dir = '/content/leftImg8bit/train'\n",
        "    train_image_cities = os.listdir(train_dir)\n",
        "    train_images = []\n",
        "\n",
        "    for city in train_image_cities:\n",
        "        train_city = os.path.join(train_dir, city)\n",
        "        images = [os.path.join(train_city, img) for img in os.listdir(train_city) if img.endswith('.png')]\n",
        "        train_images.extend(images)\n",
        "\n",
        "    return train_images\n",
        "\n",
        "def load_labels():\n",
        "    train_dir = '/content/gtFine/train'\n",
        "    train_labels_cities = os.listdir(train_dir)\n",
        "    train_labels = []\n",
        "    for city in train_labels_cities:\n",
        "        train_city_label = os.path.join(train_dir, city)\n",
        "        labels = [f for f in os.listdir(train_city_label) if f.endswith('_gtFine_labelIds.png')]\n",
        "        for label in labels:\n",
        "            label_path = os.path.join(train_city_label, label)\n",
        "            train_labels.append(label_path)\n",
        "    return train_labels"
      ],
      "metadata": {
        "id": "OzTJuxSUyT19"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**reading images from path**"
      ],
      "metadata": {
        "id": "cGkR1OkdChy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_img(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, (img_height, img_width))\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "def read_labels(label_path):\n",
        "    label = tf.io.read_file(label_path)\n",
        "    label = tf.io.decode_png(label, channels=1)\n",
        "    label = tf.image.resize(label, (img_height, img_width), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    return tf.cast(label, tf.uint8)\n"
      ],
      "metadata": {
        "id": "tR2-lYACFmLh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**augmentation**"
      ],
      "metadata": {
        "id": "PMQ2HsmKQtqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment(image, label):\n",
        "\n",
        "    label = tf.cast(label, tf.float32)\n",
        "\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "        label = tf.image.flip_left_right(label)\n",
        "\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "\n",
        "    combined = tf.concat([image, label], axis=-1)\n",
        "    combined = tf.image.random_crop(combined, size=[224, 224, 6])\n",
        "\n",
        "    image, label = tf.split(combined, num_or_size_splits=2, axis=-1)\n",
        "\n",
        "\n",
        "    label = tf.cast(label, tf.uint8)\n",
        "\n",
        "    return image, label\n"
      ],
      "metadata": {
        "id": "ArL30hPWQzQc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**creating dataset**"
      ],
      "metadata": {
        "id": "AMrQX_bwIrwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = load_img()\n",
        "labels = load_labels()\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "dataset = dataset.map(lambda image_path , label_path :( read_img(image_path) , label_path)).map(lambda image , label_path : (image,read_labels(label_path=label_path)))\n",
        "dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset = dataset.shuffle(buffer_size=1000).cache().batch(batch_size)\n",
        "dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "oiZ4wr51HQR_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for image , label in dataset.take(1):\n",
        "#   print(f'image shape : {image.shape} , label shape {label.shape}')\n",
        "#   print(f'image datatype : {image.dtype}, label dtype {label.dtype}')"
      ],
      "metadata": {
        "id": "l4asEByyJz3k"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FCN model**"
      ],
      "metadata": {
        "id": "71fnRZr6XnEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(tf.keras.models.Model):\n",
        "    def __init__(self, n_conv, filters, kernel_size, activation, pool_size, pool_stride, block_name):\n",
        "        super().__init__()\n",
        "        self.conv_layers = [\n",
        "            tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding='same',\n",
        "                                   activation=activation, name=f\"{block_name}_conv{i+1}\")\n",
        "            for i in range(n_conv)\n",
        "        ]\n",
        "        self.pool = tf.keras.layers.MaxPool2D(pool_size=pool_size, strides=pool_stride, name=f\"{block_name}_pool\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for conv in self.conv_layers:\n",
        "            x = conv(x)\n",
        "        x = self.pool(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lYYeYAZ7WKGM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.block1 = Block(n_conv=2 , filters=64 , kernel_size = (3,3) , activation ='relu' , pool_size=(2,2) , pool_stride = (2,2) , block_name = 'block1')\n",
        "    self.block2 = Block(n_conv=3 , filters = 128 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block2')\n",
        "    self.block3 = Block(n_conv=3 , filters = 256 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block3')\n",
        "    self.block4 = Block(n_conv=3 , filters = 512 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block4')\n",
        "    self.block5 = Block(n_conv=3 , filters = 512 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block5')\n",
        "  def call(self,inputs):\n",
        "    p1 = self.block1(inputs)\n",
        "    p2 = self.block2(p1)\n",
        "    p3 = self.block3(p2)\n",
        "    p4 = self.block4(p3)\n",
        "    p5 = self.block5(p4)\n",
        "    return p1 , p2 , p3 , p4 , p5"
      ],
      "metadata": {
        "id": "qTQFaELPY5CU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.models.Model):\n",
        "    def __init__(self, nclasses):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.upsample1 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.upsample2 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.upsample3 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "\n",
        "\n",
        "        self.skip1 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), activation='relu', padding='same')\n",
        "        self.skip2 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), activation='relu', padding='same')\n",
        "        self.skip3 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), activation='relu', padding='same')\n",
        "\n",
        "\n",
        "        self.add1 = tf.keras.layers.Add()\n",
        "        self.add2 = tf.keras.layers.Add()\n",
        "        self.add3 = tf.keras.layers.Add()\n",
        "\n",
        "\n",
        "        self.fcn32 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(32, 32), strides=(32, 32), padding='same', name='fcn32')\n",
        "        self.fcn16 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(16, 16), strides=(16, 16), padding='same', name='fcn16')\n",
        "        self.fcn8 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(8, 8), strides=(8, 8), padding='same', name='fcn8')\n",
        "        self.fcn4 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(4, 4), padding='same', name='fcn4')\n",
        "\n",
        "\n",
        "        self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        p1, p2, p3, p4, p5 = inputs\n",
        "\n",
        "        fcn32 = self.fcn32(p5)\n",
        "\n",
        "\n",
        "        o = self.upsample1(p5)\n",
        "        o = self.add1([o, self.skip1(p4)])\n",
        "        fcn16 = self.fcn16(o)\n",
        "\n",
        "\n",
        "        o = self.upsample2(o)\n",
        "        o = self.add2([o, self.skip2(p3)])\n",
        "        fcn8 = self.fcn8(o)\n",
        "\n",
        "\n",
        "        o = self.upsample3(o)\n",
        "        o = self.add3([o, self.skip3(p2)])\n",
        "        fcn4 = self.fcn4(o)\n",
        "\n",
        "\n",
        "        return self.softmax(fcn32), self.softmax(fcn16), self.softmax(fcn8), self.softmax(fcn4)"
      ],
      "metadata": {
        "id": "C7urJTNYZAVO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FCN(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Encoder = Encoder()\n",
        "    self.Decoder = Decoder(19)\n",
        "  def call(self, inputs):\n",
        "    x=self.Encoder(inputs)\n",
        "    x = self.Decoder(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "4WXzcbDYZOJ5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**UNET**"
      ],
      "metadata": {
        "id": "t99faxaF2nJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters,block_name , kernel_size=3 , strides = (1,1) , activation='relu'):\n",
        "    super().__init__()\n",
        "    self.conv = [tf.keras.layers.Conv2D(filters=n_filters , strides=strides , kernel_size=(kernel_size, kernel_size) , activation='relu', name=f\"{block_name}_conv{i+1}\", padding='same') for i in range (2)]\n",
        "  def call(self, input):\n",
        "    x = input\n",
        "    for layer in self.conv:\n",
        "      x = layer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "q1GY9fuSZy2v"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters , pool_size , dropout,block_name):\n",
        "    super().__init__()\n",
        "    self.convBlock = ConvBlock(n_filters=n_filters , block_name=block_name, strides=(1,1))\n",
        "    self.pool = tf.keras.layers.MaxPooling2D(pool_size=pool_size)\n",
        "    self.dropout = tf.keras.layers.Dropout(rate = dropout)\n",
        "  def call (self, input) :\n",
        "    f = self.convBlock(input)\n",
        "    p = self.pool(f)\n",
        "    p = self.dropout(p)\n",
        "    return f , p"
      ],
      "metadata": {
        "id": "XnXkjW1yBK2t"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder (tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.encoder1 = EncoderBlock(64 , pool_size=(2,2),dropout=0.3 , block_name = 'block1')\n",
        "    self.encoder2 = EncoderBlock(128 , pool_size=(2,2),dropout=0.3 , block_name = 'block2')\n",
        "    self.encoder3 = EncoderBlock(256 , pool_size=(2,2),dropout=0.3 , block_name = 'block3')\n",
        "    self.encoder4 = EncoderBlock(512, pool_size=(2,2),dropout=0.3 , block_name = 'block4')\n",
        "  def call(self, input):\n",
        "    f1,p1=self.encoder1(input)\n",
        "    f2,p2 = self.encoder2(p1)\n",
        "    f3 , p3 = self.encoder3(p2)\n",
        "    f4,p4 = self.encoder4(p3)\n",
        "    return p4,(f1,f2,f3,f4)"
      ],
      "metadata": {
        "id": "bGj_gAVYCtKV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleNeck(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.convBlock=ConvBlock(1024, block_name = 'bottleneck' )\n",
        "  def call(self, input):\n",
        "    x = self.convBlock(input)\n",
        "    return x"
      ],
      "metadata": {
        "id": "JnixQBJQEYxk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters ,dropout,block_name , kernel_size= (3,3),strides = (2,2)  ):\n",
        "    super().__init__()\n",
        "    self.convTranspose = tf.keras.layers.Conv2DTranspose(n_filters, kernel_size = kernel_size , strides=strides , padding = 'same')\n",
        "    self.concat = tf.keras.layers.Concatenate()\n",
        "    self.DropOut = tf.keras.layers.Dropout(dropout)\n",
        "    self.convBlock = ConvBlock(n_filters=n_filters , block_name =block_name  )\n",
        "  def call(self, inputs , convOutput):\n",
        "    u=self.convTranspose(inputs)\n",
        "    c = self.concat([u,convOutput])\n",
        "    c= self.DropOut(c)\n",
        "    c = self.convBlock(c)\n",
        "    return c"
      ],
      "metadata": {
        "id": "yRG3BTRoKBp_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder (tf.keras.models.Model):\n",
        "  def __init__(self) :\n",
        "    super().__init__()\n",
        "    self.Decoder1 = DecoderBlock(n_filters=512 , dropout=0.3 , block_name='Decoder1')\n",
        "    self.Decoder2 = DecoderBlock(n_filters=256 , dropout=0.3 , block_name='Decoder2')\n",
        "    self.Decoder3 = DecoderBlock(n_filters=128 , dropout=0.3 , block_name='Decoder3')\n",
        "    self.Decoder4 = DecoderBlock(n_filters=64 , dropout=0.3 , block_name='Decoder4')\n",
        "    self.final_conv = tf.keras.layers.Conv2D(19, kernel_size=(1,1), activation='softmax')\n",
        "  def call(self , inputs , conv):\n",
        "    f1, f2 , f3, f4 = conv\n",
        "    c6 = self.Decoder1(inputs, f4 )\n",
        "    c7 = self.Decoder2(c6,f3)\n",
        "    c8 = self.Decoder3(c7,f2)\n",
        "    c9= self.Decoder4(c8, f1)\n",
        "    outputs = self.final_conv(c9)\n",
        "    return outputs\n"
      ],
      "metadata": {
        "id": "38eh4paxNH6X"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class  Unet (tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Encoder = Encoder()\n",
        "    self.BottleNeck = BottleNeck()\n",
        "    self.Decoder = Decoder()\n",
        "  def call(self , inputs):\n",
        "    encoder_output,convs = self.Encoder(inputs)\n",
        "    bottleNeck_output = self.BottleNeck(encoder_output)\n",
        "    output = self.Decoder(bottleNeck_output,convs)\n",
        "    return output"
      ],
      "metadata": {
        "id": "50M1jLpNPbHe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***UNET ++***"
      ],
      "metadata": {
        "id": "jcAZx14LYsBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Unet_plus_plus_convolutional_block(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters , block_name , activation = 'relu',kernel_size=(3,3)  ,stride = (2,2) ):\n",
        "    super().__init__()\n",
        "    self.conv_layers = [tf.keras.layers.Conv2D(filters=n_filters , kernel_size= kernel_size , strides = stride , name=f\"{block_name}_conv{i+1}\",padding = 'same') for i in range (2)]\n",
        "  def call(self, inputs) :\n",
        "    x = inputs\n",
        "    for layer in self.conv_layers:\n",
        "      x=layer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Ky0wpWCXYxRo"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_Block_for_unt_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self,  n_filters , pool_size , dropout,block_name):\n",
        "    super().__init__()\n",
        "    self.conv = Unet_plus_plus_convolutional_block(n_filters=n_filters, block_name=block_name)\n",
        "    self.pool = tf.keras.layers.MaxPooling2D(pool_size=pool_size)\n",
        "    self.dropout = tf.keras.layers.Dropout(rate =dropout)\n",
        "  def call(self,inputs):\n",
        "    f=self.conv(inputs)\n",
        "    p = self.pool(f)\n",
        "    p = self.dropout(p)\n",
        "    return f ,  p"
      ],
      "metadata": {
        "id": "DoVSW0wMbWTe"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_for_unt_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.encoder1 = Encoder_Block_for_unt_plus_plus(n_filters=64, pool_size=(2,2) , dropout=0.3, block_name = 'encoder1')\n",
        "    self.encoder2 = Encoder_Block_for_unt_plus_plus(n_filters=128, pool_size=(2,2) , dropout=0.3, block_name = 'encoder2')\n",
        "    self.encoder3 = Encoder_Block_for_unt_plus_plus(n_filters=256, pool_size=(2,2) , dropout=0.3, block_name = 'encoder3')\n",
        "    self.encoder4 = Encoder_Block_for_unt_plus_plus(n_filters=512, pool_size=(2,2) , dropout=0.3, block_name = 'encoder4')\n",
        "  def call(self, inputs):\n",
        "    f1,p1 = self.encoder1(inputs)\n",
        "    f2,p2 = self.encoder2(p1)\n",
        "    f3,p3 = self.encoder3(p2)\n",
        "    f4,p4 = self.encoder4(p3)\n",
        "    return (f1,f2,f3,f4),(p1,p2,p3,p4)"
      ],
      "metadata": {
        "id": "8cis-R7e4ozB"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleNeck_for_unet_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self ):\n",
        "    super().__init__()\n",
        "    self.bottle_neck = Unet_plus_plus_convolutional_block(n_filters=1024 , block_name = 'bottle_neck'  )\n",
        "  def call(self, inputs):\n",
        "    x = self.bottle_neck(inputs)\n",
        "    return x"
      ],
      "metadata": {
        "id": "r-p5Nw8n7TcD"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder_Block_for_unet_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self,n_filters  , dropout,block_name):\n",
        "    super().__init__()\n",
        "    self.conv = Unet_plus_plus_convolutional_block(n_filters=n_filters , block_name = block_name)\n",
        "    self.dropout = tf.keras.layers.Dropout(rate = dropout)\n",
        "    self.convTranspose = tf.keras.layers.Conv2DTranspose(n_filters, kernel_size = (3,3) , strides=(2,2) , padding = 'same')\n",
        "    self.concat = tf.keras.layers.Concatenate()\n",
        "  def call(self, conv_output_conc,inputs  ):\n",
        "    u = self.convTranspose(inputs)\n",
        "    c = self.concat([u,conv_output_conc])\n",
        "    c = self.dropout(c)\n",
        "    c = self.conv(c)\n",
        "    return c"
      ],
      "metadata": {
        "id": "HKqiRcGr83D5"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder_for_unet_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.decoder11 = Decoder_Block_for_unet_plus_plus(n_filters=64  , dropout = 0.3, block_name = 'skip_conv_block_11')\n",
        "    self.decoder12 = Decoder_Block_for_unet_plus_plus(n_filters=64  , dropout = 0.3, block_name = 'skip_conv_block_12')\n",
        "    self.decoder13 = Decoder_Block_for_unet_plus_plus(n_filters=64  , dropout = 0.3, block_name = 'skip_conv_block_13')\n",
        "    self.decoder14 = Decoder_Block_for_unet_plus_plus(n_filters=64  , dropout = 0.3, block_name = 'skip_conv_block_14')\n",
        "    self.decoder21 = Decoder_Block_for_unet_plus_plus(n_filters=128  , dropout = 0.3, block_name = 'skip_conv_block_21')\n",
        "    self.decoder22 = Decoder_Block_for_unet_plus_plus(n_filters=128  , dropout = 0.3, block_name = 'skip_conv_block_22')\n",
        "    self.decoder23 = Decoder_Block_for_unet_plus_plus(n_filters=128  , dropout = 0.3, block_name = 'skip_conv_block_23')\n",
        "    self.decoder31 = Decoder_Block_for_unet_plus_plus(n_filters=256  , dropout = 0.3, block_name = 'skip_conv_block_31')\n",
        "    self.decoder32 = Decoder_Block_for_unet_plus_plus(n_filters=256  , dropout = 0.3, block_name = 'skip_conv_block_32')\n",
        "    self.decoder41 = Decoder_Block_for_unet_plus_plus(n_filters=512  , dropout = 0.3, block_name = 'skip_conv_block_41')\n",
        "\n",
        "    self.concat12=tf.keras.layers.Concatenate()\n",
        "    self.concat13=tf.keras.layers.Concatenate()\n",
        "    self.concat14=tf.keras.layers.Concatenate()\n",
        "\n",
        "    self.concat22=tf.keras.layers.Concatenate()\n",
        "    self.concat23=tf.keras.layers.Concatenate()\n",
        "\n",
        "    self.concat32=tf.keras.layers.Concatenate()\n",
        "    self.bottle_neck = BottleNeck_for_unet_plus_plus()\n",
        "  def call(self, convs_cont , pool_cont):\n",
        "    f1,f2,f3,f4 = convs_cont\n",
        "    p1,p2,p3,p4 = pool_cont\n",
        "    p5 = self.bottle_neck(p4)\n",
        "    decoder41 = self.decoder41(f4,p5)\n",
        "    decoder31 = self.decoder31(f3,p4)\n",
        "    conc32 = self.concat32([f3 , decoder31])\n",
        "    decoder32 = self.decoder32(conc32 , decoder41)\n",
        "    decoder21 = self.decoder21(f2,p3)\n",
        "    conc22 = self.concat22([f2,decoder21])\n",
        "    decoder22 = self.decoder22(conc22 , decoder31)\n",
        "    conc23 = self.concat23([f2,decoder21, decoder22])\n",
        "    decoder23 = self.decoder23(conc23 , decoder32)\n",
        "    decoder11 = self.decoder11(f1,p2)\n",
        "    conc12 = self.concat12([f1,decoder11])\n",
        "    decoder12 = self.decoder12(conc12 , decoder21)\n",
        "    conc13 = self.concat13([f1,decoder11,decoder12])\n",
        "    decoder13 = self.decoder13(conc13 , decoder22)\n",
        "    conc14 = self.concat14([f1 , decoder11  , decoder12 , decoder13])\n",
        "    decoder14 = self.decoder14(conc14 , decoder23)\n",
        "    return decoder11 , decoder12, decoder13, decoder14"
      ],
      "metadata": {
        "id": "i9jopfkfASqD"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Unet_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.encoder =Encoder_for_unt_plus_plus()\n",
        "    self.decoder = Decoder_for_unet_plus_plus()\n",
        "  def call(self,inputs):\n",
        "    y,z = self.encoder(inputs)\n",
        "    decoder11,decoder12,decoder13,decoder14=self.decoder(y,z)\n",
        "    return decoder11,decoder12,decoder13, decoder14\n",
        ""
      ],
      "metadata": {
        "id": "_QbqnnYvIS-v"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Unet_plus_plus()"
      ],
      "metadata": {
        "id": "QhvmJp5cJ86_"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "vytgogDGKqcW",
        "outputId": "dfe33f81-21f0-4a8a-c754-e0476b94d7ab"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"unet_plus_plus_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"unet_plus_plus_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_for_unt_plus_plus_7          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mEncoder_for_unt_plus_plus\u001b[0m)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder_for_unet_plus_plus_6         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mDecoder_for_unet_plus_plus\u001b[0m)         │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_for_unt_plus_plus_7          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder_for_unt_plus_plus</span>)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder_for_unet_plus_plus_6         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder_for_unet_plus_plus</span>)         │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**testing code for model**"
      ],
      "metadata": {
        "id": "bYo7fCzYMLoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "input_shape = (1, 256, 256, 3)\n",
        "random_input = tf.random.normal(input_shape)\n",
        "\n",
        "# Initialize model\n",
        "\n",
        "\n",
        "# Run forward pass\n",
        "outputs = model(random_input)\n",
        "\n",
        "# Print output shapes\n",
        "output_names = [\"fcn32\", \"fcn16\", \"fcn8\", \"fcn4\", \"fcn2\"]\n",
        "for name, out in zip(output_names, outputs):\n",
        "    print(f\"{name} output shape: {out.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "uO-8NqIPMOyR",
        "outputId": "18a0fa79-49f1-4af7-f428-c4a0089f8546"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Decoder_Block_for_unet_plus_plus.call().\n\n\u001b[1mA `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(1, 0, 0, 256), (1, 1, 1, 256)]\u001b[0m\n\nArguments received by Decoder_Block_for_unet_plus_plus.call():\n  • conv_output_conc=tf.Tensor(shape=(1, 1, 1, 256), dtype=float16)\n  • inputs=tf.Tensor(shape=(1, 0, 0, 512), dtype=float16)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-742ea18d4110>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Run forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Print output shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-92-98af52a73933>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdecoder11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder14\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoder11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder14\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-91-1be7dc589c74>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, convs_cont, pool_cont)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mp5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottle_neck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mdecoder41\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder41\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mdecoder31\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder31\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mconc32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf3\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdecoder31\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdecoder32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconc32\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdecoder41\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-bc564011ce47>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, conv_output_conc, inputs)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_output_conc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvTranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconv_output_conc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Decoder_Block_for_unet_plus_plus.call().\n\n\u001b[1mA `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(1, 0, 0, 256), (1, 1, 1, 256)]\u001b[0m\n\nArguments received by Decoder_Block_for_unet_plus_plus.call():\n  • conv_output_conc=tf.Tensor(shape=(1, 1, 1, 256), dtype=float16)\n  • inputs=tf.Tensor(shape=(1, 0, 0, 512), dtype=float16)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initilizating instaces of the models**"
      ],
      "metadata": {
        "id": "fIfwcCtrYxqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  Fcn =FCN()\n",
        "  Unet = Unet()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "Q-hssWV3olla",
        "outputId": "60a30237-1885-4862-8c53-a4d72f8cbc5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'strategy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1195bdcffb13>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mFcn\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mFCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mUnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'strategy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**defining loss**"
      ],
      "metadata": {
        "id": "pG9N7x9NpFX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "with strategy.scope():\n",
        "    class DiceLoss(tf.keras.losses.Loss):\n",
        "        def __init__(self, smooth=1e-6):\n",
        "            super().__init__()\n",
        "            self.smooth = smooth\n",
        "\n",
        "        def call(self, y_true, y_pred):\n",
        "\n",
        "            y_true_f = tf.keras.backend.flatten(y_true)\n",
        "            y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "\n",
        "            intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "            denominator = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
        "\n",
        "            dice_loss = 1 - (2.0 * intersection + self.smooth) / (denominator + self.smooth)\n",
        "            return dice_loss\n",
        "\n",
        "with strategy.scope():\n",
        "    class SemanticSegmentationLoss(tf.keras.losses.Loss):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.dice_loss = DiceLoss()\n",
        "\n",
        "        def call(self, y_true, y_pred):\n",
        "\n",
        "            ce = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
        "            dice_loss = self.dice_loss(y_true, y_pred)\n",
        "            return ce + dice_loss\n"
      ],
      "metadata": {
        "id": "Zgqf26VNpmJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  class DeepSupervisionLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, weights=None, smooth=1e-6):\n",
        "      super().__init__()\n",
        "      self.smooth = smooth\n",
        "      self.weights = weights if weights else [1.0]\n",
        "      self.ce_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    def dice_loss(self, y_true, y_pred):\n",
        "      y_true_f = tf.keras.backend.flatten(tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[-1]))\n",
        "      y_pred_f = tf.keras.backend.flatten(tf.nn.softmax(y_pred))\n",
        "      intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "      denominator = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
        "      return 1 - (2.0 * intersection + self.smooth) / (denominator + self.smooth)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "      total_loss = 0.0\n",
        "      num_outputs = len(y_pred)\n",
        "      for i in range(num_outputs):\n",
        "        ce = self.ce_loss(y_true, y_pred[i])\n",
        "        dice = self.dice_loss(y_true, y_pred[i])\n",
        "        total_loss += self.weights[i] * (ce + dice)\n",
        "      return total_loss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "VLllqFTgQm4p",
        "outputId": "a67ff78c-5c8b-4378-aa7c-453eeec9045c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'strategy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-374a16bfa081>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0mDeepSupervisionLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'strategy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    optimizer = mixed_precision.LossScaleOptimizer(tf.keras.optimizers.Adam(learning_rate=1e-5), dynamic=True)"
      ],
      "metadata": {
        "id": "p00KctQJsIL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fyxUTVNmwvIY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}