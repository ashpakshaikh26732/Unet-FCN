{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1B12W-D6S226pHFryN9Y2XzlBbHV5Pvsg",
      "authorship_tag": "ABX9TyNDMVW7hL2pwIdkbVtA+Veg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashpakshaikh26732/Unet-FCN/blob/main/Unet_FCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**all packages**"
      ],
      "metadata": {
        "id": "5XRgNljpyU9b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mm_LuZ1iev66"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "  print(f'no of tpus : {strategy.num_replicas_in_sync}')\n",
        "except ValueError :\n",
        "  print('tpu failed to initilized')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTuYhVhRffta",
        "outputId": "f0438627-113d-49af-e6ce-f6ea3e678315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tpu failed to initilized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**mixed precision training**"
      ],
      "metadata": {
        "id": "tzwsFyykuBp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "I9g7HnQsuOMj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vQK2Gy1ggZP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a752edd-f5da-40ea-fbda-4238a53cad07"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**copy datasets from drive**"
      ],
      "metadata": {
        "id": "XLI9cZz46258"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Cityscapes/gtFine_trainvaltest.zip /content/\n",
        "!cp /content/drive/MyDrive/Cityscapes/leftImg8bit_trainvaltest.zip /content"
      ],
      "metadata": {
        "id": "_cb4xI4h5b3z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**extract trainig the data**"
      ],
      "metadata": {
        "id": "gWcHvq9T67yT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.system(\"unzip -q /content/gtFine_trainvaltest.zip -d /content/ \")\n",
        "os.system(\"unzip -q /content/leftImg8bit_trainvaltest.zip -d /content/\")"
      ],
      "metadata": {
        "id": "gIGN5YpV58XW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be446489-d02d-48f0-b0d8-5934721c67ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Images:\", len(os.listdir(\"/content/leftImg8bit/train/aachen\")))  # Adjust path as needed\n",
        "print(\"Train Labels:\", len(os.listdir(\"/content/gtFine/train/aachen\")))"
      ],
      "metadata": {
        "id": "-MKUIQNX7naD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e74af6-094e-492e-a858-2db1b97076d0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images: 174\n",
            "Train Labels: 696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"test images : \", len(os.listdir('/content/leftImg8bit/test')))"
      ],
      "metadata": {
        "id": "qafiZBb5yC0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Global Valrible**"
      ],
      "metadata": {
        "id": "9Q1cFO0jJcA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 224\n",
        "img_width = 224\n",
        "batch_size = 16\n",
        "# final_batch_size = batch_size * strategy.num_replicas_in_sync"
      ],
      "metadata": {
        "id": "3NSFJ69oJiMF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**loading images and labels from directry**"
      ],
      "metadata": {
        "id": "J9Y6CZKmCbNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img():\n",
        "    train_dir = '/content/leftImg8bit/train'\n",
        "    train_image_cities = os.listdir(train_dir)\n",
        "    train_images = []\n",
        "\n",
        "    for city in train_image_cities:\n",
        "        train_city = os.path.join(train_dir, city)\n",
        "        images = [os.path.join(train_city, img) for img in os.listdir(train_city) if img.endswith('.png')]\n",
        "        train_images.extend(images)\n",
        "\n",
        "    return train_images\n",
        "\n",
        "def load_labels():\n",
        "    train_dir = '/content/gtFine/train'\n",
        "    train_labels_cities = os.listdir(train_dir)\n",
        "    train_labels = []\n",
        "    for city in train_labels_cities:\n",
        "        train_city_label = os.path.join(train_dir, city)\n",
        "        labels = [f for f in os.listdir(train_city_label) if f.endswith('_gtFine_labelIds.png')]\n",
        "        for label in labels:\n",
        "            label_path = os.path.join(train_city_label, label)\n",
        "            train_labels.append(label_path)\n",
        "    return train_labels"
      ],
      "metadata": {
        "id": "OzTJuxSUyT19"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**reading images from path**"
      ],
      "metadata": {
        "id": "cGkR1OkdChy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_img(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, (img_height, img_width))\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "def read_labels(label_path):\n",
        "    label = tf.io.read_file(label_path)\n",
        "    label = tf.io.decode_png(label, channels=1)\n",
        "    label = tf.image.resize(label, (img_height, img_width), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    return tf.cast(label, tf.uint8)\n"
      ],
      "metadata": {
        "id": "tR2-lYACFmLh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**augmentation**"
      ],
      "metadata": {
        "id": "PMQ2HsmKQtqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment(image, label):\n",
        "\n",
        "    label = tf.cast(label, tf.float32)\n",
        "\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "        label = tf.image.flip_left_right(label)\n",
        "\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "\n",
        "    combined = tf.concat([image, label], axis=-1)\n",
        "    combined = tf.image.random_crop(combined, size=[224, 224, 6])\n",
        "\n",
        "    image, label = tf.split(combined, num_or_size_splits=2, axis=-1)\n",
        "\n",
        "\n",
        "    label = tf.cast(label, tf.uint8)\n",
        "\n",
        "    return image, label\n"
      ],
      "metadata": {
        "id": "ArL30hPWQzQc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**creating dataset**"
      ],
      "metadata": {
        "id": "AMrQX_bwIrwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = load_img()\n",
        "labels = load_labels()\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "dataset = dataset.map(lambda image_path , label_path :( read_img(image_path) , label_path)).map(lambda image , label_path : (image,read_labels(label_path=label_path)))\n",
        "dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset = dataset.shuffle(buffer_size=1000).cache().batch(batch_size)\n",
        "dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "oiZ4wr51HQR_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for image , label in dataset.take(1):\n",
        "#   print(f'image shape : {image.shape} , label shape {label.shape}')\n",
        "#   print(f'image datatype : {image.dtype}, label dtype {label.dtype}')"
      ],
      "metadata": {
        "id": "l4asEByyJz3k"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FCN model**"
      ],
      "metadata": {
        "id": "71fnRZr6XnEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(tf.keras.models.Model):\n",
        "    def __init__(self, n_conv, filters, kernel_size, activation, pool_size, pool_stride, block_name):\n",
        "        super().__init__()\n",
        "        self.conv_layers = [\n",
        "            tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding='same',\n",
        "                                   activation=activation, name=f\"{block_name}_conv{i+1}\")\n",
        "            for i in range(n_conv)\n",
        "        ]\n",
        "        self.pool = tf.keras.layers.MaxPool2D(pool_size=pool_size, strides=pool_stride, name=f\"{block_name}_pool\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for conv in self.conv_layers:\n",
        "            x = conv(x)\n",
        "        x = self.pool(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lYYeYAZ7WKGM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.block1 = Block(n_conv=2 , filters=64 , kernel_size = (3,3) , activation ='relu' , pool_size=(2,2) , pool_stride = (2,2) , block_name = 'block1')\n",
        "    self.block2 = Block(n_conv=3 , filters = 128 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block2')\n",
        "    self.block3 = Block(n_conv=3 , filters = 256 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block3')\n",
        "    self.block4 = Block(n_conv=3 , filters = 512 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block4')\n",
        "    self.block5 = Block(n_conv=3 , filters = 512 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block5')\n",
        "  def call(self,inputs):\n",
        "    p1 = self.block1(inputs)\n",
        "    p2 = self.block2(p1)\n",
        "    p3 = self.block3(p2)\n",
        "    p4 = self.block4(p3)\n",
        "    p5 = self.block5(p4)\n",
        "    return p1 , p2 , p3 , p4 , p5"
      ],
      "metadata": {
        "id": "qTQFaELPY5CU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Decoder(tf.keras.models.Model):\n",
        "    def __init__(self, nclasses):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.upsample1 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.upsample2 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.upsample3 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "\n",
        "\n",
        "        self.skip1 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), activation='relu', padding='same')\n",
        "        self.skip2 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), activation='relu', padding='same')\n",
        "        self.skip3 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), activation='relu', padding='same')\n",
        "\n",
        "\n",
        "        self.add1 = tf.keras.layers.Add()\n",
        "        self.add2 = tf.keras.layers.Add()\n",
        "        self.add3 = tf.keras.layers.Add()\n",
        "\n",
        "\n",
        "        self.fcn32 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(32, 32), strides=(32, 32), padding='same', name='fcn32')\n",
        "        self.fcn16 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(16, 16), strides=(16, 16), padding='same', name='fcn16')\n",
        "        self.fcn8 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(8, 8), strides=(8, 8), padding='same', name='fcn8')\n",
        "        self.fcn4 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(4, 4), padding='same', name='fcn4')\n",
        "\n",
        "\n",
        "        self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        p1, p2, p3, p4, p5 = inputs\n",
        "\n",
        "        fcn32 = self.fcn32(p5)\n",
        "\n",
        "\n",
        "        o = self.upsample1(p5)\n",
        "        o = self.add1([o, self.skip1(p4)])\n",
        "        fcn16 = self.fcn16(o)\n",
        "\n",
        "\n",
        "        o = self.upsample2(o)\n",
        "        o = self.add2([o, self.skip2(p3)])\n",
        "        fcn8 = self.fcn8(o)\n",
        "\n",
        "\n",
        "        o = self.upsample3(o)\n",
        "        o = self.add3([o, self.skip3(p2)])\n",
        "        fcn4 = self.fcn4(o)\n",
        "\n",
        "\n",
        "        return self.softmax(fcn32), self.softmax(fcn16), self.softmax(fcn8), self.softmax(fcn4)"
      ],
      "metadata": {
        "id": "C7urJTNYZAVO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Main_model(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Encoder = Encoder()\n",
        "    self.Decoder = Decoder(19)\n",
        "  def call(self, inputs):\n",
        "    x=self.Encoder(inputs)\n",
        "    x = self.Decoder(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "4WXzcbDYZOJ5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**UNET**"
      ],
      "metadata": {
        "id": "t99faxaF2nJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters,block_name , kernel_size=3 , strides = (1,1) , activation='relu'):\n",
        "    super().__init__()\n",
        "    self.conv = [tf.keras.layers.Conv2D(filters=n_filters , strides=strides , kernel_size=(kernel_size, kernel_size) , activation='relu', name=f\"{block_name}_conv{i+1}\", padding='same') for i in range (2)]\n",
        "  def call(self, input):\n",
        "    x = input\n",
        "    for layer in self.conv:\n",
        "      x = layer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "q1GY9fuSZy2v"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters , pool_size , dropout,block_name):\n",
        "    super().__init__()\n",
        "    self.convBlock = ConvBlock(n_filters=n_filters , block_name=block_name, strides=(1,1))\n",
        "    self.pool = tf.keras.layers.MaxPooling2D(pool_size=pool_size)\n",
        "    self.dropout = tf.keras.layers.Dropout(rate = dropout)\n",
        "  def call (self, input) :\n",
        "    f = self.convBlock(input)\n",
        "    p = self.pool(f)\n",
        "    p = self.dropout(p)\n",
        "    return f , p"
      ],
      "metadata": {
        "id": "XnXkjW1yBK2t"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder (tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.encoder1 = EncoderBlock(64 , pool_size=(2,2),dropout=0.3 , block_name = 'block1')\n",
        "    self.encoder2 = EncoderBlock(128 , pool_size=(2,2),dropout=0.3 , block_name = 'block2')\n",
        "    self.encoder3 = EncoderBlock(256 , pool_size=(2,2),dropout=0.3 , block_name = 'block3')\n",
        "    self.encoder4 = EncoderBlock(512, pool_size=(2,2),dropout=0.3 , block_name = 'block4')\n",
        "  def call(self, input):\n",
        "    f1,p1=self.encoder1(input)\n",
        "    f2,p2 = self.encoder2(p1)\n",
        "    f3 , p3 = self.encoder3(p2)\n",
        "    f4,p4 = self.encoder4(p3)\n",
        "    return p4,(f1,f2,f3,f4)"
      ],
      "metadata": {
        "id": "bGj_gAVYCtKV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleNeck(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.convBlock=ConvBlock(1024, block_name = 'bottleneck' )\n",
        "  def call(self, input):\n",
        "    x = self.convBlock(input)\n",
        "    return x"
      ],
      "metadata": {
        "id": "JnixQBJQEYxk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters ,dropout,block_name , kernel_size= (3,3),strides = (2,2)  ):\n",
        "    super().__init__()\n",
        "    self.convTranspose = tf.keras.layers.Conv2DTranspose(n_filters, kernel_size = kernel_size , strides=strides , padding = 'same')\n",
        "    self.concat = tf.keras.layers.Concatenate()\n",
        "    self.DropOut = tf.keras.layers.Dropout(dropout)\n",
        "    self.convBlock = ConvBlock(n_filters=n_filters , block_name =block_name  )\n",
        "  def call(self, inputs , convOutput):\n",
        "    u=self.convTranspose(inputs)\n",
        "    c = self.concat([u,convOutput])\n",
        "    c= self.DropOut(c)\n",
        "    c = self.convBlock(c)\n",
        "    return c"
      ],
      "metadata": {
        "id": "yRG3BTRoKBp_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder (tf.keras.models.Model):\n",
        "  def __init__(self) :\n",
        "    super().__init__()\n",
        "    self.Decoder1 = DecoderBlock(n_filters=512 , dropout=0.3 , block_name='Decoder1')\n",
        "    self.Decoder2 = DecoderBlock(n_filters=256 , dropout=0.3 , block_name='Decoder2')\n",
        "    self.Decoder3 = DecoderBlock(n_filters=128 , dropout=0.3 , block_name='Decoder3')\n",
        "    self.Decoder4 = DecoderBlock(n_filters=64 , dropout=0.3 , block_name='Decoder4')\n",
        "    self.final_conv = tf.keras.layers.Conv2D(19, kernel_size=(1,1), activation='softmax')\n",
        "  def call(self , inputs , conv):\n",
        "    f1, f2 , f3, f4 = conv\n",
        "    c6 = self.Decoder1(inputs, f4 )\n",
        "    c7 = self.Decoder2(c6,f3)\n",
        "    c8 = self.Decoder3(c7,f2)\n",
        "    c9= self.Decoder4(c8, f1)\n",
        "    outputs = self.final_conv(c9)\n",
        "    return outputs\n"
      ],
      "metadata": {
        "id": "38eh4paxNH6X"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class  Unet (tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Encoder = Encoder()\n",
        "    self.BottleNeck = BottleNeck()\n",
        "    self.Decoder = Decoder()\n",
        "  def call(self , inputs):\n",
        "    encoder_output,convs = self.Encoder(inputs)\n",
        "    bottleNeck_output = self.BottleNeck(encoder_output)\n",
        "    output = self.Decoder(bottleNeck_output,convs)\n",
        "    return output"
      ],
      "metadata": {
        "id": "50M1jLpNPbHe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with strategy.scope():\n",
        "  FCN =FCN()\n",
        "  Unet = Unet()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "Q-hssWV3olla",
        "outputId": "cfbf6419-aff9-4ae5-99b1-8e5bb4e95306"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-32-d380f394ce64>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-d380f394ce64>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    FCN =FCN()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**defining loss**"
      ],
      "metadata": {
        "id": "pG9N7x9NpFX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "with strategy.scope():\n",
        "    class DiceLoss(tf.keras.losses.Loss):\n",
        "        def __init__(self, smooth=1e-6):\n",
        "            super().__init__()\n",
        "            self.smooth = smooth\n",
        "\n",
        "        def call(self, y_true, y_pred):\n",
        "\n",
        "            y_true_f = tf.keras.backend.flatten(y_true)\n",
        "            y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "\n",
        "            intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "            denominator = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
        "\n",
        "            dice_loss = 1 - (2.0 * intersection + self.smooth) / (denominator + self.smooth)\n",
        "            return dice_loss\n",
        "\n",
        "with strategy.scope():\n",
        "    class SemanticSegmentationLoss(tf.keras.losses.Loss):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.dice_loss = DiceLoss()\n",
        "\n",
        "        def call(self, y_true, y_pred):\n",
        "\n",
        "            ce = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
        "            dice_loss = self.dice_loss(y_true, y_pred)\n",
        "            return ce + dice_loss\n"
      ],
      "metadata": {
        "id": "Zgqf26VNpmJO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    optimizer = mixed_precision.LossScaleOptimizer(tf.keras.optimizers.Adam(learning_rate=1e-5), dynamic=True)"
      ],
      "metadata": {
        "id": "p00KctQJsIL1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}