{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1B12W-D6S226pHFryN9Y2XzlBbHV5Pvsg",
      "authorship_tag": "ABX9TyOuDFls2zngTZajX+Lh+W7W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashpakshaikh26732/Unet-FCN/blob/main/Unet_FCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**all packages**"
      ],
      "metadata": {
        "id": "5XRgNljpyU9b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mm_LuZ1iev66"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display,HTML"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "  print(f'no of tpus : {strategy.num_replicas_in_sync}')\n",
        "except ValueError :\n",
        "  print('tpu failed to initilized')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTuYhVhRffta",
        "outputId": "1b6570e7-7fed-40a9-8221-9ea1560fe40d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tpu failed to initilized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**mixed precision training**"
      ],
      "metadata": {
        "id": "tzwsFyykuBp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "I9g7HnQsuOMj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cdN0drMo70q4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vQK2Gy1ggZP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d2f570-5843-403a-9a77-ebeb50759747"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**copy datasets from drive**"
      ],
      "metadata": {
        "id": "XLI9cZz46258"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Cityscapes/gtFine_trainvaltest.zip /content/\n",
        "!cp /content/drive/MyDrive/Cityscapes/leftImg8bit_trainvaltest.zip /content"
      ],
      "metadata": {
        "id": "_cb4xI4h5b3z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**extract trainig the data**"
      ],
      "metadata": {
        "id": "gWcHvq9T67yT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.system(\"unzip -q /content/gtFine_trainvaltest.zip -d /content/ \")\n",
        "os.system(\"unzip -q /content/leftImg8bit_trainvaltest.zip -d /content/\")"
      ],
      "metadata": {
        "id": "gIGN5YpV58XW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a1cefa-bdde-4eb6-b301-58c8c9475184"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Images:\", len(os.listdir(\"/content/leftImg8bit/train/aachen\")))  # Adjust path as needed\n",
        "print(\"Train Labels:\", len(os.listdir(\"/content/gtFine/train/aachen\")))"
      ],
      "metadata": {
        "id": "-MKUIQNX7naD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12564fe-feb1-475a-c085-e56b732d386a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images: 174\n",
            "Train Labels: 696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"test images : \", len(os.listdir('/content/leftImg8bit/test')))"
      ],
      "metadata": {
        "id": "qafiZBb5yC0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6cf8990-2a36-46fd-abfa-9d71db7bd78a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test images :  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Global Valrible**"
      ],
      "metadata": {
        "id": "9Q1cFO0jJcA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 224\n",
        "img_width = 224\n",
        "batch_size = 16\n",
        "# final_batch_size = batch_size * strategy.num_replicas_in_sync"
      ],
      "metadata": {
        "id": "3NSFJ69oJiMF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**loading images and labels from directry for training**"
      ],
      "metadata": {
        "id": "J9Y6CZKmCbNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img():\n",
        "    train_dir = '/content/leftImg8bit/train'\n",
        "    train_image_cities = os.listdir(train_dir)\n",
        "    train_images = []\n",
        "\n",
        "    for city in sorted(train_image_cities):\n",
        "        train_city = os.path.join(train_dir, city)\n",
        "        images = sorted([os.path.join(train_city, img) for img in os.listdir(train_city) if img.endswith('.png')])\n",
        "        train_images.extend(images)\n",
        "\n",
        "    return train_images\n",
        "\n",
        "def load_labels():\n",
        "    train_dir = '/content/gtFine/train'\n",
        "    train_labels_cities = os.listdir(train_dir)\n",
        "    train_labels = []\n",
        "\n",
        "    for city in sorted(train_labels_cities):\n",
        "        train_city_label = os.path.join(train_dir, city)\n",
        "        labels = sorted([f for f in os.listdir(train_city_label) if f.endswith('_gtFine_labelIds.png')])\n",
        "        for label in labels:\n",
        "            label_path = os.path.join(train_city_label, label)\n",
        "            train_labels.append(label_path)\n",
        "\n",
        "    return train_labels"
      ],
      "metadata": {
        "id": "OzTJuxSUyT19"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**reading images from path**"
      ],
      "metadata": {
        "id": "cGkR1OkdChy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_img(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, (img_height, img_width))\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "def read_labels(label_path):\n",
        "    label = tf.io.read_file(label_path)\n",
        "    label = tf.io.decode_png(label, channels=1)\n",
        "    label = tf.image.resize(label, (img_height, img_width), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    return tf.cast(label, tf.uint8)"
      ],
      "metadata": {
        "id": "tR2-lYACFmLh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**augmentation**"
      ],
      "metadata": {
        "id": "PMQ2HsmKQtqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(image_path, label_path):\n",
        "    image = read_img(image_path)\n",
        "    label = read_labels(label_path)\n",
        "    return image, label\n",
        "\n",
        "def augment(image, label):\n",
        "    label = tf.cast(label, tf.float32)\n",
        "\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "        label = tf.image.flip_left_right(label)\n",
        "\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "\n",
        "    combined = tf.concat([image, label], axis=-1)\n",
        "    combined = tf.image.random_crop(combined, size=[224, 224, 4])\n",
        "    image, label = tf.split(combined, num_or_size_splits=[3, 1], axis=-1)\n",
        "\n",
        "    label = tf.cast(label, tf.uint8)\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "ArL30hPWQzQc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**creating dataset**"
      ],
      "metadata": {
        "id": "AMrQX_bwIrwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = load_img()\n",
        "labels = load_labels()\n",
        "\n",
        "# Create TF Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "dataset = dataset.map(process_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset = dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset = dataset.shuffle(buffer_size=1000).cache().batch(batch_size)\n",
        "train_dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "oiZ4wr51HQR_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for image , label in dataset.take(1):\n",
        "#   print(f'image shape : {image.shape} , label shape {label.shape}')\n",
        "#   print(f'image datatype : {image.dtype}, label dtype {label.dtype}')"
      ],
      "metadata": {
        "id": "l4asEByyJz3k"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**loading images and labels from directry for validiation**"
      ],
      "metadata": {
        "id": "DtUwaeoBgZ1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img_val():\n",
        "    train_dir = '/content/leftImg8bit/val'\n",
        "    train_image_cities = os.listdir(train_dir)\n",
        "    train_images = []\n",
        "\n",
        "    for city in sorted(train_image_cities):\n",
        "        train_city = os.path.join(train_dir, city)\n",
        "        images = sorted([os.path.join(train_city, img) for img in os.listdir(train_city) if img.endswith('.png')])\n",
        "        train_images.extend(images)\n",
        "\n",
        "    return train_images\n",
        "\n",
        "def load_labels_val():\n",
        "    train_dir = '/content/gtFine/val'\n",
        "    train_labels_cities = os.listdir(train_dir)\n",
        "    train_labels = []\n",
        "\n",
        "    for city in sorted(train_labels_cities):\n",
        "        train_city_label = os.path.join(train_dir, city)\n",
        "        labels = sorted([f for f in os.listdir(train_city_label) if f.endswith('_gtFine_labelIds.png')])\n",
        "        for label in labels:\n",
        "            label_path = os.path.join(train_city_label, label)\n",
        "            train_labels.append(label_path)\n",
        "\n",
        "    return train_labels"
      ],
      "metadata": {
        "id": "Bt2sAOA9gZP4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_img_val(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, (img_height, img_width))\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "def read_labels_val(label_path):\n",
        "    label = tf.io.read_file(label_path)\n",
        "    label = tf.io.decode_png(label, channels=1)\n",
        "    label = tf.image.resize(label, (img_height, img_width), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    return tf.cast(label, tf.uint8)"
      ],
      "metadata": {
        "id": "akUFQg0SgqWq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data_val(image_path, label_path):\n",
        "    image = read_img(image_path)\n",
        "    label = read_labels(label_path)\n",
        "    return image, label\n",
        "\n",
        "images = load_img_val()\n",
        "labels = load_labels_val()\n",
        "\n",
        "# Create TF Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "dataset = dataset.map(process_data_val, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size=1000).cache().batch(batch_size)\n",
        "val_dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "oLLrc6JQgv15"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**loading images and labels from directry for testing**"
      ],
      "metadata": {
        "id": "nWuEcsIvhHAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img_test():\n",
        "    train_dir = '/content/leftImg8bit/test'\n",
        "    train_image_cities = os.listdir(train_dir)\n",
        "    train_images = []\n",
        "\n",
        "    for city in sorted(train_image_cities):\n",
        "        train_city = os.path.join(train_dir, city)\n",
        "        images = sorted([os.path.join(train_city, img) for img in os.listdir(train_city) if img.endswith('.png')])\n",
        "        train_images.extend(images)\n",
        "\n",
        "    return train_images\n",
        "\n",
        "def load_labels_test():\n",
        "    train_dir = '/content/gtFine/test'\n",
        "    train_labels_cities = os.listdir(train_dir)\n",
        "    train_labels = []\n",
        "\n",
        "    for city in sorted(train_labels_cities):\n",
        "        train_city_label = os.path.join(train_dir, city)\n",
        "        labels = sorted([f for f in os.listdir(train_city_label) if f.endswith('_gtFine_labelIds.png')])\n",
        "        for label in labels:\n",
        "            label_path = os.path.join(train_city_label, label)\n",
        "            train_labels.append(label_path)\n",
        "\n",
        "    return train_labels"
      ],
      "metadata": {
        "id": "ZnpkmjsehZUW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_img_test(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, (img_height, img_width))\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "def read_labels_test(label_path):\n",
        "    label = tf.io.read_file(label_path)\n",
        "    label = tf.io.decode_png(label, channels=1)\n",
        "    label = tf.image.resize(label, (img_height, img_width), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    return tf.cast(label, tf.uint8)"
      ],
      "metadata": {
        "id": "-w9CLcnqhqH9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data_test(image_path, label_path):\n",
        "    image = read_img(image_path)\n",
        "    label = read_labels(label_path)\n",
        "    return image, label\n",
        "\n",
        "images = load_img_test()\n",
        "labels = load_labels_test()\n",
        "\n",
        "# Create TF Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "dataset = dataset.map(process_data_test, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size=1000).cache().batch(batch_size)\n",
        "test_dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "2TQo6yfIh2J0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FCN model**"
      ],
      "metadata": {
        "id": "71fnRZr6XnEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(tf.keras.models.Model):\n",
        "    def __init__(self, n_conv, filters, kernel_size, activation, pool_size, pool_stride, block_name):\n",
        "        super().__init__()\n",
        "        self.conv_layers = [\n",
        "            tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding='same',\n",
        "                                   activation=activation, name=f\"{block_name}_conv{i+1}\")\n",
        "            for i in range(n_conv)\n",
        "        ]\n",
        "        self.pool = tf.keras.layers.MaxPool2D(pool_size=pool_size, strides=pool_stride, name=f\"{block_name}_pool\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for conv in self.conv_layers:\n",
        "            x = conv(x)\n",
        "        x = self.pool(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lYYeYAZ7WKGM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.block1 = Block(n_conv=2 , filters=64 , kernel_size = (3,3) , activation ='relu' , pool_size=(2,2) , pool_stride = (2,2) , block_name = 'block1')\n",
        "    self.block2 = Block(n_conv=3 , filters = 128 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block2')\n",
        "    self.block3 = Block(n_conv=3 , filters = 256 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block3')\n",
        "    self.block4 = Block(n_conv=3 , filters = 512 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block4')\n",
        "    self.block5 = Block(n_conv=3 , filters = 512 , kernel_size = (3,3) , activation='relu' , pool_size = (2,2) , pool_stride = (2,2) , block_name = 'block5')\n",
        "  def call(self,inputs):\n",
        "    p1 = self.block1(inputs)\n",
        "    p2 = self.block2(p1)\n",
        "    p3 = self.block3(p2)\n",
        "    p4 = self.block4(p3)\n",
        "    p5 = self.block5(p4)\n",
        "    return p1 , p2 , p3 , p4 , p5"
      ],
      "metadata": {
        "id": "qTQFaELPY5CU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.models.Model):\n",
        "    def __init__(self, nclasses=19):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.upsample1 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.upsample2 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.upsample3 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "\n",
        "\n",
        "        self.skip1 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), activation='relu', padding='same')\n",
        "        self.skip2 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), activation='relu', padding='same')\n",
        "        self.skip3 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), activation='relu', padding='same')\n",
        "\n",
        "\n",
        "        self.add1 = tf.keras.layers.Add()\n",
        "        self.add2 = tf.keras.layers.Add()\n",
        "        self.add3 = tf.keras.layers.Add()\n",
        "\n",
        "\n",
        "        self.fcn32 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(32, 32), strides=(32, 32), padding='same', name='fcn32')\n",
        "        self.fcn16 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(16, 16), strides=(16, 16), padding='same', name='fcn16')\n",
        "        self.fcn8 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(8, 8), strides=(8, 8), padding='same', name='fcn8')\n",
        "        self.fcn4 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(4, 4), padding='same', name='fcn4')\n",
        "\n",
        "\n",
        "        self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        p1, p2, p3, p4, p5 = inputs\n",
        "\n",
        "        fcn32 = self.fcn32(p5)\n",
        "\n",
        "\n",
        "        o = self.upsample1(p5)\n",
        "        o = self.add1([o, self.skip1(p4)])\n",
        "        fcn16 = self.fcn16(o)\n",
        "\n",
        "\n",
        "        o = self.upsample2(o)\n",
        "        o = self.add2([o, self.skip2(p3)])\n",
        "        fcn8 = self.fcn8(o)\n",
        "\n",
        "\n",
        "        o = self.upsample3(o)\n",
        "        o = self.add3([o, self.skip3(p2)])\n",
        "        fcn4 = self.fcn4(o)\n",
        "\n",
        "\n",
        "        return self.softmax(fcn32), self.softmax(fcn16), self.softmax(fcn8), self.softmax(fcn4)"
      ],
      "metadata": {
        "id": "C7urJTNYZAVO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FCN(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Encoder = Encoder()\n",
        "    self.Decoder = Decoder()\n",
        "  def call(self, inputs):\n",
        "    x=self.Encoder(inputs)\n",
        "    x = self.Decoder(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "4WXzcbDYZOJ5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fcn =FCN()"
      ],
      "metadata": {
        "id": "JxRi_CXd411R"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**UNET**"
      ],
      "metadata": {
        "id": "t99faxaF2nJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters,block_name , kernel_size=3 , strides = (1,1) , activation='relu'):\n",
        "    super().__init__()\n",
        "    self.conv = [tf.keras.layers.Conv2D(filters=n_filters , strides=strides , kernel_size=(kernel_size, kernel_size) , activation='relu', name=f\"{block_name}_conv{i+1}\", padding='same') for i in range (2)]\n",
        "  def call(self, inputs):\n",
        "    x = inputs\n",
        "    for layer in self.conv:\n",
        "      x = layer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "q1GY9fuSZy2v"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters , pool_size , dropout,block_name):\n",
        "    super().__init__()\n",
        "    self.convBlock = ConvBlock(n_filters=n_filters , block_name=block_name, strides=(1,1))\n",
        "    self.pool = tf.keras.layers.MaxPooling2D(pool_size=pool_size)\n",
        "    self.dropout = tf.keras.layers.Dropout(rate = dropout)\n",
        "  def call (self, inputs) :\n",
        "    f = self.convBlock(inputs)\n",
        "    p = self.pool(f)\n",
        "    p = self.dropout(p)\n",
        "    return f , p"
      ],
      "metadata": {
        "id": "XnXkjW1yBK2t"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder (tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.encoder1 = EncoderBlock(64 , pool_size=(2,2),dropout=0.3 , block_name = 'block1')\n",
        "    self.encoder2 = EncoderBlock(128 , pool_size=(2,2),dropout=0.3 , block_name = 'block2')\n",
        "    self.encoder3 = EncoderBlock(256 , pool_size=(2,2),dropout=0.3 , block_name = 'block3')\n",
        "    self.encoder4 = EncoderBlock(512, pool_size=(2,2),dropout=0.3 , block_name = 'block4')\n",
        "  def call(self, inputs):\n",
        "    f1,p1=self.encoder1(inputs)\n",
        "    f2,p2 = self.encoder2(p1)\n",
        "    f3 , p3 = self.encoder3(p2)\n",
        "    f4,p4 = self.encoder4(p3)\n",
        "    return p4,(f1,f2,f3,f4)"
      ],
      "metadata": {
        "id": "bGj_gAVYCtKV"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleNeck(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.convBlock=ConvBlock(1024, block_name = 'bottleneck' )\n",
        "  def call(self, inputs):\n",
        "    x = self.convBlock(inputs)\n",
        "    return x"
      ],
      "metadata": {
        "id": "JnixQBJQEYxk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters ,dropout,block_name , kernel_size= (3,3),strides = (2,2)  ):\n",
        "    super().__init__()\n",
        "    self.convTranspose = tf.keras.layers.Conv2DTranspose(n_filters, kernel_size = kernel_size , strides=strides , padding = 'same')\n",
        "    self.concat = tf.keras.layers.Concatenate()\n",
        "    self.DropOut = tf.keras.layers.Dropout(dropout)\n",
        "    self.convBlock = ConvBlock(n_filters=n_filters , block_name =block_name  )\n",
        "  def call(self, inputs , convOutput):\n",
        "    u=self.convTranspose(inputs)\n",
        "    c = self.concat([u,convOutput])\n",
        "    c= self.DropOut(c)\n",
        "    c = self.convBlock(c)\n",
        "    return c"
      ],
      "metadata": {
        "id": "yRG3BTRoKBp_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder (tf.keras.models.Model):\n",
        "  def __init__(self) :\n",
        "    super().__init__()\n",
        "    self.Decoder1 = DecoderBlock(n_filters=512 , dropout=0.3 , block_name='Decoder1')\n",
        "    self.Decoder2 = DecoderBlock(n_filters=256 , dropout=0.3 , block_name='Decoder2')\n",
        "    self.Decoder3 = DecoderBlock(n_filters=128 , dropout=0.3 , block_name='Decoder3')\n",
        "    self.Decoder4 = DecoderBlock(n_filters=64 , dropout=0.3 , block_name='Decoder4')\n",
        "    self.final_conv = tf.keras.layers.Conv2D(19, kernel_size=(1,1), activation='softmax')\n",
        "  def call(self , inputs , conv):\n",
        "    f1, f2 , f3, f4 = conv\n",
        "    c6 = self.Decoder1(inputs, f4 )\n",
        "    c7 = self.Decoder2(c6,f3)\n",
        "    c8 = self.Decoder3(c7,f2)\n",
        "    c9= self.Decoder4(c8, f1)\n",
        "    outputs = self.final_conv(c9)\n",
        "    return outputs\n"
      ],
      "metadata": {
        "id": "38eh4paxNH6X"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Unet (tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Encoder = Encoder()\n",
        "    self.BottleNeck = BottleNeck()\n",
        "    self.Decoder = Decoder()\n",
        "  def call(self , inputs):\n",
        "    encoder_output,convs = self.Encoder(inputs)\n",
        "    bottleNeck_output = self.BottleNeck(encoder_output)\n",
        "    output = self.Decoder(bottleNeck_output,convs)\n",
        "    return output"
      ],
      "metadata": {
        "id": "50M1jLpNPbHe"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet = Unet()"
      ],
      "metadata": {
        "id": "8ZQzYRpVi9dS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***UNET ++***"
      ],
      "metadata": {
        "id": "jcAZx14LYsBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Unet_plus_plus_convolutional_block(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters , block_name , activation = 'relu',kernel_size=(3,3)  ):\n",
        "    super().__init__()\n",
        "    self.conv_layers = [tf.keras.layers.Conv2D(filters=n_filters , kernel_size= kernel_size , name=f\"{block_name}_conv{i+1}\",padding = 'same', activation='relu') for i in range (2)]\n",
        "  def call(self, inputs) :\n",
        "    x = inputs\n",
        "    for layer in self.conv_layers:\n",
        "      x=layer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Ky0wpWCXYxRo"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_Block_for_unt_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self,  n_filters , pool_size , dropout,block_name):\n",
        "    super().__init__()\n",
        "    self.conv = Unet_plus_plus_convolutional_block(n_filters=n_filters, block_name=block_name)\n",
        "    self.pool = tf.keras.layers.MaxPooling2D(pool_size=pool_size)\n",
        "    self.dropout = tf.keras.layers.Dropout(rate =dropout)\n",
        "  def call(self,inputs):\n",
        "    f=self.conv(inputs)\n",
        "    p = self.pool(f)\n",
        "    p = self.dropout(p)\n",
        "    return f ,  p"
      ],
      "metadata": {
        "id": "DoVSW0wMbWTe"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_for_unt_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.encoder1 = Encoder_Block_for_unt_plus_plus(n_filters=64, pool_size=(2,2) , dropout=0.3, block_name = 'encoder1')\n",
        "    self.encoder2 = Encoder_Block_for_unt_plus_plus(n_filters=128, pool_size=(2,2) , dropout=0.3, block_name = 'encoder2')\n",
        "    self.encoder3 = Encoder_Block_for_unt_plus_plus(n_filters=256, pool_size=(2,2) , dropout=0.3, block_name = 'encoder3')\n",
        "    self.encoder4 = Encoder_Block_for_unt_plus_plus(n_filters=512, pool_size=(2,2) , dropout=0.3, block_name = 'encoder4')\n",
        "  def call(self, inputs):\n",
        "    f1,p1 = self.encoder1(inputs)\n",
        "    f2,p2 = self.encoder2(p1)\n",
        "    f3,p3 = self.encoder3(p2)\n",
        "    f4,p4 = self.encoder4(p3)\n",
        "    return (f1,f2,f3,f4),(p1,p2,p3,p4)"
      ],
      "metadata": {
        "id": "8cis-R7e4ozB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleNeck_for_unet_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self ):\n",
        "    super().__init__()\n",
        "    self.bottle_neck = Unet_plus_plus_convolutional_block(n_filters=1024 , block_name = 'bottle_neck'  )\n",
        "  def call(self, inputs):\n",
        "    x = self.bottle_neck(inputs)\n",
        "    return x"
      ],
      "metadata": {
        "id": "r-p5Nw8n7TcD"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder_Block_for_unet_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self,n_filters  , dropout,block_name):\n",
        "    super().__init__()\n",
        "    self.conv = Unet_plus_plus_convolutional_block(n_filters=n_filters , block_name = block_name)\n",
        "    self.dropout = tf.keras.layers.Dropout(rate = dropout)\n",
        "    self.convTranspose = tf.keras.layers.Conv2DTranspose(n_filters, kernel_size = (3,3) , strides=(2,2) , padding = 'same')\n",
        "    self.concat = tf.keras.layers.Concatenate()\n",
        "\n",
        "  def call(self, conv_output_conc, inputs):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      if inputs.shape[1] <= 1 or inputs.shape[2] <= 1:\n",
        "\n",
        "          target_size = (max(conv_output_conc.shape[1], 1), max(conv_output_conc.shape[2], 1))\n",
        "          u = tf.image.resize(inputs, target_size)\n",
        "      else:\n",
        "          u = self.convTranspose(inputs)\n",
        "\n",
        "\n",
        "      if u.shape[1:3] != conv_output_conc.shape[1:3]:\n",
        "\n",
        "          if u.shape[1] * u.shape[2] < conv_output_conc.shape[1] * conv_output_conc.shape[2]:\n",
        "              u = tf.image.resize(u, (conv_output_conc.shape[1], conv_output_conc.shape[2]))\n",
        "          else:\n",
        "              conv_output_conc = tf.image.resize(conv_output_conc, (u.shape[1], u.shape[2]))\n",
        "\n",
        "      c = self.concat([u, conv_output_conc])\n",
        "      c = self.dropout(c)\n",
        "      c = self.conv(c)\n",
        "      return c"
      ],
      "metadata": {
        "id": "HKqiRcGr83D5"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder_for_unet_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self,num_classes = 19):\n",
        "    super().__init__()\n",
        "    self.decoder11 = Decoder_Block_for_unet_plus_plus(n_filters=64  , dropout = 0.3, block_name = 'skip_conv_block_11')\n",
        "    self.decoder12 = Decoder_Block_for_unet_plus_plus(n_filters=64  , dropout = 0.3, block_name = 'skip_conv_block_12')\n",
        "    self.decoder13 = Decoder_Block_for_unet_plus_plus(n_filters=64  , dropout = 0.3, block_name = 'skip_conv_block_13')\n",
        "    self.decoder14 = Decoder_Block_for_unet_plus_plus(n_filters=64  , dropout = 0.3, block_name = 'skip_conv_block_14')\n",
        "    self.decoder21 = Decoder_Block_for_unet_plus_plus(n_filters=128  , dropout = 0.3, block_name = 'skip_conv_block_21')\n",
        "    self.decoder22 = Decoder_Block_for_unet_plus_plus(n_filters=128  , dropout = 0.3, block_name = 'skip_conv_block_22')\n",
        "    self.decoder23 = Decoder_Block_for_unet_plus_plus(n_filters=128  , dropout = 0.3, block_name = 'skip_conv_block_23')\n",
        "    self.decoder31 = Decoder_Block_for_unet_plus_plus(n_filters=256  , dropout = 0.3, block_name = 'skip_conv_block_31')\n",
        "    self.decoder32 = Decoder_Block_for_unet_plus_plus(n_filters=256  , dropout = 0.3, block_name = 'skip_conv_block_32')\n",
        "    self.decoder41 = Decoder_Block_for_unet_plus_plus(n_filters=512  , dropout = 0.3, block_name = 'skip_conv_block_41')\n",
        "\n",
        "    self.concat12=tf.keras.layers.Concatenate()\n",
        "    self.concat13=tf.keras.layers.Concatenate()\n",
        "    self.concat14=tf.keras.layers.Concatenate()\n",
        "\n",
        "    self.concat22=tf.keras.layers.Concatenate()\n",
        "    self.concat23=tf.keras.layers.Concatenate()\n",
        "\n",
        "    self.concat32=tf.keras.layers.Concatenate()\n",
        "    self.bottle_neck = BottleNeck_for_unet_plus_plus()\n",
        "    self.output_layer14 = tf.keras.layers.Conv2D(\n",
        "        filters=num_classes,\n",
        "        kernel_size=(1,1),\n",
        "        activation='sigmoid' if num_classes == 1 else 'softmax',\n",
        "        padding='same',\n",
        "        name='output_layer'\n",
        "        )\n",
        "    self.output_layer13 = tf.keras.layers.Conv2D(\n",
        "        filters=num_classes,\n",
        "        kernel_size=(1,1),\n",
        "        activation='sigmoid' if num_classes == 1 else 'softmax',\n",
        "        padding='same',\n",
        "        name='output_layer'\n",
        "        )\n",
        "    self.output_layer12 = tf.keras.layers.Conv2D(\n",
        "        filters=num_classes,\n",
        "        kernel_size=(1,1),\n",
        "        activation='sigmoid' if num_classes == 1 else 'softmax',\n",
        "        padding='same',\n",
        "        name='output_layer'\n",
        "        )\n",
        "    self.output_layer11 = tf.keras.layers.Conv2D(\n",
        "        filters=num_classes,\n",
        "        kernel_size=(1,1),\n",
        "        activation='sigmoid' if num_classes == 1 else 'softmax',\n",
        "        padding='same',\n",
        "        name='output_layer'\n",
        "        )\n",
        "\n",
        "  def call(self, convs_cont , pool_cont):\n",
        "    f1,f2,f3,f4 = convs_cont\n",
        "    p1,p2,p3,p4 = pool_cont\n",
        "    for i, feat in enumerate([f1, f2, f3, f4, p1, p2, p3, p4]):\n",
        "        if feat.shape[1] < 1 or feat.shape[2] < 1:\n",
        "            print(f\"Warning: Feature map {i} has invalid dimensions: {feat.shape}\")\n",
        "    p5 = self.bottle_neck(p4)\n",
        "    decoder41 = self.decoder41(f4,p5)\n",
        "    decoder31 = self.decoder31(f3,p4)\n",
        "    conc32 = self.concat32([f3 , decoder31])\n",
        "    decoder32 = self.decoder32(conc32 , decoder41)\n",
        "    decoder21 = self.decoder21(f2,p3)\n",
        "    conc22 = self.concat22([f2,decoder21])\n",
        "    decoder22 = self.decoder22(conc22 , decoder31)\n",
        "    conc23 = self.concat23([f2,decoder21, decoder22])\n",
        "    decoder23 = self.decoder23(conc23 , decoder32)\n",
        "    decoder11 = self.decoder11(f1,p2)\n",
        "    conc12 = self.concat12([f1,decoder11])\n",
        "    decoder12 = self.decoder12(conc12 , decoder21)\n",
        "    conc13 = self.concat13([f1,decoder11,decoder12])\n",
        "    decoder13 = self.decoder13(conc13 , decoder22)\n",
        "    conc14 = self.concat14([f1 , decoder11  , decoder12 , decoder13])\n",
        "    decoder14 = self.decoder14(conc14 , decoder23)\n",
        "    output14 = self.output_layer14(decoder14)\n",
        "    output13 = self.output_layer13(decoder13)\n",
        "    output12 = self.output_layer12(decoder12)\n",
        "    output11 = self.output_layer11(decoder11)\n",
        "    return output11,output12,output13,output14"
      ],
      "metadata": {
        "id": "i9jopfkfASqD"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Unet_plus_plus(tf.keras.models.Model):\n",
        "    def __init__(self, min_input_size=16):\n",
        "        super().__init__()\n",
        "        self.min_input_size = min_input_size\n",
        "        self.encoder = Encoder_for_unt_plus_plus()\n",
        "        self.decoder = Decoder_for_unet_plus_plus()\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        input_shape = inputs.shape\n",
        "        if input_shape[1] < self.min_input_size or input_shape[2] < self.min_input_size:\n",
        "            raise ValueError(f\"Input image dimensions must be at least {self.min_input_size}x{self.min_input_size}\")\n",
        "\n",
        "        y, z = self.encoder(inputs)\n",
        "        output11, output12, output13, output14 = self.decoder(y, z)\n",
        "        return output11, output12, output13, output14"
      ],
      "metadata": {
        "id": "_QbqnnYvIS-v"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_plus_plus = Unet_plus_plus()"
      ],
      "metadata": {
        "id": "QhvmJp5cJ86_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**testing code for model**"
      ],
      "metadata": {
        "id": "bYo7fCzYMLoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "input_shape = (1, 256,256, 3)\n",
        "random_input = tf.random.normal(input_shape)\n",
        "\n",
        "# Initialize model\n",
        "\n",
        "\n",
        "# Run forward pass\n",
        "outputs = model122(random_input)\n",
        "\n",
        "# Print output shapes\n",
        "output_names = [\"fcn32\", \"fcn16\", \"fcn8\", \"fcn4\", \"fcn2\"]\n",
        "for name, out in zip(output_names, outputs):\n",
        "    print(f\"{name} output shape: {out.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO-8NqIPMOyR",
        "outputId": "bc4644f3-ab35-4708-8d7f-2a2d97caf4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fcn32 output shape: (1, 256, 256, 19)\n",
            "fcn16 output shape: (1, 256, 256, 19)\n",
            "fcn8 output shape: (1, 256, 256, 19)\n",
            "fcn4 output shape: (1, 256, 256, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model122.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "F_v-YwqH5Izm",
        "outputId": "124efd19-df32-4dfd-fed5-7c30cc1312f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"unet_plus_plus\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"unet_plus_plus\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_for_unt_plus_plus            │ ?                           │       \u001b[38;5;34m4,685,376\u001b[0m │\n",
              "│ (\u001b[38;5;33mEncoder_for_unt_plus_plus\u001b[0m)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder_for_unet_plus_plus           │ ?                           │      \u001b[38;5;34m36,064,972\u001b[0m │\n",
              "│ (\u001b[38;5;33mDecoder_for_unet_plus_plus\u001b[0m)         │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_for_unt_plus_plus            │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,685,376</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder_for_unt_plus_plus</span>)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder_for_unet_plus_plus           │ ?                           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">36,064,972</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder_for_unet_plus_plus</span>)         │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,750,348\u001b[0m (155.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,750,348</span> (155.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,750,348\u001b[0m (155.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,750,348</span> (155.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model122.save('model.keras')"
      ],
      "metadata": {
        "id": "Y2mqdoHT5-U1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files"
      ],
      "metadata": {
        "id": "K-t_7gG7z_TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# files.download('model.h5')"
      ],
      "metadata": {
        "id": "ERGbIpq80CJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# files.download('model.keras')"
      ],
      "metadata": {
        "id": "Py27qFeK0F75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initilizating instaces of the models**"
      ],
      "metadata": {
        "id": "fIfwcCtrYxqG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q-hssWV3olla",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "201880b9-9156-4238-fe78-3f61e15eadd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "missing a required argument: 'inputs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-84170099fe33>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfcn\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mFCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0munet_plus_plus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnet_plus_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mcan\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3194\u001b[0m         \"\"\"\n\u001b[0;32m-> 3195\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbind_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36m_bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3108\u001b[0m                             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'missing a required argument: {arg!r}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3109\u001b[0m                             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3110\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3111\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3112\u001b[0m                 \u001b[0;31m# We have a positional argument to process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: missing a required argument: 'inputs'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**defining loss**"
      ],
      "metadata": {
        "id": "pG9N7x9NpFX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class DiceLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, smooth=1e-6):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        y_true_f = tf.keras.backend.flatten(tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[-1]))\n",
        "        y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "\n",
        "        intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "        denominator = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
        "\n",
        "        dice_loss = 1 - (2.0 * intersection + self.smooth) / (denominator + self.smooth)\n",
        "        return dice_loss\n",
        "\n",
        "class SemanticSegmentationLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, alpha=1.0, beta=1.0):\n",
        "        super().__init__()\n",
        "        self.dice_loss = DiceLoss()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        ce = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
        "        dice_loss = self.dice_loss(y_true, y_pred)\n",
        "        return self.alpha * ce + self.beta * dice_loss\n"
      ],
      "metadata": {
        "id": "Zgqf26VNpmJO"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepSupervisionLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, weights=None, smooth=1e-6):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "        self.weights = weights or [1.0]\n",
        "        self.ce_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    def dice_loss(self, y_true, y_pred):\n",
        "        num_classes = tf.shape(y_pred)[-1]\n",
        "        y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=num_classes)\n",
        "        intersection = tf.reduce_sum(y_true_one_hot * y_pred, axis=[1, 2])\n",
        "        denominator = tf.reduce_sum(y_true_one_hot, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n",
        "        return 1 - (2.0 * intersection + self.smooth) / (denominator + self.smooth)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        total_loss = 0.0\n",
        "        num_outputs = len(y_pred)\n",
        "        self.weights = self.weights[:num_outputs] + [1.0] * (num_outputs - len(self.weights))\n",
        "        for i in range(num_outputs):\n",
        "            ce = self.ce_loss(y_true, y_pred[i])\n",
        "            dice = self.dice_loss(y_true, y_pred[i])\n",
        "            total_loss += self.weights[i] * (ce + dice)\n",
        "        return total_loss\n"
      ],
      "metadata": {
        "id": "VLllqFTgQm4p"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    optimizer = mixed_precision.LossScaleOptimizer(tf.keras.optimizers.Adam(learning_rate=1e-5), dynamic=True)"
      ],
      "metadata": {
        "id": "p00KctQJsIL1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "0a7011ef-b14b-4964-81f5-e85e65462e7a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'strategy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-f36964d846ee>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixed_precision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLossScaleOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'strategy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IOU metric**"
      ],
      "metadata": {
        "id": "HqLy6d_fQqWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IOUMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, n_classes=19, smooth=1e-6, name=\"iou\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.n_classes = n_classes\n",
        "        self.smooth = smooth\n",
        "        self.iou_sum = self.add_weight(name=\"iou_sum\", initializer=\"zeros\")\n",
        "        self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n",
        "    @tf.function\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "\n",
        "        y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=self.n_classes)\n",
        "        # y_pred = tf.nn.softmax(y_pred, axis=-1)\n",
        "\n",
        "\n",
        "        intersection = tf.reduce_sum(y_true * y_pred, axis=[0, 1, 2])\n",
        "        union = tf.reduce_sum(y_true, axis=[0, 1, 2]) + tf.reduce_sum(y_pred, axis=[0, 1, 2]) - intersection\n",
        "\n",
        "\n",
        "        iou_per_class = (intersection + self.smooth) / (union + self.smooth)\n",
        "\n",
        "\n",
        "        valid_classes = tf.cast(union > 0, tf.float32)\n",
        "        num_valid_classes = tf.reduce_sum(valid_classes)\n",
        "\n",
        "\n",
        "        mean_iou = tf.reduce_sum(iou_per_class * valid_classes) / tf.maximum(num_valid_classes, 1.0)\n",
        "\n",
        "\n",
        "        self.iou_sum.assign_add(mean_iou)\n",
        "        self.count.assign_add(1)\n",
        "    @tf.function\n",
        "    def result(self):\n",
        "        return self.iou_sum / tf.maximum(self.count, 1.0)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.iou_sum.assign(0)\n",
        "        self.count.assign(0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"n_classes\": self.n_classes, \"smooth\": self.smooth})\n",
        "        return config\n"
      ],
      "metadata": {
        "id": "fyxUTVNmwvIY"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**per class IOU metrics**"
      ],
      "metadata": {
        "id": "Jb5ZLJrUQxgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PerClassIOUMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, n_classes=19, smooth=1e-6, name=\"iou_per_class\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.n_classes = n_classes\n",
        "        self.smooth = smooth\n",
        "        self.sum_union = self.add_weight(name=\"sum_union\", shape=(n_classes,), initializer=\"zeros\")\n",
        "        self.sum_intersection = self.add_weight(name=\"sum_intersection\", shape=(n_classes,), initializer=\"zeros\")\n",
        "    @tf.function\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "\n",
        "        y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.n_classes)\n",
        "\n",
        "\n",
        "        intersection = tf.reduce_sum(y_true * y_pred, axis=[0, 1, 2])\n",
        "        union = tf.reduce_sum(y_true, axis=[0, 1, 2]) + tf.reduce_sum(y_pred, axis=[0, 1, 2]) - intersection\n",
        "\n",
        "\n",
        "        self.sum_union.assign_add(union)\n",
        "        self.sum_intersection.assign_add(intersection)\n",
        "    @tf.function\n",
        "    def result(self):\n",
        "        return (self.sum_intersection + self.smooth) / (self.sum_union + self.smooth)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.sum_intersection.assign(tf.zeros_like(self.sum_intersection))\n",
        "        self.sum_union.assign(tf.zeros_like(self.sum_union))\n"
      ],
      "metadata": {
        "id": "XVQfJePV-tjG"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dice Coeficient Metrics**"
      ],
      "metadata": {
        "id": "UI8rv85Uic1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dice_Coefficent_matrics(tf.keras.metrics.Metric):\n",
        "  def __init__(self, n_classes = 19 , smooth = 1e-6 , name = 'dice coefficent' , **kwargs):\n",
        "    super().__init__(name = name , **kwargs)\n",
        "    self.n_classes = n_classes\n",
        "    self.smooth = smooth\n",
        "    self.sum_dice_coefficent =self.add_weight(name=\"sum_dice_coeffient\", initializer=\"zeros\")\n",
        "    self.count =self.add_weight(name=\"count\", initializer=\"zeros\")\n",
        "  @tf.function\n",
        "  def update_state(self, y_true , y_pred , sample_weight = None):\n",
        "    y_true = tf.one_hot(tf.cast(y_true , dtype= tf.int32) , depth=self.n_classes)\n",
        "\n",
        "    intersection = tf.reduce_sum (y_true * y_pred , axis = [0,1,2])\n",
        "    total_area = tf.reduce_sum(y_pred, axis=[0,1,2])  + tf.reduce_sum(y_true , axis=[0,1,2])\n",
        "\n",
        "    dice_score = 2 * (intersection+ self.smooth)/(total_area +self.smooth)\n",
        "    valid_classes = tf.cast(total_area > 0, tf.float32)\n",
        "    num_valid_classes = tf.reduce_sum(valid_classes)\n",
        "\n",
        "    mean_dice = tf.reduce_sum(dice_score * valid_classes) / tf.maximum(num_valid_classes, 1.0)\n",
        "\n",
        "    self.sum_dice_coefficent.assign_add(dice_score)\n",
        "    self.count.assign_add(1)\n",
        "  @tf.function\n",
        "  def result(self ):\n",
        "    return self.sum_dice_coefficent/tf.maximum(self.count, 1.0)\n",
        "  def reset_state(self):\n",
        "    self.sum_dice_coefficent.assign(0)\n",
        "    self.count.assign(0)"
      ],
      "metadata": {
        "id": "UVd2Y6GxVtPl"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**per class_dice_coefficent metrics**"
      ],
      "metadata": {
        "id": "YLNA7ijum2vZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PerClassDiceCoefficientMatrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, n_classes=19, smooth=1e-6, name=\"dice_per_class\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.n_classes = n_classes\n",
        "        self.smooth = smooth\n",
        "        self.sum_intersection = self.add_weight(name=\"sum_intersection\", shape=(n_classes,), initializer=\"zeros\")\n",
        "        self.sum_union = self.add_weight(name=\"sum_union\", shape=(n_classes,), initializer=\"zeros\")\n",
        "    @tf.function\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "\n",
        "        y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.n_classes)\n",
        "\n",
        "        intersection = tf.reduce_sum(y_true * y_pred, axis=[0, 1, 2])\n",
        "        sum_areas = tf.reduce_sum(y_true, axis=[0, 1, 2]) + tf.reduce_sum(y_pred, axis=[0, 1, 2])\n",
        "\n",
        "        self.sum_intersection.assign_add(intersection)\n",
        "        self.sum_union.assign_add(sum_areas)\n",
        "    @tf.function\n",
        "    def result(self):\n",
        "        return (2.0 * self.sum_intersection + self.smooth) / (self.sum_union + self.smooth)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.sum_intersection.assign(tf.zeros_like(self.sum_intersection))\n",
        "        self.sum_union.assign(tf.zeros_like(self.sum_union))\n"
      ],
      "metadata": {
        "id": "qd-b0q9nmYZd"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pixel Accurcy Metrics**"
      ],
      "metadata": {
        "id": "JkxRcmDDnKth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Pixel_accurcy_metrics(tf.keras.metrics.Metric):\n",
        "  def __init__(self, n_classes = 19  , name = 'pixel_accurcy_metrics' , **kwargs):\n",
        "    super().__init__(name = name , **kwargs)\n",
        "    self.n_classes = n_classes\n",
        "    self.sum_pixel_wise_accurcy = self.add_weight(name=\"sum_pixel_wise_accurcy\", initializer=\"zeros\")\n",
        "    self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n",
        "  @tf.function\n",
        "  def update_state(self, y_true , y_pred  , sample_weight  = None) :\n",
        "    y_true = tf.one_hot(tf.cast(y_true , dtype=tf.int32) , depth = self.n_classes)\n",
        "    y_pred = tf.one_hot(tf.argmax(y_pred , axis=-1) , depth = self.n_classes)\n",
        "    correct_pixel = tf.reduce_sum(y_true * y_pred)\n",
        "    total_pixel = tf.reduce_prod(tf.shape(y_true)[:-1])\n",
        "    pixel_accuracy = (correct_pixel)/tf.maximum(total_pixel,1.0)\n",
        "    self.sum_pixel_wise_accurcy.assign_add(pixel_accuracy)\n",
        "    self.count.assign_add(1)\n",
        "  @tf.function\n",
        "  def result(self):\n",
        "    return self.sum_pixel_wise_accurcy/tf.maximum(self.count, 1.0)\n",
        "  def reset_state(self):\n",
        "    self.sum_pixel_wise_accurcy.assign(0)\n",
        "    self.count.assign(0)"
      ],
      "metadata": {
        "id": "boqIP7CWm8Gy"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**optimizer**"
      ],
      "metadata": {
        "id": "hbxDqaLiU2LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  optimizer_fcn = tf.optimizers.AdamW(learning_rate=1e-4 , weight_decay=1e-5)\n",
        "  optimizer_unet = tf.optimizers.AdamW(learning_rate=1e-4 , weight_decay=1e-5)\n",
        "  optimizer_unet_plus_plus = tf.optimizers.AdamW(learning_rate=1e-4 , weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "3rhyJcz4U4dz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "9b9be305-98fd-43df-d0b0-6ff06c628872"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'strategy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-56028bc1ea0c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0moptimizer_fcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0moptimizer_unet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0moptimizer_unet_plus_plus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'strategy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_fcn = mixed_precision.LossScaleOptimizer(tf.optimizers.AdamW(learning_rate=1e-4 , weight_decay=1e-5),dynamic = True)\n",
        "optimizer_unet = mixed_precision.LossScaleOptimizer(tf.optimizers.AdamW(learning_rate=1e-4 , weight_decay=1e-5),dynamic = True)\n",
        "optimizer_unet_plus_plus = mixed_precision.LossScaleOptimizer(tf.optimizers.AdamW(learning_rate=1e-4 , weight_decay=1e-5),dynamic=True)"
      ],
      "metadata": {
        "id": "EkI53Row67bK"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**checkPoint dirs**"
      ],
      "metadata": {
        "id": "j72q95Pjob9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir_fcn = '/content/drive/MyDrive/CityScapes_model_checkpoints/fcn'\n",
        "checkpoint_dir_unet = '/content/drive/MyDrive/CityScapes_model_checkpoints/unet'\n",
        "checkpoint_dir_unet_plus_plus = '/content/drive/MyDrive/CityScapes_model_checkpoints/unet_plus_plus'\n",
        "log_dir = '/content/drive/MyDrive/CityScapes_model_checkpoints/log_dir'"
      ],
      "metadata": {
        "id": "Jolqu8_FoelE"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**custom callbacks**"
      ],
      "metadata": {
        "id": "Wr83oImgE-T7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Custom_checkpoint_Callabck(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, checkpoint_dir_fcn , checkpoint_dir_unet , checkpoint_dir_unet_plus_plus , fcn , unet , unet_plus_plus , optimizer_fcn ,optimizer_unet ,optimizer_unet_plus_plus  ) :\n",
        "    super().__init__()\n",
        "    self.checkpoint_dir_fcn = checkpoint_dir_fcn\n",
        "    self.checkpoint_dir_unet = checkpoint_dir_unet\n",
        "    self.checkpoint_dir_unet_plus_plus = checkpoint_dir_unet_plus_plus\n",
        "    self.checkpoint_fcn = tf.train.Checkpoint(\n",
        "        model = fcn ,\n",
        "        optimizer = optimizer_fcn,\n",
        "        epoch = tf.Variable(0 , dtype = tf.int64)\n",
        "    )\n",
        "    self.checkpoint_manager_for_fcn = tf.train.CheckpointManager(\n",
        "        self.checkpoint_fcn ,\n",
        "        self.checkpoint_dir_fcn ,\n",
        "        max_to_keep=3\n",
        "    )\n",
        "    self.checkpoint_unet = tf.train.Checkpoint(\n",
        "        model = unet ,\n",
        "        optimizer = optimizer_unet,\n",
        "        epoch = tf.Variable(0 , dtype = tf.int64)\n",
        "    )\n",
        "    self.checkpoint_manager_for_unet = tf.train.CheckpointManager(\n",
        "        self.checkpoint_unet ,\n",
        "        self.checkpoint_dir_unet ,\n",
        "        max_to_keep=3\n",
        "    )\n",
        "    self.checkpoint_unet_plus_plus = tf.train.Checkpoint(\n",
        "        model = unet_plus_plus ,\n",
        "        optimizer = optimizer_unet_plus_plus,\n",
        "        epoch = tf.Variable(0 , dtype = tf.int64)\n",
        "    )\n",
        "    self.checkpoint_manager_for_unet_plus_plus = tf.train.CheckpointManager(\n",
        "        self.checkpoint_unet_plus_plus ,\n",
        "        self.checkpoint_dir_unet_plus_plus ,\n",
        "        max_to_keep=3\n",
        "    )\n",
        "  def on_epoch_end(self , epoch, logs = None):\n",
        "    self.checkpoint_fcn.epoch.assign(epoch+1)\n",
        "    self.checkpoint_manager_for_fcn.save()\n",
        "    print(f\"\\nCheckpoint saved for epoch {epoch } at {self.checkpoint_manager_for_fcn.latest_checkpoint} for fcn model\")\n",
        "    self.checkpoint_unet.epoch.assign(epoch+1)\n",
        "    self.checkpoint_manager_for_unet.save()\n",
        "    print(f\"\\nCheckpoint saved for epoch {epoch } at {self.checkpoint_manager_for_unet.latest_checkpoint} for unet model\")\n",
        "    self.checkpoint_unet_plus_plus.epoch.assign(epoch+1)\n",
        "    self.checkpoint_manager_for_unet_plus_plus.save()\n",
        "    print(f\"\\nCheckpoint saved for epoch {epoch } at {self.checkpoint_manager_for_unet_plus_plus.latest_checkpoint} for unet_plus_plus model\")\n",
        "  def load_latest_model(self):\n",
        "    if self.checkpoint_manager_for_fcn.latest_checkpoint and self.checkpoint_manager_for_unet.latest_checkpoint and self.checkpoint_manager_for_unet_plus_plus.latest_checkpoint :\n",
        "\n",
        "      self.checkpoint_fcn.restore(self.checkpoint_manager_for_fcn.latest_checkpoint)\n",
        "      self.checkpoint_unet.restore(self.checkpoint_manager_for_unet.latest_checkpoint)\n",
        "      self.checkpoint_unet_plus_plus.restore(self.checkpoint_manager_for_unet_plus_plus.latest_checkpoint)\n",
        "      start_epoch =self.checkpoint_fcn.epoch.numpy()\n",
        "      print(f\"Restored from checkpoint: {self.checkpoint_manager_for_fcn.latest_checkpoint}, \"\n",
        "                  f\"resuming from epoch {start_epoch}\")\n",
        "      print(f\"Restored from checkpoint: {self.checkpoint_manager_for_unet.latest_checkpoint}, \"\n",
        "                  f\"resuming from epoch {start_epoch}\")\n",
        "      print(f\"Restored from checkpoint: {self.checkpoint_manager_for_unet_plus_plus.latest_checkpoint}, \"\n",
        "                  f\"resuming from epoch {start_epoch}\")\n",
        "      return start_epoch\n",
        "    else :\n",
        "      print('no checkpoint found starting from epoch 1')\n",
        "      return 1\n"
      ],
      "metadata": {
        "id": "az4V0gCqFDCt"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Custom_early_stopping_callback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, paticance = 15  , min_delta = 1e-4):\n",
        "    self.patiance = paticance\n",
        "    self.min_delta = min_delta\n",
        "    self.best_loss = {\n",
        "        'fcn' : float('inf') ,\n",
        "        'unet' : float('inf') ,\n",
        "        'unet_plus_plus' : float('inf')\n",
        "    }\n",
        "    self.stoped_epoch = 0\n",
        "    self.wait = {\n",
        "        'fcn' : 0 ,\n",
        "        'unet': 0 ,\n",
        "        'unet_plus_plus' : 0\n",
        "    }\n",
        "  def early_stoping(self, epoch , val_loss):\n",
        "    if (val_loss['fcn']< self.best_loss['fcn']-self.min_delta):\n",
        "      self.best_loss['fcn'] = val_loss['fcn']\n",
        "      self.wait['fcn'] = 0\n",
        "    else :\n",
        "      self.wait['fcn'] +=1\n",
        "    if (val_loss['unet']< self.best_loss['unet']-self.min_delta):\n",
        "      self.best_loss['unet'] = val_loss['unet']\n",
        "      self.wait['unet'] = 0\n",
        "    else  :\n",
        "      self.wait['unet']+=1\n",
        "    if (val_loss['unet_plus_plus']< self.best_loss['unet_plus_plus']-self.min_delta):\n",
        "      self.best_loss['unet_plus_plus'] = val_loss['unet_plus_plus']\n",
        "      self.wait['unet_plus_plus'] = 0\n",
        "    else :\n",
        "      self.wait['unet_plus_plus']+=1\n",
        "    if self.wait['fcn'] > self.patiance and self.wait['unet']>self.patiance and self.wait['unet_plus_plus']>self.patiance:\n",
        "      self.stoped_epoch  =epoch\n",
        "      print (f'early stoping trainig at {self.stoped_epoch}')\n",
        "      return True\n",
        "    return False\n"
      ],
      "metadata": {
        "id": "_m7da_J8G566"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Custom_learning_rate_schedule(tf.keras.callbacks.Callback):\n",
        "  def __init__(self , optimizer_fcn , optimizer_unet , optimizer_unet_plus_plus , factor = 0.5 , patiance = 5 , min_delta = 1e-4 , min_lr = 1e-8 ):\n",
        "    super().__init__()\n",
        "    self.factor = factor\n",
        "    self.patiance = patiance\n",
        "    self.min_delta = min_delta\n",
        "    self.min_lr = min_lr\n",
        "    self.best_val_loss = {\n",
        "        'fcn' : float('inf') ,\n",
        "        'unet': float('inf') ,\n",
        "        'unet_plus_plus' : float('inf')\n",
        "    }\n",
        "    self.optimzer  = {\n",
        "        'fcn' : optimizer_fcn ,\n",
        "        'unet' : optimizer_fcn ,\n",
        "        'unet_plus_plus': optimizer_unet_plus_plus\n",
        "    }\n",
        "    self.wait = {\n",
        "        'fcn' : 0 ,\n",
        "        'unet': 0 ,\n",
        "        'unet_plus_plus' : 0\n",
        "    }\n",
        "  def change_learning_rate(self, epoch , val_loss):\n",
        "    for model_name , val_loss in val_loss.items():\n",
        "      if val_loss < self.best_val_loss[model_name]-self.min_delta:\n",
        "        self.best_val_loss[model_name] = val_loss\n",
        "        self.wait[model_name] = 0\n",
        "      else :\n",
        "        self.wait[model_name] +=1\n",
        "      if self.wait[model_name] >= self.patiance :\n",
        "        old_lr = self.optimzer[model_name].lr.numpy()\n",
        "        new_lr = tf.maximum(old_lr*self.factor , self.min_lr)\n",
        "        self.optimzer[model_name].lr.assign(new_lr)\n",
        "        print (f'learning rate for model : {model_name} has been change from : {old_lr} to the new lr : {new_lr} at epoch : {epoch}')\n",
        "        self.wait= 0\n"
      ],
      "metadata": {
        "id": "NGFZO7E5UMgH"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Custom_Training_logger_callback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, batches_per_epoch):\n",
        "    super().__init__()\n",
        "    self.model_name = ['fcn' , 'unet' , 'unet_plus_plus']\n",
        "    self.batch_per_epoch = batches_per_epoch\n",
        "    self.batch_table_display = None\n",
        "    self.graph_display = None\n",
        "  def On_epoch_begin(self, epoch ):\n",
        "    print(f'Epoch begins : {epoch}')\n",
        "    self.progress_bar = tqdm(total=self.batch_per_epoch,desc=f'epoch {epoch}')\n",
        "    self.batch_table_data = []\n",
        "    self.batch_loss = {\n",
        "        'fcn':[] ,\n",
        "        'unet': [] ,\n",
        "        'unet_plus_plus' :[]\n",
        "    }\n",
        "    self.batch_val_loss = {\n",
        "        'fcn' :[] ,\n",
        "        'unet' : [] ,\n",
        "        'unet_plus_plus' : []\n",
        "    }\n",
        "    self.epoch_table_data = []\n",
        "    display(HTML('<h3>📊 Batch-wise Loss Table</h3>'))\n",
        "  def on_batch_end(self, batch , epoch,data = None):\n",
        "    self.progress_bar.set_postfix({\n",
        "        f'epoch :{epoch} , batch ': batch / self.batch_per_epoch\n",
        "        })\n",
        "    self.progress_bar.update(1)\n",
        "    if data == None :\n",
        "      return\n",
        "    self.batch_table_data.append({\n",
        "        'batch': batch ,\n",
        "        'fcn_loss' : data['fcn']['loss'] ,\n",
        "\n",
        "        'unet_loss' :data['unet']['loss'],\n",
        "\n",
        "        'unet_plus_plus_loss' : data['unet_plus_plus']['loss']  ,\n",
        "\n",
        "        'fcn_IOUMetric' : data['fcn']['metrics']['IOUMetric'] ,\n",
        "        'fcn_PerClassIOUMetric' : data['fcn']['metrics']['PerClassIOUMetric'],\n",
        "        'fcn_Dice_Coefficent_matrics' :  data['fcn']['metrics']['Dice_Coefficent_matrics'],\n",
        "        'fcn_PerClassDiceCoefficientMatrics' : data['fcn']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "        'fcn_Pixel_accurcy_metrics' : data['fcn']['metrics']['Pixel_accurcy_metrics'],\n",
        "        'unet_IOUMetric' : data['unet']['metrics']['IOUMetric'] ,\n",
        "        'unet_PerClassIOUMetric' : data['unet']['metrics']['PerClassIOUMetric'],\n",
        "        'unet_Dice_Coefficent_matrics' :  data['unet']['metrics']['Dice_Coefficent_matrics'],\n",
        "        'unet_PerClassDiceCoefficientMatrics' : data['unet']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "        'unet_Pixel_accurcy_metrics' : data['unet']['metrics']['Pixel_accurcy_metrics'],\n",
        "        'unet_plus_plus_IOUMetric' : data['unet_plus_plus']['metrics']['IOUMetric'] ,\n",
        "        'unet_plus_plus_PerClassIOUMetric' : data['unet_plus_plus']['metrics']['PerClassIOUMetric'],\n",
        "        'unet_plus_plus_Dice_Coefficent_matrics' :  data['unet_plus_plus']['metrics']['Dice_Coefficent_matrics'],\n",
        "        'unet_plus_plus_PerClassDiceCoefficientMatrics' : data['unet_plus_plus']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "        'unet_plus_plus_Pixel_accurcy_metrics' : data['unet_plus_plus']['metrics']['Pixel_accurcy_metrics'],\n",
        "\n",
        "      })\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(self.batch_table_data)\n",
        "\n",
        "    if self.batch_table_display is None:\n",
        "      self.batch_table_display = display( df, display_id=True)\n",
        "    else :\n",
        "      self.batch_table_display.update(df)\n",
        "    self.batch_loss['fcn'].append(data['fcn']['loss'])\n",
        "    self.batch_loss['unet'].append(data['unet']['loss'])\n",
        "    self.batch_loss['unet_plus_plus'].append(data['unet_plus_plus']['loss'])\n",
        "    self.batch_val_loss['fcn'].append(data['fcn']['val_loss'])\n",
        "    self.batch_val_loss['unet'].append(data['unet']['val_loss'])\n",
        "    self.batch_val_loss['unet_plus_plus'].append(data['unet_plus_plus']['val_loss'])\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    axes[0].plot(self.batch_loss['fcn'], label='FCN Loss', marker='o')\n",
        "    axes[0].plot(self.batch_loss['unet'], label='U-Net Loss', marker='o')\n",
        "    axes[0].plot(self.batch_loss['unet_plus_plus'], label='U-Net++ Loss', marker='o')\n",
        "    axes[0].set_title('Training Loss')\n",
        "    axes[0].set_xlabel('Batch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if self.graph_display is None:\n",
        "      display(HTML('<h3>📉 Loss Graphs (Batch-wise Trend)</h3>'))\n",
        "      self.graph_display = display(fig, display_id=True)\n",
        "    else:\n",
        "      self.graph_display.update(fig)\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "  def on_epoch_end(self , epoch ,data):\n",
        "    self.progress_bar.close()\n",
        "    if data == None :\n",
        "      return\n",
        "    display(HTML('<h3>📊 Epoch Summary Table</h3>'))\n",
        "    self.epoch_table_data.append({\n",
        "        'epoch': epoch ,\n",
        "        'fcn_loss' : data['fcn']['loss'] ,\n",
        "        'fcn_val_loss':data['fcn']['val_loss'] ,\n",
        "        'unet_loss' :data['unet']['loss'],\n",
        "        'unet_val_loss' : data['unet']['val_loss'] ,\n",
        "        'unet_plus_plus_loss' : data['unet_plus_plus']['loss']  ,\n",
        "        'unet_plus_plus_val_loss' : data['unet_plus_plus']['val_loss'],\n",
        "        'fcn_IOUMetric' : data['fcn']['metrics']['IOUMetric'] ,\n",
        "        'fcn_PerClassIOUMetric' : data['fcn']['metrics']['PerClassIOUMetric'],\n",
        "        'fcn_Dice_Coefficent_matrics' :  data['fcn']['metrics']['Dice_Coefficent_matrics'],\n",
        "        'fcn_PerClassDiceCoefficientMatrics' : data['fcn']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "        'fcn_Pixel_accurcy_metrics' : data['fcn']['metrics']['Pixel_accurcy_metrics'],\n",
        "        'unet_IOUMetric' : data['unet']['metrics']['IOUMetric'] ,\n",
        "        'unet_PerClassIOUMetric' : data['unet']['metrics']['PerClassIOUMetric'],\n",
        "        'unet_Dice_Coefficent_matrics' :  data['unet']['metrics']['Dice_Coefficent_matrics'],\n",
        "        'unet_PerClassDiceCoefficientMatrics' : data['unet']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "        'unet_Pixel_accurcy_metrics' : data['unet']['metrics']['Pixel_accurcy_metrics'],\n",
        "        'unet_plus_plus_IOUMetric' : data['unet_plus_plus']['metrics']['IOUMetric'] ,\n",
        "        'unet_plus_plus_PerClassIOUMetric' : data['unet_plus_plus']['metrics']['PerClassIOUMetric'],\n",
        "        'unet_plus_plus_Dice_Coefficent_matrics' :  data['unet_plus_plus']['metrics']['Dice_Coefficent_matrics'],\n",
        "        'unet_plus_plus_PerClassDiceCoefficientMatrics' : data['unet_plus_plus']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "        'unet_plus_plus_Pixel_accurcy_metrics' : data['unet_plus_plus']['metrics']['Pixel_accurcy_metrics'],\n",
        "\n",
        "        'fcn_IOUMetric_val' : data['fcn']['metrics']['IOUMetric_val'] ,\n",
        "        'fcn_PerClassIOUMetric_val' : data['fcn']['metrics']['PerClassIOUMetric_val'],\n",
        "        'fcn_Dice_Coefficent_matrics_val' :  data['fcn']['metrics']['Dice_Coefficent_matrics_val'],\n",
        "        'fcn_PerClassDiceCoefficientMatrics_val' : data['fcn']['metrics']['PerClassDiceCoefficientMatrics_val'],\n",
        "        'fcn_Pixel_accurcy_metrics_val' : data['fcn']['metrics']['Pixel_accurcy_metrics_val'],\n",
        "        'unet_IOUMetric_val' : data['unet']['metrics']['IOUMetric_val'] ,\n",
        "        'unet_PerClassIOUMetric_val' : data['unet']['metrics']['PerClassIOUMetric_val'],\n",
        "        'unet_Dice_Coefficent_matrics_val' :  data['unet']['metrics']['Dice_Coefficent_matrics_val'],\n",
        "        'unet_PerClassDiceCoefficientMatrics_val' : data['unet']['metrics']['PerClassDiceCoefficientMatrics_val'],\n",
        "        'unet_Pixel_accurcy_metrics_val' : data['unet']['metrics']['Pixel_accurcy_metrics_val'],\n",
        "        'unet_plus_plus_IOUMetric_val' : data['unet_plus_plus']['metrics']['IOUMetric_val'] ,\n",
        "        'unet_plus_plus_PerClassIOUMetric_val' : data['unet_plus_plus']['metrics']['PerClassIOUMetric_val'],\n",
        "        'unet_plus_plus_Dice_Coefficent_matrics_val' :  data['unet_plus_plus']['metrics']['Dice_Coefficent_matrics_val'],\n",
        "        'unet_plus_plus_PerClassDiceCoefficientMatrics_val' : data['unet_plus_plus']['metrics']['PerClassDiceCoefficientMatrics_val'],\n",
        "        'unet_plus_plus_Pixel_accurcy_metrics_val' : data['unet_plus_plus']['metrics']['Pixel_accurcy_metrics_val'],\n",
        "      })\n",
        "    df=pd.DataFrame(self.epoch_table_data)\n",
        "    display(df)\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    axes[0].plot(self.batch_loss['fcn'], label='FCN Loss', marker='o')\n",
        "    axes[0].plot(self.batch_loss['unet'], label='U-Net Loss', marker='o')\n",
        "    axes[0].plot(self.batch_loss['unet_plus_plus'], label='U-Net++ Loss', marker='o')\n",
        "    axes[0].set_title('Training Loss')\n",
        "    axes[0].set_xlabel('Batch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    display(HTML(f'<h3>📉 Final Loss Graphs - Epoch {epoch + 1}</h3>'))\n",
        "    self.final_graph_display = display(fig, display_id=f'final_graph_epoch_{epoch + 1}')\n",
        "    plt.close(fig)"
      ],
      "metadata": {
        "id": "wOdDahlsAFkl"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Master_callback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, log_dir , checkpoint_dir_fcn , checkpoint_dir_unet ,                 checkpoint_dir_unet_plus_plus , fcn , unet , unet_plus_plus , optimizer_fcn ,optimizer_unet ,   optimizer_unet_plus_plus , batches_per_epoch  ):\n",
        "    self.writer=tf.summary.create_file_writer(logdir=log_dir)\n",
        "    # initilizing custom checkpoint callback\n",
        "    self.ccc = Custom_checkpoint_Callabck(checkpoint_dir_fcn=checkpoint_dir_fcn,checkpoint_dir_unet=checkpoint_dir_unet , checkpoint_dir_unet_plus_plus=checkpoint_dir_unet_plus_plus , fcn = fcn , unet = unet , unet_plus_plus=unet_plus_plus , optimizer_fcn=optimizer_fcn , optimizer_unet=optimizer_unet , optimizer_unet_plus_plus=optimizer_unet_plus_plus )\n",
        "    # initilizing custom ealry stoping callback\n",
        "    self.cesc = Custom_early_stopping_callback()\n",
        "    # initilizing custom learning rate scheduler\n",
        "    self.clrs = Custom_learning_rate_schedule(optimizer_fcn=optimizer_fcn , optimizer_unet=optimizer_unet , optimizer_unet_plus_plus=optimizer_unet_plus_plus)\n",
        "    # initilizing custom training logger\n",
        "    self.ctlc = Custom_Training_logger_callback(batches_per_epoch=batches_per_epoch)\n",
        "    self.stop = False\n",
        "\n",
        "  def on_train_begin(self):\n",
        "    return self.ccc.load_latest_model()\n",
        "  def on_epoch_begin(self, epoch ):\n",
        "    self.ctlc.On_epoch_begin(epoch)\n",
        "  def on_batch_end(self,batch , epoch , data):\n",
        "    self.ctlc.on_batch_end(batch , epoch , data)\n",
        "  def on_epoch_end(self, epoch , data):\n",
        "    self.ctlc.on_epoch_end(epoch , data)\n",
        "    # summary -->\n",
        "    with self.writer.as_default():\n",
        "      tf.summary.scalar('fcn_loss' , data['fcn']['loss'],step=epoch)\n",
        "      tf.summary.scalar('fcn_val_loss' , data['fcn']['val_loss'],step=epoch)\n",
        "      tf.summary.scalar('unet_loss' , data['unet']['loss'],step=epoch)\n",
        "      tf.summary.scalar('uent_val_loss' , data['unet']['val_loss'],step=epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_loss' , data['unet_plus_plus']['loss'],step=epoch)\n",
        "      tf.summary.scalar('uent_plus_plus_val_loss' , data['unet_plus_plus']['val_loss'],step=epoch)\n",
        "      tf.summary.scalar('fcn_IOUMetric',data['fcn']['metrics']['IOUMetric'] , step = epoch)\n",
        "      tf.summary.scalar('fcn_PerClassIOUMetric' , data['fcn']['metrics']['PerClassIOUMetric'] , step = epoch)\n",
        "      tf.summary.scalar('fcn_Dice_Coefficent_matrics' ,  data['fcn']['metrics']['Dice_Coefficent_matrics'] , step = epoch)\n",
        "      tf.summary.scalar('fcn_PerClassDiceCoefficientMatrics' , data['fcn']['metrics']['PerClassDiceCoefficientMatrics'] , step = epoch)\n",
        "      tf.summary.scalar('fcn_Pixel_accurcy_metrics' , data['fcn']['metrics']['Pixel_accurcy_metrics'], step = epoch)\n",
        "\n",
        "      tf.summary.scalar('unet_IOUMetric',data['unet']['metrics']['IOUMetric'] , step = epoch)\n",
        "      tf.summary.scalar('unet_PerClassIOUMetric' , data['unet']['metrics']['PerClassIOUMetric'] , step = epoch)\n",
        "      tf.summary.scalar('unet_Dice_Coefficent_matrics' ,  data['unet']['metrics']['Dice_Coefficent_matrics'] , step = epoch)\n",
        "      tf.summary.scalar('unet_PerClassDiceCoefficientMatrics' , data['unet']['metrics']['PerClassDiceCoefficientMatrics'] , step = epoch)\n",
        "      tf.summary.scalar('unet_Pixel_accurcy_metrics' , data['unet']['metrics']['Pixel_accurcy_metrics'], step = epoch)\n",
        "\n",
        "      tf.summary.scalar('unet_plus_plus_IOUMetric',data['unet_plus_plus']['metrics']['IOUMetric'] , step = epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_PerClassIOUMetric' , data['unet_plus_plus']['metrics']['PerClassIOUMetric'] , step = epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_Dice_Coefficent_matrics' ,  data['unet_plus_plus']['metrics']['Dice_Coefficent_matrics'] , step = epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_PerClassDiceCoefficientMatrics' , data['unet_plus_plus']['metrics']['PerClassDiceCoefficientMatrics'] , step = epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_Pixel_accurcy_metrics' , data['unet_plus_plus']['metrics']['Pixel_accurcy_metrics'], step = epoch)\n",
        "\n",
        "      tf.summary.scalar('fcn_IOUMetric_val',data['fcn']['metrics']['IOUMetric_val'] , step = epoch)\n",
        "      tf.summary.scalar('fcn_PerClassIOUMetric_val' , data['fcn']['metrics']['PerClassIOUMetric_val'] , step = epoch)\n",
        "      tf.summary.scalar('fcn_Dice_Coefficent_matrics_val' ,  data['fcn']['metrics']['Dice_Coefficent_matrics_val'] , step = epoch)\n",
        "      tf.summary.scalar('fcn_PerClassDiceCoefficientMatrics_val' , data['fcn']['metrics']['PerClassDiceCoefficientMatrics_val'] , step = epoch)\n",
        "      tf.summary.scalar('fcn_Pixel_accurcy_metrics_val' , data['fcn']['metrics']['Pixel_accurcy_metrics_val'], step = epoch)\n",
        "\n",
        "      tf.summary.scalar('unet_IOUMetric_val',data['unet']['metrics']['IOUMetric_val'] , step = epoch)\n",
        "      tf.summary.scalar('unet_PerClassIOUMetric_val' , data['unet']['metrics']['PerClassIOUMetric_val'] , step = epoch)\n",
        "      tf.summary.scalar('unet_Dice_Coefficent_matrics_val' ,  data['unet']['metrics']['Dice_Coefficent_matrics_val'] , step = epoch)\n",
        "      tf.summary.scalar('unet_PerClassDiceCoefficientMatrics_val' , data['unet']['metrics']['PerClassDiceCoefficientMatrics_val'] , step = epoch)\n",
        "      tf.summary.scalar('unet_Pixel_accurcy_metrics_val' , data['unet']['metrics']['Pixel_accurcy_metrics__val'], step = epoch)\n",
        "\n",
        "      tf.summary.scalar('unet_plus_plus_IOUMetric_val',data['unet_plus_plus']['metrics']['IOUMetric_val'] , step = epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_PerClassIOUMetric_val' , data['unet_plus_plus']['metrics']['PerClassIOUMetric_val'] , step = epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_Dice_Coefficent_matrics_val' ,  data['unet_plus_plus']['metrics']['Dice_Coefficent_matrics_val'] , step = epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_PerClassDiceCoefficientMatrics_val' , data['unet_plus_plus']['metrics']['PerClassDiceCoefficientMatrics_val'] , step = epoch)\n",
        "      tf.summary.scalar('unet_plus_plus_Pixel_accurcy_metrics_val' , data['unet_plus_plus']['metrics']['Pixel_accurcy_metrics_val'], step = epoch)\n",
        "    self.writer.flush()\n",
        "    self.ccc.on_epoch_end(epoch)\n",
        "    self.clrs.change_learning_rate(epoch ,{\n",
        "        'fcn' : data['fcn']['val_loss'] ,\n",
        "        'unet' :  data['unet']['val_loss'] ,\n",
        "        'unet_plus_plus' :  data['unet_plus_plus']['val_loss']\n",
        "    })\n",
        "    return self.cesc.early_stoping(epoch , {\n",
        "        'fcn' : data['fcn']['val_loss'] ,\n",
        "        'unet' :  data['unet']['val_loss'] ,\n",
        "        'unet_plus_plus' :  data['unet_plus_plus']['val_loss']\n",
        "    })"
      ],
      "metadata": {
        "id": "lZb3PnfxLOWu"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**initilizing instances**"
      ],
      "metadata": {
        "id": "ugK4Tt5h7myZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batches_per_epoch = 100\n",
        "master_callback =Master_callback(log_dir=log_dir , checkpoint_dir_fcn=checkpoint_dir_fcn , checkpoint_dir_unet=checkpoint_dir_unet , checkpoint_dir_unet_plus_plus=checkpoint_dir_unet_plus_plus , fcn=fcn , unet = unet , unet_plus_plus=unet_plus_plus , optimizer_fcn=optimizer_fcn , optimizer_unet=optimizer_unet , optimizer_unet_plus_plus=optimizer_unet_plus_plus , batches_per_epoch=batches_per_epoch)\n",
        "fcn_SemanticSegmentationLoss=SemanticSegmentationLoss()\n",
        "unet_SemanticSegmentationLoss=SemanticSegmentationLoss()\n",
        "deepSupervisionLoss=DeepSupervisionLoss(weights = [0.5, 0.3, 0.15, 0.05])\n",
        "\n",
        "# fcn matrics\n",
        "fcn_IOUMetric = IOUMetric()\n",
        "fcn_PerClassIOUMetric = PerClassIOUMetric()\n",
        "fcn_Dice_Coefficent_matrics = Dice_Coefficent_matrics()\n",
        "fcn_PerClassDiceCoefficientMatrics = PerClassDiceCoefficientMatrics()\n",
        "fcn_Pixel_accurcy_metrics  = Pixel_accurcy_metrics()\n",
        "\n",
        "fcn_IOUMetric_val = IOUMetric()\n",
        "fcn_PerClassIOUMetric_val = PerClassIOUMetric()\n",
        "fcn_Dice_Coefficent_matrics_val = Dice_Coefficent_matrics()\n",
        "fcn_PerClassDiceCoefficientMatrics_val = PerClassDiceCoefficientMatrics()\n",
        "fcn_Pixel_accurcy_metrics_val  = Pixel_accurcy_metrics()\n",
        "\n",
        "# unet matrics\n",
        "unet_IOUMetric = IOUMetric()\n",
        "unet_PerClassIOUMetric = PerClassIOUMetric()\n",
        "unet_Dice_Coefficent_matrics = Dice_Coefficent_matrics()\n",
        "unet_PerClassDiceCoefficientMatrics = PerClassDiceCoefficientMatrics()\n",
        "unet_Pixel_accurcy_metrics  = Pixel_accurcy_metrics()\n",
        "\n",
        "unet_IOUMetric_val = IOUMetric()\n",
        "unet_PerClassIOUMetric_val = PerClassIOUMetric()\n",
        "unet_Dice_Coefficent_matrics_val = Dice_Coefficent_matrics()\n",
        "unet_PerClassDiceCoefficientMatrics_val = PerClassDiceCoefficientMatrics()\n",
        "unet_Pixel_accurcy_metrics_val  = Pixel_accurcy_metrics()\n",
        "\n",
        "# unet_plus_plus matrics\n",
        "unet_plus_plus_IOUMetric = IOUMetric()\n",
        "unet_plus_plus_PerClassIOUMetric = PerClassIOUMetric()\n",
        "unet_plus_plus_Dice_Coefficent_matrics = Dice_Coefficent_matrics()\n",
        "unet_plus_plus_PerClassDiceCoefficientMatrics = PerClassDiceCoefficientMatrics()\n",
        "unet_plus_plus_Pixel_accurcy_metrics  = Pixel_accurcy_metrics()\n",
        "\n",
        "unet_plus_plus_IOUMetric_val = IOUMetric()\n",
        "unet_plus_plus_PerClassIOUMetric_val = PerClassIOUMetric()\n",
        "unet_plus_plus_Dice_Coefficent_matrics_val = Dice_Coefficent_matrics()\n",
        "unet_plus_plus_PerClassDiceCoefficientMatrics_val = PerClassDiceCoefficientMatrics()\n",
        "unet_plus_plus_Pixel_accurcy_metrics_val  = Pixel_accurcy_metrics()"
      ],
      "metadata": {
        "id": "QrB19aAPvme4"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**custom training**"
      ],
      "metadata": {
        "id": "xBt10VB8kHRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(x_train_batch, y_train_batch):\n",
        "  with tf.GradientTape(persistent=True) as tape:\n",
        "\n",
        "    fcn_logits = fcn(x_train_batch)\n",
        "    fcn_loss = fcn_SemanticSegmentationLoss(y_true=y_train_batch, y_pred=fcn_logits)\n",
        "\n",
        "    unet_logits = unet(x_train_batch)\n",
        "    unet_loss = unet_SemanticSegmentationLoss(y_true=y_train_batch, y_pred=unet_logits)\n",
        "\n",
        "    unet_plus_plus_logits = unet_plus_plus(x_train_batch)\n",
        "    unet_plus_plus_loss = deepSupervisionLoss(y_true=y_train_batch, y_pred=unet_plus_plus_logits)\n",
        "\n",
        "\n",
        "  fcn_gradients = tape.gradient(fcn_loss, fcn.trainable_variables)\n",
        "  unet_gradients = tape.gradient(unet_loss, unet.trainable_variables)\n",
        "  unet_plus_plus_gradients = tape.gradient(unet_plus_plus_loss, unet_plus_plus.trainable_variables)\n",
        "\n",
        "  fcn_IOUMetric.update_state(y_true=y_train_batch, y_pred=fcn_logits)\n",
        "  fcn_PerClassIOUMetric.update_state(y_true=y_train_batch, y_pred=fcn_logits)\n",
        "  fcn_Dice_Coefficent_matrics.update_state(y_train_batch, fcn_logits)\n",
        "  fcn_PerClassDiceCoefficientMatrics.update_state(y_train_batch, fcn_logits)\n",
        "  fcn_Pixel_accurcy_metrics.update_state(y_train_batch, fcn_logits)\n",
        "\n",
        "  unet_IOUMetric.update_state(y_true=y_train_batch, y_pred=unet_logits)\n",
        "  unet_PerClassIOUMetric.update_state(y_true=y_train_batch, y_pred=unet_logits)\n",
        "  unet_Dice_Coefficent_matrics.update_state(y_train_batch, unet_logits)\n",
        "  unet_PerClassDiceCoefficientMatrics.update_state(y_train_batch, unet_logits)\n",
        "  unet_Pixel_accurcy_metrics.update_state(y_train_batch, unet_logits)\n",
        "\n",
        "  unet_plus_plus_IOUMetric.update_state(y_true=y_train_batch, y_pred=unet_plus_plus_logits)\n",
        "  unet_plus__plus_PerClassIOUMetric.update_state(y_true=y_train_batch, y_pred=unet_plus_plus_logits)\n",
        "  unet_plus_plus_Dice_Coefficent_matrics.update_state(y_train_batch, unet_plus_plus_logits)\n",
        "  unet_plus_plus_PerClassDiceCoefficientMatrics.update_state(y_train_batch, unet_plus_plus_logits)\n",
        "  unet_plus_plus_Pixel_accurcy_metrics.update_state(y_train_batch, unet_plus_plus_logits)\n",
        "\n",
        "\n",
        "  return {\n",
        "    'fcn_loss': fcn_loss,\n",
        "    'fcn_gradients': fcn_gradients,\n",
        "    'unet_loss': unet_loss,\n",
        "    'unet_gradients': unet_gradients,\n",
        "    'unet_plus_plus_loss': unet_plus_plus_loss,\n",
        "    'unet_plus_plus_gradients': unet_plus_plus_gradients\n",
        "  }"
      ],
      "metadata": {
        "id": "wDw20qT5HhDJ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope() :\n",
        "  @tf.function\n",
        "  def distributed_train_step(x_train_batch , y_train_batch):\n",
        "    per_replica_results = strategy.run(train_step, args=(x_train_batch, y_train_batch))\n",
        "    fcn_gradients = [strategy.reduce(tf.distribute.ReduceOp.SUM,grad,axis=None) for grad in per_replica_results['fcn_gradients']]\n",
        "    unet_gradients = [strategy.reduce(tf.distribute.ReduceOp.SUM,grad,axis=None) for grad in per_replica_results['unet_gradients']]\n",
        "    unet_plus_plus_gradients = [strategy.reduce(tf.distribute.ReduceOp.SUM , grad , axis = None) for grad in per_replica_results['unet_plus_plus_gradients']]\n",
        "\n",
        "    optimizer_fcn.apply_gradients(zip(fcn_gradients,fcn.trainable_variables))\n",
        "    optimizer_unet.apply_gradients(zip(unet_gradients,unet.trainable_variables))\n",
        "    optimizer_unet_plus_plus.apply_gradients(zip(unet_plus_plus_gradients , unet_plus_plus.trainable_variables))\n",
        "\n",
        "    fcn_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN,per_replica_results['fcn_loss'],axis=None)\n",
        "    unet_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN,per_replica_results['unet_loss'],axis=None)\n",
        "    unet_plus_plus_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN,per_replica_results['unet_plus_plus_loss'],axis = None)\n",
        "\n",
        "    return {\n",
        "        'fcn' : fcn_loss ,\n",
        "        'unet' : unet_loss ,\n",
        "        'unet_plus_plus' : unet_plus_plus_loss\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "u90A1zGJ3rhE",
        "outputId": "430b18c1-c049-46e0-ff56-972cd2338238"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'strategy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-2303ee70be16>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdistributed_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_batch\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mper_replica_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfcn_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceOp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mper_replica_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fcn_gradients'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'strategy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope()\n",
        "  def train_model_for_one_epoch(epoch):\n",
        "    fcn_loss = []\n",
        "    unet_loss = []\n",
        "    unet_plus_plus_loss = []\n",
        "    for step  , (x_train_batch , y_train_batch) in enumerate (train_dataset):\n",
        "      losses=distributed_train_step(x_train_batch , y_train_batch)\n",
        "      fcn_loss.append(losses['fcn'])\n",
        "      unet_loss.append(losses['unet'])\n",
        "      unet_plus_plus.append(losses['unet_plus_plus'])\n",
        "      data = {\n",
        "          'fcn': {\n",
        "              'loss' : losses['fcn'] ,\n",
        "              'metrics': {\n",
        "                  'IOUMetric' : fcn_IOUMetric.result(),\n",
        "                  'PerClassIOUMetric' : fcn_PerClassIOUMetric.result(),\n",
        "                  'Dice_Coefficent_matrics' : fcn_Dice_Coefficent_matrics.result(),\n",
        "                  'PerClassDiceCoefficientMatrics' : fcn_PerClassDiceCoefficientMatrics.result() ,\n",
        "                  'Pixel_accurcy_metrics' : fcn_Pixel_accurcy_metrics.result()\n",
        "              }\n",
        "          },\n",
        "          'unet' : {\n",
        "              'loss' : losses['unet'] ,\n",
        "              'metrics': {\n",
        "                  'IOUMetric' : unet_IOUMetric.result(),\n",
        "                  'PerClassIOUMetric' : unet_PerClassIOUMetric.result(),\n",
        "                  'Dice_Coefficent_matrics' : unet_Dice_Coefficent_matrics.result(),\n",
        "                  'PerClassDiceCoefficientMatrics' : unet_PerClassDiceCoefficientMatrics.result() ,\n",
        "                  'Pixel_accurcy_metrics' : unet_Pixel_accurcy_metrics.result()\n",
        "              }\n",
        "          },\n",
        "          'unet_plus_plus' : {\n",
        "              'loss' : losses['unet_plus_plus'] ,\n",
        "              'metrics': {\n",
        "                  'IOUMetric' : unet_plus_plus_IOUMetric.result(),\n",
        "                  'PerClassIOUMetric' : unet_plus_plus_PerClassIOUMetric.result(),\n",
        "                  'Dice_Coefficent_matrics' : unet_plus_plus_Dice_Coefficent_matrics.result(),\n",
        "                  'PerClassDiceCoefficientMatrics' : unet_plus_plus_PerClassDiceCoefficientMatrics.result() ,\n",
        "                  'Pixel_accurcy_metrics' : unet_plus_plus_Pixel_accurcy_metrics.result()\n",
        "              }\n",
        "          }\n",
        "      }\n",
        "      master_callback.on_batch_end(batch = step+1 , epoch = epoch,data = data)\n",
        "    return {\n",
        "        'fcn' : fcn_loss ,\n",
        "        'unet' : unet_loss  ,\n",
        "        'unet_plus_plus' : unet_plus_plus_loss\n",
        "    }"
      ],
      "metadata": {
        "id": "_8Iz61nAft5x"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_training =False\n",
        "start=master_callback.on_train_begin()\n",
        "for epoch in range(start , 250 ):\n",
        ""
      ],
      "metadata": {
        "id": "fcq-4mHrBoZB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}